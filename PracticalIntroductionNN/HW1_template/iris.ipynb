{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "species = ['Setosa', 'Versicolor', 'Virginica']\n",
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_path, names=feature_names, header=0)\n",
    "test = pd.read_csv(test_path, names=feature_names, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      2\n",
      "1      1\n",
      "2      2\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "115    1\n",
      "116    1\n",
      "117    0\n",
      "118    0\n",
      "119    1\n",
      "Name: Species, Length: 120, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_y = train.pop(\"Species\")\n",
    "test_y = test.pop(\"Species\")\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "feature_columns = []\n",
    "for key in train.keys():\n",
    "    feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "print(feature_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\alber\\AppData\\Local\\Temp\\tmpgvbsv9o4\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\alber\\\\AppData\\\\Local\\\\Temp\\\\tmpgvbsv9o4', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns,\n",
    "                                        hidden_units=[30,10],\n",
    "                                        n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alber\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:235: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\alber\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\optimizer_v2\\adagrad.py:83: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\alber\\AppData\\Local\\Temp\\tmpgvbsv9o4\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 1.3178289, step = 0\n",
      "INFO:tensorflow:global_step/sec: 291.548\n",
      "INFO:tensorflow:loss = 1.1367966, step = 100 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.226\n",
      "INFO:tensorflow:loss = 1.071871, step = 200 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.466\n",
      "INFO:tensorflow:loss = 1.0250478, step = 300 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.004\n",
      "INFO:tensorflow:loss = 0.990469, step = 400 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.717\n",
      "INFO:tensorflow:loss = 0.9539531, step = 500 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.223\n",
      "INFO:tensorflow:loss = 0.92821443, step = 600 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.351\n",
      "INFO:tensorflow:loss = 0.89554, step = 700 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.988\n",
      "INFO:tensorflow:loss = 0.88456535, step = 800 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.364\n",
      "INFO:tensorflow:loss = 0.8585133, step = 900 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.429\n",
      "INFO:tensorflow:loss = 0.83605886, step = 1000 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.639\n",
      "INFO:tensorflow:loss = 0.79945445, step = 1100 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.008\n",
      "INFO:tensorflow:loss = 0.7852309, step = 1200 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.575\n",
      "INFO:tensorflow:loss = 0.76446056, step = 1300 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.403\n",
      "INFO:tensorflow:loss = 0.7554667, step = 1400 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.445\n",
      "INFO:tensorflow:loss = 0.7307774, step = 1500 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.715\n",
      "INFO:tensorflow:loss = 0.69880074, step = 1600 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.419\n",
      "INFO:tensorflow:loss = 0.6817575, step = 1700 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.428\n",
      "INFO:tensorflow:loss = 0.66843164, step = 1800 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.607\n",
      "INFO:tensorflow:loss = 0.6494412, step = 1900 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.636\n",
      "INFO:tensorflow:loss = 0.63283217, step = 2000 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.011\n",
      "INFO:tensorflow:loss = 0.6218277, step = 2100 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.368\n",
      "INFO:tensorflow:loss = 0.6074441, step = 2200 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.958\n",
      "INFO:tensorflow:loss = 0.59280324, step = 2300 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.948\n",
      "INFO:tensorflow:loss = 0.594868, step = 2400 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.637\n",
      "INFO:tensorflow:loss = 0.569399, step = 2500 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.964\n",
      "INFO:tensorflow:loss = 0.5531251, step = 2600 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.964\n",
      "INFO:tensorflow:loss = 0.5523574, step = 2700 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.011\n",
      "INFO:tensorflow:loss = 0.5459934, step = 2800 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.61\n",
      "INFO:tensorflow:loss = 0.54656065, step = 2900 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.01\n",
      "INFO:tensorflow:loss = 0.53645104, step = 3000 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.319\n",
      "INFO:tensorflow:loss = 0.53560275, step = 3100 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.357\n",
      "INFO:tensorflow:loss = 0.53781617, step = 3200 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.01\n",
      "INFO:tensorflow:loss = 0.5184099, step = 3300 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.147\n",
      "INFO:tensorflow:loss = 0.51510155, step = 3400 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.315\n",
      "INFO:tensorflow:loss = 0.51139206, step = 3500 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.005\n",
      "INFO:tensorflow:loss = 0.49595624, step = 3600 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.356\n",
      "INFO:tensorflow:loss = 0.49666655, step = 3700 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.417\n",
      "INFO:tensorflow:loss = 0.50196666, step = 3800 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.011\n",
      "INFO:tensorflow:loss = 0.49377504, step = 3900 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.878\n",
      "INFO:tensorflow:loss = 0.48978853, step = 4000 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.138\n",
      "INFO:tensorflow:loss = 0.48683128, step = 4100 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.877\n",
      "INFO:tensorflow:loss = 0.48172677, step = 4200 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.15\n",
      "INFO:tensorflow:loss = 0.46483243, step = 4300 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.127\n",
      "INFO:tensorflow:loss = 0.4615979, step = 4400 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.115\n",
      "INFO:tensorflow:loss = 0.46017927, step = 4500 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.026\n",
      "INFO:tensorflow:loss = 0.45680544, step = 4600 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.031\n",
      "INFO:tensorflow:loss = 0.4535441, step = 4700 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.641\n",
      "INFO:tensorflow:loss = 0.45612693, step = 4800 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.468\n",
      "INFO:tensorflow:loss = 0.43465692, step = 4900 (0.293 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\alber\\AppData\\Local\\Temp\\tmpgvbsv9o4\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.43030626.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x191b8f0e220>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "    steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-27T13:44:12\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\alber\\AppData\\Local\\Temp\\tmpgvbsv9o4\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.18700s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-27-13:44:13\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.6666667, average_loss = 0.5456292, global_step = 5000, loss = 0.5456292\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: C:\\Users\\alber\\AppData\\Local\\Temp\\tmpgvbsv9o4\\model.ckpt-5000\n",
      "0.6666667\n"
     ]
    }
   ],
   "source": [
    "eval_result=classifier.evaluate(\n",
    "    input_fn=lambda: input_fn(test, test_y, training=False)\n",
    ")\n",
    "print(eval_result[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SepalLength': [10.0], 'SepalWidth': [12.0], 'PetalLength': [2.0]}\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\alber\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py:346 call  *\n        net = self._input_layer(features, training=is_training)\n    C:\\Users\\alber\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\base_layer_v1.py:765 __call__  **\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    C:\\Users\\alber\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\feature_column\\dense_features.py:168 call  **\n        tensor = column.get_dense_tensor(transformation_cache,\n    C:\\Users\\alber\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2697 get_dense_tensor\n        return transformation_cache.get(self, state_manager)\n    C:\\Users\\alber\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2460 get\n        transformed = column.transform_feature(self, state_manager)\n    C:\\Users\\alber\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2669 transform_feature\n        input_tensor = transformation_cache.get(self.key, state_manager)\n    C:\\Users\\alber\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2444 get\n        raise ValueError('Feature {} is not in features dictionary.'.format(key))\n\n    ValueError: Feature PetalWidth is not in features dictionary.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18472/2100273112.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mpred_dict\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mclass_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class_ids'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mprobability\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'probabilities'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclass_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[0;32m    611\u001b[0m         features, input_hooks = self._get_features_from_input_fn(\n\u001b[0;32m    612\u001b[0m             input_fn, ModeKeys.PREDICT)\n\u001b[1;32m--> 613\u001b[1;33m         estimator_spec = self._call_model_fn(features, None, ModeKeys.PREDICT,\n\u001b[0m\u001b[0;32m    614\u001b[0m                                              self.config)\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[1;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[0;32m   1162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1164\u001b[1;33m     \u001b[0mmodel_fn_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1165\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py\u001b[0m in \u001b[0;36m_model_fn\u001b[1;34m(features, labels, mode, config)\u001b[0m\n\u001b[0;32m    744\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m       \u001b[1;34m\"\"\"Call the defined shared dnn_model_fn_v2.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 746\u001b[1;33m       return dnn_model_fn_v2(\n\u001b[0m\u001b[0;32m    747\u001b[0m           \u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m           \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py\u001b[0m in \u001b[0;36mdnn_model_fn_v2\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    554\u001b[0m   \u001b[1;32mdel\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m   logits, trainable_variables, update_ops = _dnn_model_fn_builder_v2(\n\u001b[0m\u001b[0;32m    557\u001b[0m       \u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits_dimension\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m       \u001b[0mhidden_units\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhidden_units\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py\u001b[0m in \u001b[0;36m_dnn_model_fn_builder_v2\u001b[1;34m(units, hidden_units, feature_columns, activation_fn, dropout, batch_norm, features, mode)\u001b[0m\n\u001b[0;32m    498\u001b[0m       \u001b[0mbatch_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m       name='dnn')\n\u001b[1;32m--> 500\u001b[1;33m   \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdnn_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m   \u001b[0mtrainable_variables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m   \u001b[0mupdate_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\base_layer_v1.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    763\u001b[0m               with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m    764\u001b[0m                   self._compute_dtype_object):\n\u001b[1;32m--> 765\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    693\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 695\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    696\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\alber\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py:346 call  *\n        net = self._input_layer(features, training=is_training)\n    C:\\Users\\alber\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\base_layer_v1.py:765 __call__  **\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    C:\\Users\\alber\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\feature_column\\dense_features.py:168 call  **\n        tensor = column.get_dense_tensor(transformation_cache,\n    C:\\Users\\alber\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2697 get_dense_tensor\n        return transformation_cache.get(self, state_manager)\n    C:\\Users\\alber\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2460 get\n        transformed = column.transform_feature(self, state_manager)\n    C:\\Users\\alber\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2669 transform_feature\n        input_tensor = transformation_cache.get(self.key, state_manager)\n    C:\\Users\\alber\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2444 get\n        raise ValueError('Feature {} is not in features dictionary.'.format(key))\n\n    ValueError: Feature PetalWidth is not in features dictionary.\n"
     ]
    }
   ],
   "source": [
    "def input_fn(features, batch_size=256):\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
    "predict = {}\n",
    "\n",
    "for feature in features:\n",
    "  val = input(feature + \": \")\n",
    "  if val.isdigit():\n",
    "    predict[feature] = [float(val)]\n",
    "\n",
    "print(predict)\n",
    "\n",
    "predictions = classifier.predict(input_fn=lambda: input_fn(predict))\n",
    "\n",
    "for pred_dict in predictions:\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%)'.format(\n",
    "                SPECIES[class_id], 100 * probability))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f63929e3db36fe13aee1081860966e065fd27c1f14440ef685fe33e45209081c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tf-gpu': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
