{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Save and Restore tf.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create tf.Variables</h2>\n",
    "<p style=\"font-size:20px\">In the previous tutorial, we use <b>tf.Variable</b> to create variables. Here we introduce a second way to create tensorflow variables --- <b>tf.get_variable</b>. The <b>tf.get_variable</b> can be used to get the variable you have defined in the graph before and if it is not defined, it will create a new variable. You can initialize the variable with the <b>initializer</b> argument. You can use <b>assign</b> operation to update the variable just like what we did before. And you still need to have the \"init_op\" to initialize all variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create some variables\n",
    "W = tf.get_variable(\"W\",shape=[3],initializer = tf.zeros_initializer)\n",
    "b = tf.get_variable(\"b\",shape=[5],initializer = tf.zeros_initializer)\n",
    "\n",
    "#increase operation for W\n",
    "increase_op = W.assign(W+1)\n",
    "#decrease operation for b\n",
    "decrease_op = b.assign(b-1)\n",
    "\n",
    "#initialize variables\n",
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Saver</h2>\n",
    "<p style=\"font-size:20px\">You can create a <b>Saver</b> with <b>tf.train.Saver()</b> to manage all variables in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create saver operation to save and restore all the variables\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px\">In the <b>tf.Session()</b>, you can save the variables to a specific directory using <b>saver.save(sess,\"directory\")</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path: tmp/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init_op)\n",
    "    \n",
    "    #run the increase and decrease operations\n",
    "    sess.run(increase_op)\n",
    "    sess.run(decrease_op)\n",
    "    \n",
    "    #save the variables to the directory\n",
    "    save_path = saver.save(sess,\"tmp/model.ckpt\")\n",
    "    print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px\">In the tmp folder, you will find four files:\n",
    "    <ol style=\"font-size:20px\">\n",
    "        <li><b>checkpoint</b>: All checkpoint information, like model ckpt file name and path</li>\n",
    "        <li><b>model.ckpt.meta</b>: Tensorflow stores the graph structure separately from the vairable values. The file .ckpt.meta contains the complete graph.</li>\n",
    "        <li><b>model.ckpt.data-0000-of-00001</b>: This contains the values of variables (weights, biases, placeholders, gradients, hyperparamters, etc.).</li>\n",
    "        <li><b>model.ckpt.index</b>: It is a table where each key is the name of a tensor and its value is a serialized BundleEntryProto. (SerializedBundleEntryProto holds metadata of the tensors. Metadata of a tensor may be like: which of the \"data\" files contains the content of the content of a tensor, the offset into that file, checksum, etc.</li>\n",
    "    </ol>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Restore variables</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px\">We can restore our variables from disk by <b>saver.restore(sess, \"directory\")</b>. Note that here you don't need to initialize the variables with <b>tf.global_variables_initializer</b> anymore because they are existed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px\">In addition, we introduce another way to get the values out: <b>W.eval()</b> that does exactly the same thing as <b>sess.run(W)</b>. In the end, you can see the variables are restored and printed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tmp/model.ckpt\n",
      "Model restored.\n",
      "W: [1. 1. 1.]\n",
      "b: [-1. -1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "W = tf.get_variable(\"W\",shape=[3])\n",
    "b = tf.get_variable(\"b\",shape=[5])\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    #restore variables from disk\n",
    "    saver.restore(sess,\"tmp/model.ckpt\")\n",
    "    \n",
    "    print(\"Model restored.\")\n",
    "    #check the values of the variables, W.eval() == sess.run(W)\n",
    "    print(\"W: %s\"%W.eval())\n",
    "    print(\"b: %s\"%b.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Choose vairbales to save and restore</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px\">If you do not pass any arguments to <b>tf.train.Saver()</b>, the saver handles all variables in the graph. Each variable is saved under the name that was passed when the variable was created.</p>\n",
    "<p style=\"font-size:20px\">It is sometimes useful to explicitly specify names for variables in the checkpoint files. For example, you may have trained a model with a variable named \"weights\" whose value you want to restore into a variable named \"params\".</p>\n",
    "\n",
    "<p style=\"font-size:20px\">It is also sometimes useful to only save or restore a subset of the variables used by a model. For example, you may have trained a neural net with five layers, and you now want to train a new model with six layers that reuses the existing weights of the five trained layers. You can use the saver to restore the weights of just the first five layers.\n",
    "\n",
    "<p style=\"font-size:20px\">You can easily specify the names and variables to save or load by passing to the <b>tf.train.Saver()</b> constructor either of the following:\n",
    "\n",
    "<ul style=\"font-size:20px\">\n",
    "    <li>A list of variables (which will be stored under their own names).</li>\n",
    "    <li>A Python dictionary in which keys are the names to use and the values are the variables to manage.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tmp/model.ckpt\n",
      "W: [0. 0. 0.]\n",
      "b: [-1. -1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "W = tf.get_variable(\"W\",[3],initializer=tf.zeros_initializer)\n",
    "b = tf.get_variable(\"b\",[5],initializer=tf.zeros_initializer)\n",
    "\n",
    "#Add ops to save and restore only 'b' using the name \"b\"\n",
    "saver = tf.train.Saver({\"b\":b})\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #initialize W since the saver will not.\n",
    "    W.initializer.run()\n",
    "    \n",
    "    saver.restore(sess,'tmp/model.ckpt')\n",
    "    \n",
    "    print(\"W: %s\"%W.eval())\n",
    "    print(\"b: %s\"%b.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Restore graph with meta file</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px\">Since the <b>.meta</b> file has the structure of the graph. You can load this graph structure using <b>tf.train.import_meta_graph()</b>. This adds the graph to the default graph, and returns a <b>Saver</b> instance that you can then use to restore the graph's state (i.e., the variable values).</p>\n",
    "\n",
    "<p style=\"font-size:20px\"> This allows you to fully restore a saved model, including both the graph structure and the variable values, without having to search for the code that built it.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tmp/model.ckpt\n",
      "W: [1. 1. 1.]\n",
      "b: [-1. -1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "saver = tf.train.import_meta_graph(\"tmp/model.ckpt.meta\")\n",
    "W = tf.get_default_graph().get_tensor_by_name(\"W:0\")\n",
    "b = tf.get_default_graph().get_tensor_by_name(\"b:0\")\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,\"tmp/model.ckpt\")\n",
    "    \n",
    "    print(\"W: %s\" %sess.run(W))\n",
    "    print(\"b: %s\" %sess.run(b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
