{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "import h5py\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, AveragePooling2D, MaxPooling2D ,Dropout, Flatten\n",
    "import tensorflow.keras as keras\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Load training, validation, testing set from your preprocessed files</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"D:\\Work\\EPE\\PracticalIntroductionNN\\HW2_template\\cat_dog\\dc_227.h5\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "train_img = f[\"train_img\"][...]\n",
    "train_lab = f[\"train_lab\"][...]\n",
    "val_img = f[\"val_img\"][...]\n",
    "val_lab = f[\"val_lab\"][...]\n",
    "print(type(train_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=(19000, 227, 227, 3), y=(19000,)\n",
      "Val: X=(1000, 227, 227, 3), y=(1000,)\n",
      "[0. 1. 1. ... 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print('Train: X=%s, y=%s' % (train_img.shape, train_lab.shape))\n",
    "print('Val: X=%s, y=%s' % (val_img.shape, val_lab.shape))\n",
    "print(train_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height, img_num_channels = 227, 227, 3\n",
    "input_shape = (img_width, img_height, img_num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fit_generator\n",
    "\"\"\"\n",
    "def data_generator(data, targets, batch_size):\n",
    "    batches = (len(data) + batch_size - 1)//batch_size\n",
    "    while(True):\n",
    "         for i in range(batches):\n",
    "              X = data[i*batch_size : (i+1)*batch_size]\n",
    "              Y = targets[i*batch_size : (i+1)*batch_size]\n",
    "              yield (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 120\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alber\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "159/159 [==============================] - 78s 411ms/step - loss: 3.2357 - accuracy: 0.5502 - val_loss: 0.6865 - val_accuracy: 0.5390\n",
      "Epoch 2/20\n",
      "159/159 [==============================] - 54s 343ms/step - loss: 0.6819 - accuracy: 0.5814 - val_loss: 0.6636 - val_accuracy: 0.6120\n",
      "Epoch 3/20\n",
      "159/159 [==============================] - 38s 242ms/step - loss: 0.6484 - accuracy: 0.6273 - val_loss: 0.6569 - val_accuracy: 0.6050\n",
      "Epoch 4/20\n",
      "159/159 [==============================] - 25s 159ms/step - loss: 0.5928 - accuracy: 0.6941 - val_loss: 0.6650 - val_accuracy: 0.6400\n",
      "Epoch 5/20\n",
      "159/159 [==============================] - 46s 291ms/step - loss: 0.5320 - accuracy: 0.7386 - val_loss: 0.7684 - val_accuracy: 0.6030\n",
      "Epoch 6/20\n",
      "159/159 [==============================] - 39s 245ms/step - loss: 0.4763 - accuracy: 0.7782 - val_loss: 0.5417 - val_accuracy: 0.7400\n",
      "Epoch 7/20\n",
      "159/159 [==============================] - 30s 190ms/step - loss: 0.4428 - accuracy: 0.8001 - val_loss: 0.9306 - val_accuracy: 0.5660\n",
      "Epoch 8/20\n",
      "159/159 [==============================] - 40s 252ms/step - loss: 0.4068 - accuracy: 0.8210 - val_loss: 0.8101 - val_accuracy: 0.7000\n",
      "Epoch 9/20\n",
      "159/159 [==============================] - 33s 206ms/step - loss: 0.3790 - accuracy: 0.8349 - val_loss: 0.5971 - val_accuracy: 0.6860\n",
      "Epoch 10/20\n",
      "159/159 [==============================] - 31s 196ms/step - loss: 0.3505 - accuracy: 0.8523 - val_loss: 0.5184 - val_accuracy: 0.7300\n",
      "Epoch 11/20\n",
      "159/159 [==============================] - 26s 161ms/step - loss: 0.3116 - accuracy: 0.8692 - val_loss: 0.5852 - val_accuracy: 0.7450\n",
      "Epoch 12/20\n",
      "159/159 [==============================] - 23s 147ms/step - loss: 0.2749 - accuracy: 0.8841 - val_loss: 0.6825 - val_accuracy: 0.6110\n",
      "Epoch 13/20\n",
      "159/159 [==============================] - 30s 188ms/step - loss: 0.2471 - accuracy: 0.8945 - val_loss: 0.7226 - val_accuracy: 0.6240\n",
      "Epoch 14/20\n",
      "159/159 [==============================] - 35s 224ms/step - loss: 0.2331 - accuracy: 0.9041 - val_loss: 0.3539 - val_accuracy: 0.8710\n",
      "Epoch 15/20\n",
      "159/159 [==============================] - 31s 195ms/step - loss: 0.2066 - accuracy: 0.9152 - val_loss: 0.6763 - val_accuracy: 0.7320\n",
      "Epoch 16/20\n",
      "159/159 [==============================] - 24s 150ms/step - loss: 0.1980 - accuracy: 0.9216 - val_loss: 0.8265 - val_accuracy: 0.6840\n",
      "Epoch 17/20\n",
      "159/159 [==============================] - 17s 108ms/step - loss: 0.1927 - accuracy: 0.9222 - val_loss: 0.6275 - val_accuracy: 0.7810\n",
      "Epoch 18/20\n",
      "159/159 [==============================] - 25s 157ms/step - loss: 0.1770 - accuracy: 0.9297 - val_loss: 0.5561 - val_accuracy: 0.7290\n",
      "Epoch 19/20\n",
      "159/159 [==============================] - 21s 134ms/step - loss: 0.1583 - accuracy: 0.9386 - val_loss: 0.4453 - val_accuracy: 0.7780\n",
      "Epoch 20/20\n",
      "159/159 [==============================] - 15s 94ms/step - loss: 0.1333 - accuracy: 0.9483 - val_loss: 0.8839 - val_accuracy: 0.7520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2469b0579d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(generator = data_generator(train_img, train_lab, batch_size=batch_size),\n",
    "            steps_per_epoch = (len(train_img) + batch_size - 1) // batch_size,\n",
    "            epochs = num_epochs,\n",
    "            verbose = 1,\n",
    "            validation_data = (val_img, val_lab)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = f[\"train_img\"][...]\n",
    "train_lab = f[\"train_lab\"][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lab = f[\"train_lab\"][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data, targets, batch_size):\n",
    "    batches = (len(data) + batch_size - 1)//batch_size\n",
    "    while(True):\n",
    "         for i in range(batches):\n",
    "              X = data[i*batch_size : (i+1)*batch_size]\n",
    "              Y = targets[i*batch_size : (i+1)*batch_size]\n",
    "              yield (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4790/Unknown - 538s 112ms/step - loss: 0.5925 - accuracy: 0.8034"
     ]
    }
   ],
   "source": [
    "model.evaluate(data_generator(train_img, train_lab, batch_size=200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define hyperparameter</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>AlexNet</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cost and Optimization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Training and validation</h1>\n",
    "<h2>Train your model only 10 epochs</h2>\n",
    "<p style=\"font-size:20px\">1. Print out training accuracy and validation accuracy each training epoch</p>\n",
    "<p style=\"font-size:20px\">2. Print out training time each training epoch</p>\n",
    "<p style=\"font-size:20px\">3. Your goal is to reach 85% validation accuracy in 10 training epochs. If you reach that, you can perform testing, print out your test accuracy. Plot out the ten images with title that contains the probability of the labeled class.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
