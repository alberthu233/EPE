{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PFN and PFN with mdn layer\n",
    "this note book is only for model training, see result comparison in evaluation notebook\n",
    "\n",
    "STMC_V2 dataset\n",
    "\n",
    "Eta ---->2.5\n",
    "DeltaR ---->1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import time as t\n",
    "import scipy.constants as spc\n",
    "import matplotlib.ticker as ticker\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_prefix = 'D:/Work/EPE/ML4pi/'\n",
    "plotpath = path_prefix+'plots/'\n",
    "modelpath_c = path_prefix+''\n",
    "modelpath = path_prefix+''\n",
    "data_path = path_prefix + \"v7/\"\n",
    "ext_path = \"H:/EPE_file_storage/\"\n",
    "ext_modelpath = ext_path + \"Model/\"\n",
    "ext_datapath = 'H:/EPE_file_storage/data_storage/pipm/root/'\n",
    "stmc_v2_path = ext_datapath + 'STMC_v2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(path_prefix)\n",
    "from util import resolution_util as ru\n",
    "from util import plot_util as pu\n",
    "from util import ml_util as mu\n",
    "import uproot3 as ur\n",
    "import keras.utils.io_utils as kiu\n",
    "import h5py as h5\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "with h5.File(stmc_v2_path+'STMC_v2_train.h5', 'r') as hf:\n",
    "    data = hf['X'][:]\n",
    "    target = hf['Y'][:]\n",
    "\n",
    "# load validation data\n",
    "with h5.File(stmc_v2_path+'STMC_v2_val.h5', 'r') as hf:\n",
    "    val_data = hf['X'][:]\n",
    "    val_target = hf['Y'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:,:,:5]\n",
    "val_data = val_data[:,:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288046, 1389, 5)\n",
      "(288046,)\n",
      "(61724, 1389, 5)\n",
      "(61724,)\n"
     ]
    }
   ],
   "source": [
    "# select target 0 as the 'true energy', and 1 as the 'track Pt', and 2 as the 'Cluster energy calib total'\n",
    "target = target[:,0]\n",
    "val_target = val_target[:,0]\n",
    "print(data.shape)\n",
    "print(target.shape)\n",
    "print(val_data.shape)\n",
    "print(val_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use data generator feed input data to avoid memory issue, any one of the three here should work, carefully choose the generator batch sizes would improve the gpu usage rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatches(inputs=None, targets=None, batch_size=None, shuffle=True):\n",
    "    while True:\n",
    "        assert len(inputs) == len(targets)\n",
    "        if shuffle:\n",
    "            indices = np.arange(len(inputs))\n",
    "            np.random.shuffle(indices)\n",
    "        for start_idx in range( len(inputs) - batch_size ):\n",
    "            if shuffle:\n",
    "                excerpt = indices[start_idx:start_idx + batch_size]\n",
    "            else:\n",
    "                excerpt = slice(start_idx, start_idx + batch_size)\n",
    "            yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data, targets, batch_size):\n",
    "     batches = (len(data) + batch_size - 1)//batch_size\n",
    "     while True:\n",
    "          for i in range(batches):\n",
    "               X = data[i*batch_size : (i+1)*batch_size]\n",
    "               Y = targets[i*batch_size : (i+1)*batch_size]\n",
    "               yield (X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.models import load_model\n",
    "import keras.backend as Kb\n",
    "import energyflow as ef\n",
    "from energyflow.archs import PFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network architecture parameters\n",
    "Phi_sizes, F_sizes = (100, 100, 128), (100, 100, 100)\n",
    "output_act, output_dim = 'linear', 1\n",
    "loss = 'mse'\n",
    "\n",
    "# network training parameters\n",
    "num_epoch = 1500\n",
    "batch_size = 1000\n",
    "\n",
    "netOpt = tf.keras.optimizers.Adam(\n",
    "    learning_rate=.002,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-09,\n",
    "    amsgrad=False)\n",
    "\n",
    "RMS_prop = tf.keras.optimizers.RMSprop(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 5)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 100)    600         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, None, 100)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 100)    10100       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, 100)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 128)    12928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, 128)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 128)          0           mask[0][0]                       \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 100)          12900       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 100)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          10100       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          10100       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 100)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            101         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 1)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 56,829\n",
      "Trainable params: 56,829\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# network architecture parameters\n",
    "Phi_sizes, F_sizes = (100, 100, 128), (100, 100, 100)\n",
    "output_act, output_dim = 'linear', 1\n",
    "loss = 'mse'\n",
    "\n",
    "Kb.clear_session()\n",
    "\n",
    "pfn = PFN(input_dim=5, Phi_sizes=Phi_sizes, F_sizes=F_sizes, \n",
    "          output_act=output_act, output_dim=output_dim, loss=loss,\n",
    "          optimizer=netOpt, metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/564\n",
      "281/281 [==============================] - 34s 115ms/step - loss: 0.0076 - val_loss: 0.0109\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.01086, saving model to model\\pfn_stmc_v2_dg_1.h5\n",
      "Epoch 2/564\n",
      "281/281 [==============================] - 32s 114ms/step - loss: 0.0029 - val_loss: 0.0099\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.01086 to 0.00993, saving model to model\\pfn_stmc_v2_dg_1.h5\n",
      "Epoch 3/564\n",
      "281/281 [==============================] - 32s 114ms/step - loss: 0.0028 - val_loss: 0.0123\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00993\n",
      "Epoch 4/564\n",
      "281/281 [==============================] - 32s 113ms/step - loss: 0.0033 - val_loss: 0.0121\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00993\n",
      "Epoch 5/564\n",
      "281/281 [==============================] - 29s 102ms/step - loss: 0.0045 - val_loss: 0.0166\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00993\n",
      "Epoch 6/564\n",
      "281/281 [==============================] - 29s 102ms/step - loss: 0.0039 - val_loss: 0.0177\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00993\n",
      "Epoch 7/564\n",
      "281/281 [==============================] - 29s 102ms/step - loss: 0.0035 - val_loss: 0.0183\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00993\n",
      "Epoch 8/564\n",
      "281/281 [==============================] - 29s 102ms/step - loss: 0.0035 - val_loss: 0.0208\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00993\n",
      "Epoch 9/564\n",
      "281/281 [==============================] - 29s 103ms/step - loss: 0.0028 - val_loss: 0.0170\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00993\n",
      "Epoch 10/564\n",
      "281/281 [==============================] - 29s 102ms/step - loss: 0.0026 - val_loss: 0.0178\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00993\n",
      "Epoch 11/564\n",
      "281/281 [==============================] - 29s 102ms/step - loss: 0.0025 - val_loss: 0.0145\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00993\n",
      "Epoch 12/564\n",
      "281/281 [==============================] - 29s 102ms/step - loss: 0.0025 - val_loss: 0.0146\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00993\n",
      "Epoch 13/564\n",
      "281/281 [==============================] - 29s 103ms/step - loss: 0.0056 - val_loss: 0.0177\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00993\n",
      "Epoch 14/564\n",
      "281/281 [==============================] - 29s 102ms/step - loss: 0.0062 - val_loss: 0.0288\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00993\n",
      "Epoch 15/564\n",
      "281/281 [==============================] - 29s 103ms/step - loss: 0.0055 - val_loss: 0.0272\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00993\n",
      "Epoch 16/564\n",
      "281/281 [==============================] - 35s 125ms/step - loss: 0.0050 - val_loss: 0.0297\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00993\n",
      "Epoch 17/564\n",
      "281/281 [==============================] - 43s 151ms/step - loss: 0.0035 - val_loss: 0.0331\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00993\n",
      "Epoch 18/564\n",
      "281/281 [==============================] - 46s 162ms/step - loss: 0.0028 - val_loss: 0.0357\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00993\n",
      "Epoch 19/564\n",
      "281/281 [==============================] - 38s 137ms/step - loss: 0.0038 - val_loss: 0.0215\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00993\n",
      "Epoch 20/564\n",
      "281/281 [==============================] - 37s 133ms/step - loss: 0.0040 - val_loss: 0.0176\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00993\n",
      "Epoch 21/564\n",
      "281/281 [==============================] - 37s 130ms/step - loss: 0.0030 - val_loss: 0.0159\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00993\n",
      "Epoch 22/564\n",
      "281/281 [==============================] - 37s 131ms/step - loss: 0.0040 - val_loss: 0.0258\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00993\n",
      "Epoch 23/564\n",
      "281/281 [==============================] - 45s 159ms/step - loss: 0.0038 - val_loss: 0.0341\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00993\n",
      "Epoch 24/564\n",
      "281/281 [==============================] - 45s 159ms/step - loss: 0.0044 - val_loss: 0.0302\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00993\n",
      "Epoch 25/564\n",
      "281/281 [==============================] - 45s 159ms/step - loss: 0.0033 - val_loss: 0.0285\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00993\n",
      "Epoch 26/564\n",
      "281/281 [==============================] - 44s 158ms/step - loss: 0.0030 - val_loss: 0.0294\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00993\n",
      "Epoch 27/564\n",
      "281/281 [==============================] - 42s 149ms/step - loss: 0.0030 - val_loss: 0.0261\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00993\n",
      "Epoch 28/564\n",
      "281/281 [==============================] - 37s 131ms/step - loss: 0.0035 - val_loss: 0.0300\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00993\n",
      "Epoch 29/564\n",
      "281/281 [==============================] - 37s 132ms/step - loss: 0.0028 - val_loss: 0.0323\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00993\n",
      "Epoch 30/564\n",
      "281/281 [==============================] - 37s 133ms/step - loss: 0.0028 - val_loss: 0.0331\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00993\n",
      "Epoch 31/564\n",
      "281/281 [==============================] - 42s 151ms/step - loss: 0.0044 - val_loss: 0.0252\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00993\n",
      "Epoch 32/564\n",
      "281/281 [==============================] - 42s 148ms/step - loss: 0.0047 - val_loss: 0.0312\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00993\n",
      "Epoch 33/564\n",
      "281/281 [==============================] - 38s 135ms/step - loss: 0.0051 - val_loss: 0.0275\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00993\n",
      "Epoch 34/564\n",
      "281/281 [==============================] - 37s 133ms/step - loss: 0.0040 - val_loss: 0.0278\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00993\n",
      "Epoch 35/564\n",
      "281/281 [==============================] - 38s 137ms/step - loss: 0.0047 - val_loss: 0.0347\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00993\n",
      "Epoch 36/564\n",
      "281/281 [==============================] - 38s 136ms/step - loss: 0.0144 - val_loss: 0.0489\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00993\n",
      "Epoch 37/564\n",
      "281/281 [==============================] - 38s 135ms/step - loss: 0.0089 - val_loss: 0.0471\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00993\n",
      "Epoch 38/564\n",
      "281/281 [==============================] - 38s 136ms/step - loss: 0.0064 - val_loss: 0.0491\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00993\n",
      "Epoch 39/564\n",
      "281/281 [==============================] - 41s 148ms/step - loss: 0.0063 - val_loss: 0.0357\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00993\n",
      "Epoch 40/564\n",
      "281/281 [==============================] - 41s 146ms/step - loss: 0.0072 - val_loss: 0.0538\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00993\n",
      "Epoch 41/564\n",
      "281/281 [==============================] - 38s 137ms/step - loss: 0.0048 - val_loss: 0.0584\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00993\n",
      "Epoch 42/564\n",
      "281/281 [==============================] - 39s 138ms/step - loss: 0.0058 - val_loss: 0.0583\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00993\n",
      "Epoch 43/564\n",
      "281/281 [==============================] - 39s 140ms/step - loss: 0.0098 - val_loss: 0.0459\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00993\n",
      "Epoch 44/564\n",
      "281/281 [==============================] - 38s 136ms/step - loss: 0.0062 - val_loss: 0.0223\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00993\n",
      "Epoch 45/564\n",
      "281/281 [==============================] - 39s 138ms/step - loss: 0.0042 - val_loss: 0.0217\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00993\n",
      "Epoch 46/564\n",
      "281/281 [==============================] - 38s 137ms/step - loss: 0.0062 - val_loss: 0.0163\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00993\n",
      "Epoch 47/564\n",
      "281/281 [==============================] - 40s 142ms/step - loss: 0.0144 - val_loss: 0.0327\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00993\n",
      "Epoch 48/564\n",
      "281/281 [==============================] - 38s 135ms/step - loss: 0.0146 - val_loss: 0.0466\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00993\n",
      "Epoch 49/564\n",
      "281/281 [==============================] - 38s 134ms/step - loss: 0.0125 - val_loss: 0.0398\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00993\n",
      "Epoch 50/564\n",
      "281/281 [==============================] - 39s 138ms/step - loss: 0.0074 - val_loss: 0.0516\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00993\n",
      "Epoch 51/564\n",
      "281/281 [==============================] - 36s 130ms/step - loss: 0.0096 - val_loss: 0.0348\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00993\n",
      "Epoch 52/564\n",
      "281/281 [==============================] - 36s 130ms/step - loss: 0.0042 - val_loss: 0.0477\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00993\n",
      "Epoch 53/564\n",
      "281/281 [==============================] - 36s 130ms/step - loss: 0.0039 - val_loss: 0.0417\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00993\n",
      "Epoch 54/564\n",
      "281/281 [==============================] - 42s 151ms/step - loss: 0.0040 - val_loss: 0.0277\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00993\n",
      "Epoch 55/564\n",
      "281/281 [==============================] - 41s 145ms/step - loss: 0.0050 - val_loss: 0.0297\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00993\n",
      "Epoch 56/564\n",
      "281/281 [==============================] - 41s 148ms/step - loss: 0.0045 - val_loss: 0.0356\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.00993\n",
      "Epoch 57/564\n",
      "281/281 [==============================] - 39s 140ms/step - loss: 0.0061 - val_loss: 0.0425\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00993\n",
      "Epoch 58/564\n",
      "281/281 [==============================] - 42s 150ms/step - loss: 0.0044 - val_loss: 0.0342\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00993\n",
      "Epoch 59/564\n",
      "281/281 [==============================] - 40s 142ms/step - loss: 0.0060 - val_loss: 0.0878\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00993\n",
      "Epoch 60/564\n",
      "281/281 [==============================] - 39s 139ms/step - loss: 0.0046 - val_loss: 0.1061\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.00993\n",
      "Epoch 61/564\n",
      "281/281 [==============================] - 40s 143ms/step - loss: 0.0040 - val_loss: 0.0671\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.00993\n",
      "Epoch 62/564\n",
      "281/281 [==============================] - 41s 145ms/step - loss: 0.0044 - val_loss: 0.0613\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00993\n",
      "Epoch 63/564\n",
      "281/281 [==============================] - 41s 144ms/step - loss: 0.0043 - val_loss: 0.0521\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00993\n",
      "Epoch 64/564\n",
      "281/281 [==============================] - 42s 148ms/step - loss: 0.0037 - val_loss: 0.0445\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.00993\n",
      "Epoch 65/564\n",
      "281/281 [==============================] - 40s 141ms/step - loss: 0.0036 - val_loss: 0.0469\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.00993\n",
      "Epoch 66/564\n",
      "281/281 [==============================] - 41s 145ms/step - loss: 0.0040 - val_loss: 0.0292\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00993\n",
      "Epoch 67/564\n",
      "281/281 [==============================] - 40s 141ms/step - loss: 0.0046 - val_loss: 0.0247\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.00993\n",
      "Epoch 68/564\n",
      "281/281 [==============================] - 40s 144ms/step - loss: 0.0061 - val_loss: 0.0205\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00993\n",
      "Epoch 69/564\n",
      "281/281 [==============================] - 40s 143ms/step - loss: 0.0063 - val_loss: 0.0216\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00993\n",
      "Epoch 70/564\n",
      "281/281 [==============================] - 38s 135ms/step - loss: 0.0048 - val_loss: 0.0169\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.00993\n",
      "Epoch 71/564\n",
      "281/281 [==============================] - 40s 144ms/step - loss: 0.0076 - val_loss: 0.0156\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.00993\n",
      "Epoch 72/564\n",
      "281/281 [==============================] - 41s 147ms/step - loss: 0.0066 - val_loss: 0.0141\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.00993\n",
      "Epoch 73/564\n",
      "281/281 [==============================] - 39s 140ms/step - loss: 0.0113 - val_loss: 0.0156\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.00993\n",
      "Epoch 74/564\n",
      "281/281 [==============================] - 39s 139ms/step - loss: 0.0099 - val_loss: 0.0215\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.00993\n",
      "Epoch 75/564\n",
      "281/281 [==============================] - 41s 145ms/step - loss: 0.0057 - val_loss: 0.0328\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.00993\n",
      "Epoch 76/564\n",
      "281/281 [==============================] - 38s 136ms/step - loss: 0.0045 - val_loss: 0.0199\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.00993\n",
      "Epoch 77/564\n",
      "281/281 [==============================] - 39s 138ms/step - loss: 0.0045 - val_loss: 0.0494\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.00993\n",
      "Epoch 78/564\n",
      "281/281 [==============================] - 55s 195ms/step - loss: 0.0050 - val_loss: 0.0312\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.00993\n",
      "Epoch 79/564\n",
      "281/281 [==============================] - 41s 146ms/step - loss: 0.0074 - val_loss: 0.1537\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00993\n",
      "Epoch 80/564\n",
      "281/281 [==============================] - 38s 136ms/step - loss: 0.0060 - val_loss: 0.0295\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.00993\n",
      "Epoch 81/564\n",
      "281/281 [==============================] - 39s 139ms/step - loss: 0.0046 - val_loss: 0.0320\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.00993\n",
      "Epoch 82/564\n",
      "281/281 [==============================] - 41s 147ms/step - loss: 0.0035 - val_loss: 0.0285\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.00993\n",
      "Epoch 83/564\n",
      "281/281 [==============================] - 40s 142ms/step - loss: 0.0044 - val_loss: 0.0190\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.00993\n",
      "Epoch 84/564\n",
      "281/281 [==============================] - 42s 148ms/step - loss: 0.0047 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.00993\n",
      "Epoch 85/564\n",
      "281/281 [==============================] - 41s 145ms/step - loss: 0.0055 - val_loss: 0.0162\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.00993\n",
      "Epoch 86/564\n",
      "281/281 [==============================] - 40s 142ms/step - loss: 0.0041 - val_loss: 0.0145\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.00993\n",
      "Epoch 87/564\n",
      "281/281 [==============================] - 41s 145ms/step - loss: 0.0035 - val_loss: 0.0125\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.00993\n",
      "Epoch 88/564\n",
      "281/281 [==============================] - 39s 138ms/step - loss: 0.0034 - val_loss: 0.0173\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.00993\n",
      "Epoch 89/564\n",
      "281/281 [==============================] - 39s 138ms/step - loss: 0.0045 - val_loss: 0.0167\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.00993\n",
      "Epoch 90/564\n",
      "281/281 [==============================] - 38s 135ms/step - loss: 0.0034 - val_loss: 0.0278\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.00993\n",
      "Epoch 91/564\n",
      "281/281 [==============================] - 38s 134ms/step - loss: 0.0040 - val_loss: 0.0246\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.00993\n",
      "Epoch 92/564\n",
      "281/281 [==============================] - 39s 138ms/step - loss: 0.0045 - val_loss: 0.0219\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.00993\n",
      "Epoch 93/564\n",
      "281/281 [==============================] - 40s 143ms/step - loss: 0.0040 - val_loss: 0.0306\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.00993\n",
      "Epoch 94/564\n",
      "281/281 [==============================] - 43s 151ms/step - loss: 0.0036 - val_loss: 0.0266\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.00993\n",
      "Epoch 95/564\n",
      "281/281 [==============================] - 40s 141ms/step - loss: 0.0032 - val_loss: 0.0224\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.00993\n",
      "Epoch 96/564\n",
      "281/281 [==============================] - 38s 136ms/step - loss: 0.0048 - val_loss: 0.0329\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.00993\n",
      "Epoch 97/564\n",
      "281/281 [==============================] - 39s 140ms/step - loss: 0.0049 - val_loss: 0.0389\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.00993\n",
      "Epoch 98/564\n",
      "281/281 [==============================] - 39s 139ms/step - loss: 0.0057 - val_loss: 0.0358\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.00993\n",
      "Epoch 99/564\n",
      "281/281 [==============================] - 40s 144ms/step - loss: 0.0053 - val_loss: 0.0572\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.00993\n",
      "Epoch 100/564\n",
      "281/281 [==============================] - 39s 140ms/step - loss: 0.0040 - val_loss: 0.0521\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.00993\n",
      "Epoch 101/564\n",
      "281/281 [==============================] - 41s 145ms/step - loss: 0.0031 - val_loss: 0.0585\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.00993\n",
      "Epoch 102/564\n",
      "281/281 [==============================] - 47s 167ms/step - loss: 0.0037 - val_loss: 0.0575\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.00993\n",
      "Epoch 103/564\n",
      "281/281 [==============================] - 41s 147ms/step - loss: 0.0034 - val_loss: 0.0675\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.00993\n",
      "Epoch 104/564\n",
      "281/281 [==============================] - 39s 138ms/step - loss: 0.0033 - val_loss: 0.0710\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.00993\n",
      "Epoch 105/564\n",
      "281/281 [==============================] - 39s 137ms/step - loss: 0.0036 - val_loss: 0.0375\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.00993\n",
      "Epoch 106/564\n",
      "281/281 [==============================] - 43s 152ms/step - loss: 0.0045 - val_loss: 0.0336\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.00993\n",
      "Epoch 107/564\n",
      "281/281 [==============================] - 38s 137ms/step - loss: 0.0087 - val_loss: 0.0285\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.00993\n",
      "Epoch 108/564\n",
      "281/281 [==============================] - 39s 138ms/step - loss: 0.0092 - val_loss: 0.0244\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.00993\n",
      "Epoch 109/564\n",
      "281/281 [==============================] - 38s 137ms/step - loss: 0.0083 - val_loss: 0.0227\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.00993\n",
      "Epoch 110/564\n",
      "281/281 [==============================] - 41s 146ms/step - loss: 0.0063 - val_loss: 0.0225\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.00993\n",
      "Epoch 111/564\n",
      "281/281 [==============================] - 46s 165ms/step - loss: 0.0109 - val_loss: 0.0340\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.00993\n",
      "Epoch 112/564\n",
      "281/281 [==============================] - 47s 167ms/step - loss: 0.0052 - val_loss: 0.0484\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.00993\n",
      "Epoch 113/564\n",
      "281/281 [==============================] - 48s 171ms/step - loss: 0.0112 - val_loss: 0.0432\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.00993\n",
      "Epoch 114/564\n",
      "281/281 [==============================] - 44s 158ms/step - loss: 0.0080 - val_loss: 0.0407\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.00993\n",
      "Epoch 115/564\n",
      "281/281 [==============================] - 38s 135ms/step - loss: 0.0064 - val_loss: 0.0243\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.00993\n",
      "Epoch 116/564\n",
      "281/281 [==============================] - 39s 140ms/step - loss: 0.0062 - val_loss: 0.0339\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.00993\n",
      "Epoch 117/564\n",
      "281/281 [==============================] - 40s 143ms/step - loss: 0.0045 - val_loss: 0.4751\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.00993\n",
      "Epoch 118/564\n",
      "281/281 [==============================] - 39s 137ms/step - loss: 0.0042 - val_loss: 3.4865\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.00993\n",
      "Epoch 119/564\n",
      "281/281 [==============================] - 39s 140ms/step - loss: 0.0035 - val_loss: 0.1039\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.00993\n",
      "Epoch 120/564\n",
      "281/281 [==============================] - 39s 138ms/step - loss: 0.0030 - val_loss: 0.0770\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.00993\n",
      "Epoch 121/564\n",
      "281/281 [==============================] - 40s 143ms/step - loss: 0.0047 - val_loss: 0.2121\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.00993\n",
      "Epoch 122/564\n",
      "281/281 [==============================] - 39s 139ms/step - loss: 0.0046 - val_loss: 0.0630\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.00993\n",
      "Epoch 123/564\n",
      "281/281 [==============================] - 41s 145ms/step - loss: 0.0045 - val_loss: 0.0471\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.00993\n",
      "Epoch 124/564\n",
      "281/281 [==============================] - 43s 153ms/step - loss: 0.0037 - val_loss: 0.0502\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.00993\n",
      "Epoch 125/564\n",
      "281/281 [==============================] - 37s 132ms/step - loss: 0.0034 - val_loss: 0.0489\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.00993\n",
      "Epoch 126/564\n",
      "281/281 [==============================] - 43s 155ms/step - loss: 0.0041 - val_loss: 0.0529\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.00993\n",
      "Epoch 127/564\n",
      "281/281 [==============================] - 38s 136ms/step - loss: 0.0047 - val_loss: 0.0517\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.00993\n",
      "Epoch 128/564\n",
      "281/281 [==============================] - 39s 138ms/step - loss: 0.0052 - val_loss: 0.0492\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.00993\n",
      "Epoch 129/564\n",
      "281/281 [==============================] - 41s 144ms/step - loss: 0.0040 - val_loss: 1.9740\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.00993\n",
      "Epoch 130/564\n",
      "281/281 [==============================] - 44s 157ms/step - loss: 0.0037 - val_loss: 0.1779\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.00993\n",
      "Epoch 131/564\n",
      "281/281 [==============================] - 46s 164ms/step - loss: 0.0037 - val_loss: 0.0415\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.00993\n",
      "Epoch 132/564\n",
      "281/281 [==============================] - 44s 156ms/step - loss: 0.0038 - val_loss: 0.0374\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.00993\n",
      "Epoch 133/564\n",
      "281/281 [==============================] - 40s 144ms/step - loss: 0.0054 - val_loss: 0.0404\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.00993\n",
      "Epoch 134/564\n",
      "281/281 [==============================] - 41s 145ms/step - loss: 0.0064 - val_loss: 0.0528\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.00993\n",
      "Epoch 135/564\n",
      "281/281 [==============================] - 40s 143ms/step - loss: 0.0049 - val_loss: 0.0568\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.00993\n",
      "Epoch 136/564\n",
      "281/281 [==============================] - 42s 149ms/step - loss: 0.0061 - val_loss: 0.0353\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.00993\n",
      "Epoch 137/564\n",
      "281/281 [==============================] - 43s 151ms/step - loss: 0.0048 - val_loss: 0.0349\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.00993\n",
      "Epoch 138/564\n",
      "281/281 [==============================] - 36s 130ms/step - loss: 0.0048 - val_loss: 0.0552\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.00993\n",
      "Epoch 139/564\n",
      "281/281 [==============================] - 38s 134ms/step - loss: 0.0055 - val_loss: 0.0372\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.00993\n",
      "Epoch 140/564\n",
      "281/281 [==============================] - 37s 132ms/step - loss: 0.0060 - val_loss: 0.0539\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.00993\n",
      "Epoch 141/564\n",
      "281/281 [==============================] - 41s 145ms/step - loss: 0.0040 - val_loss: 0.0406\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.00993\n",
      "Epoch 142/564\n",
      "281/281 [==============================] - 46s 162ms/step - loss: 0.0034 - val_loss: 0.0520\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.00993\n",
      "Epoch 143/564\n",
      "281/281 [==============================] - 39s 140ms/step - loss: 0.0030 - val_loss: 0.0484\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.00993\n",
      "Epoch 144/564\n",
      "281/281 [==============================] - 43s 153ms/step - loss: 0.0032 - val_loss: 0.0428\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.00993\n",
      "Epoch 145/564\n",
      "281/281 [==============================] - 49s 175ms/step - loss: 0.0038 - val_loss: 0.0802\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.00993\n",
      "Epoch 146/564\n",
      "281/281 [==============================] - 49s 175ms/step - loss: 0.0041 - val_loss: 0.0483\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.00993\n",
      "Epoch 147/564\n",
      "281/281 [==============================] - 47s 166ms/step - loss: 0.0034 - val_loss: 0.0375\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.00993\n",
      "Epoch 148/564\n",
      "281/281 [==============================] - 50s 177ms/step - loss: 0.0037 - val_loss: 0.0390\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.00993\n",
      "Epoch 149/564\n",
      "281/281 [==============================] - 54s 194ms/step - loss: 0.0050 - val_loss: 0.0693\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.00993\n",
      "Epoch 150/564\n",
      "281/281 [==============================] - 59s 209ms/step - loss: 0.0076 - val_loss: 0.0610\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.00993\n",
      "Epoch 151/564\n",
      "281/281 [==============================] - 54s 193ms/step - loss: 0.0091 - val_loss: 0.0660\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.00993\n",
      "Epoch 152/564\n",
      "281/281 [==============================] - 60s 214ms/step - loss: 0.0097 - val_loss: 0.0503\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.00993\n",
      "Epoch 153/564\n",
      "281/281 [==============================] - 58s 205ms/step - loss: 0.0062 - val_loss: 0.0537\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.00993\n",
      "Epoch 154/564\n",
      "281/281 [==============================] - 59s 210ms/step - loss: 0.0040 - val_loss: 0.0562\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.00993\n",
      "Epoch 155/564\n",
      "281/281 [==============================] - 40s 141ms/step - loss: 0.0073 - val_loss: 0.0557\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.00993\n",
      "Epoch 156/564\n",
      "281/281 [==============================] - 40s 141ms/step - loss: 0.0083 - val_loss: 0.0659\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.00993\n",
      "Epoch 157/564\n",
      "281/281 [==============================] - 39s 139ms/step - loss: 0.0088 - val_loss: 0.0658\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.00993\n",
      "Epoch 158/564\n",
      "281/281 [==============================] - 40s 142ms/step - loss: 0.0083 - val_loss: 0.0807\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.00993\n",
      "Epoch 159/564\n",
      "281/281 [==============================] - 41s 145ms/step - loss: 0.0049 - val_loss: 0.0813\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.00993\n",
      "Epoch 160/564\n",
      "281/281 [==============================] - 37s 130ms/step - loss: 0.0060 - val_loss: 0.0456\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.00993\n",
      "Epoch 161/564\n",
      "281/281 [==============================] - 37s 131ms/step - loss: 0.0065 - val_loss: 0.0465\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.00993\n",
      "Epoch 162/564\n",
      "281/281 [==============================] - 38s 135ms/step - loss: 0.0053 - val_loss: 0.0424\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.00993\n",
      "Epoch 163/564\n",
      "281/281 [==============================] - 39s 141ms/step - loss: 0.0050 - val_loss: 0.0554\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.00993\n",
      "Epoch 164/564\n",
      "281/281 [==============================] - 39s 140ms/step - loss: 0.0051 - val_loss: 0.0560\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.00993\n",
      "Epoch 165/564\n",
      "281/281 [==============================] - 41s 145ms/step - loss: 0.0061 - val_loss: 0.0402\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.00993\n",
      "Epoch 166/564\n",
      "281/281 [==============================] - 42s 148ms/step - loss: 0.0063 - val_loss: 0.0199\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.00993\n",
      "Epoch 167/564\n",
      "281/281 [==============================] - 46s 162ms/step - loss: 0.0092 - val_loss: 0.0187\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.00993\n",
      "Epoch 168/564\n",
      "281/281 [==============================] - 43s 152ms/step - loss: 0.0077 - val_loss: 0.0254\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.00993\n",
      "Epoch 169/564\n",
      "281/281 [==============================] - 42s 148ms/step - loss: 0.0040 - val_loss: 0.0261\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.00993\n",
      "Epoch 170/564\n",
      "281/281 [==============================] - 43s 155ms/step - loss: 0.0062 - val_loss: 0.0255\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.00993\n",
      "Epoch 171/564\n",
      "281/281 [==============================] - 46s 163ms/step - loss: 0.0071 - val_loss: 0.0353\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.00993\n",
      "Epoch 172/564\n",
      "281/281 [==============================] - 40s 143ms/step - loss: 0.0070 - val_loss: 0.0396\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.00993\n",
      "Epoch 173/564\n",
      "281/281 [==============================] - 39s 139ms/step - loss: 0.0063 - val_loss: 0.0407\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.00993\n",
      "Epoch 174/564\n",
      "281/281 [==============================] - 43s 153ms/step - loss: 0.0064 - val_loss: 0.0218\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.00993\n",
      "Epoch 175/564\n",
      "281/281 [==============================] - 43s 155ms/step - loss: 0.0064 - val_loss: 0.0151\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.00993\n",
      "Epoch 176/564\n",
      "281/281 [==============================] - 60s 213ms/step - loss: 0.0042 - val_loss: 0.0185\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.00993\n",
      "Epoch 177/564\n",
      "281/281 [==============================] - 61s 215ms/step - loss: 0.0049 - val_loss: 0.0189\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.00993\n",
      "Epoch 178/564\n",
      "281/281 [==============================] - 60s 213ms/step - loss: 0.0060 - val_loss: 0.0245\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.00993\n",
      "Epoch 179/564\n",
      "281/281 [==============================] - 62s 220ms/step - loss: 0.0057 - val_loss: 0.0308\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.00993\n",
      "Epoch 180/564\n",
      "281/281 [==============================] - 56s 198ms/step - loss: 0.0059 - val_loss: 0.0316\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.00993\n",
      "Epoch 181/564\n",
      "281/281 [==============================] - 56s 200ms/step - loss: 0.0088 - val_loss: 0.0282\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.00993\n",
      "Epoch 182/564\n",
      "281/281 [==============================] - 51s 183ms/step - loss: 0.0094 - val_loss: 0.0327\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.00993\n",
      "Epoch 183/564\n",
      "281/281 [==============================] - 40s 142ms/step - loss: 0.0133 - val_loss: 0.0237\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.00993\n",
      "Epoch 184/564\n",
      "281/281 [==============================] - 43s 154ms/step - loss: 0.0054 - val_loss: 0.0265\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.00993\n",
      "Epoch 185/564\n",
      "281/281 [==============================] - 40s 143ms/step - loss: 0.0047 - val_loss: 0.0266\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.00993\n",
      "Epoch 186/564\n",
      "281/281 [==============================] - 38s 136ms/step - loss: 0.0059 - val_loss: 0.0409\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.00993\n",
      "Epoch 187/564\n",
      "281/281 [==============================] - 39s 140ms/step - loss: 0.0057 - val_loss: 0.0731\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.00993\n",
      "Epoch 188/564\n",
      "281/281 [==============================] - 37s 132ms/step - loss: 0.0051 - val_loss: 0.0921\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.00993\n",
      "Epoch 189/564\n",
      "281/281 [==============================] - 41s 145ms/step - loss: 0.0087 - val_loss: 0.0309\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.00993\n",
      "Epoch 190/564\n",
      "281/281 [==============================] - 39s 139ms/step - loss: 0.0042 - val_loss: 0.0411\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.00993\n",
      "Epoch 191/564\n",
      "281/281 [==============================] - 38s 135ms/step - loss: 0.0065 - val_loss: 0.0661\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.00993\n",
      "Epoch 192/564\n",
      "281/281 [==============================] - 39s 139ms/step - loss: 0.0068 - val_loss: 0.0277\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.00993\n",
      "Epoch 193/564\n",
      "281/281 [==============================] - 38s 136ms/step - loss: 0.0061 - val_loss: 0.0388\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.00993\n",
      "Epoch 194/564\n",
      "281/281 [==============================] - 38s 136ms/step - loss: 0.0045 - val_loss: 0.0496\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.00993\n",
      "Epoch 195/564\n",
      "281/281 [==============================] - 41s 145ms/step - loss: 0.0061 - val_loss: 0.0369\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.00993\n",
      "Epoch 196/564\n",
      "281/281 [==============================] - 39s 138ms/step - loss: 0.0099 - val_loss: 0.0339\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.00993\n",
      "Epoch 197/564\n",
      "281/281 [==============================] - 38s 134ms/step - loss: 0.0092 - val_loss: 0.0386\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.00993\n",
      "Epoch 198/564\n",
      "281/281 [==============================] - 43s 151ms/step - loss: 0.0052 - val_loss: 0.0279\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.00993\n",
      "Epoch 199/564\n",
      "281/281 [==============================] - 38s 136ms/step - loss: 0.0071 - val_loss: 0.0675\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.00993\n",
      "Epoch 200/564\n",
      "281/281 [==============================] - 40s 143ms/step - loss: 0.0063 - val_loss: 0.0260\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.00993\n",
      "Epoch 201/564\n",
      "281/281 [==============================] - 40s 142ms/step - loss: 0.0052 - val_loss: 0.0260\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.00993\n",
      "Epoch 202/564\n",
      "281/281 [==============================] - 41s 145ms/step - loss: 0.0040 - val_loss: 0.0269\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.00993\n",
      "Epoch 203/564\n",
      "281/281 [==============================] - 43s 153ms/step - loss: 0.0047 - val_loss: 0.0249\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.00993\n",
      "Epoch 204/564\n",
      "281/281 [==============================] - 38s 136ms/step - loss: 0.0039 - val_loss: 0.0269\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.00993\n",
      "Epoch 205/564\n",
      "281/281 [==============================] - 38s 136ms/step - loss: 0.0039 - val_loss: 0.0250\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.00993\n",
      "Epoch 206/564\n",
      "281/281 [==============================] - 39s 138ms/step - loss: 0.0036 - val_loss: 0.0327\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.00993\n",
      "Epoch 207/564\n",
      "281/281 [==============================] - 46s 165ms/step - loss: 0.0041 - val_loss: 0.0326\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.00993\n",
      "Epoch 208/564\n",
      "281/281 [==============================] - 46s 163ms/step - loss: 0.0034 - val_loss: 0.0392\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.00993\n",
      "Epoch 209/564\n",
      "281/281 [==============================] - 51s 183ms/step - loss: 0.0039 - val_loss: 0.0453\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.00993\n",
      "Epoch 210/564\n",
      "281/281 [==============================] - 67s 237ms/step - loss: 0.0041 - val_loss: 0.0489\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.00993\n",
      "Epoch 211/564\n",
      "281/281 [==============================] - 64s 228ms/step - loss: 0.0046 - val_loss: 0.0411\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.00993\n",
      "Epoch 212/564\n",
      "281/281 [==============================] - 62s 220ms/step - loss: 0.0052 - val_loss: 0.0498\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.00993\n",
      "Epoch 213/564\n",
      "281/281 [==============================] - 62s 222ms/step - loss: 0.0049 - val_loss: 0.0338\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.00993\n",
      "Epoch 214/564\n",
      "281/281 [==============================] - 53s 187ms/step - loss: 0.0067 - val_loss: 0.0426\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.00993\n",
      "Epoch 215/564\n",
      "281/281 [==============================] - 41s 147ms/step - loss: 0.0072 - val_loss: 0.0466\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.00993\n",
      "Epoch 216/564\n",
      "281/281 [==============================] - 44s 157ms/step - loss: 0.0048 - val_loss: 0.0487\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.00993\n",
      "Epoch 217/564\n",
      "281/281 [==============================] - 53s 188ms/step - loss: 0.0061 - val_loss: 0.0546\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.00993\n",
      "Epoch 218/564\n",
      "281/281 [==============================] - 56s 200ms/step - loss: 0.0139 - val_loss: 0.0463\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.00993\n",
      "Epoch 219/564\n",
      "281/281 [==============================] - 61s 216ms/step - loss: 0.0047 - val_loss: 0.0517\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.00993\n",
      "Epoch 220/564\n",
      "281/281 [==============================] - 55s 195ms/step - loss: 0.0055 - val_loss: 0.0420\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.00993\n",
      "Epoch 221/564\n",
      "281/281 [==============================] - 41s 147ms/step - loss: 0.0050 - val_loss: 0.0428\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.00993\n",
      "Epoch 222/564\n",
      "281/281 [==============================] - 40s 143ms/step - loss: 0.0036 - val_loss: 0.0420\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.00993\n",
      "Epoch 223/564\n",
      "281/281 [==============================] - 40s 142ms/step - loss: 0.0040 - val_loss: 0.0479\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.00993\n",
      "Epoch 224/564\n",
      "281/281 [==============================] - 50s 177ms/step - loss: 0.0060 - val_loss: 0.0552\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.00993\n",
      "Epoch 225/564\n",
      "281/281 [==============================] - 41s 145ms/step - loss: 0.0054 - val_loss: 0.0533\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.00993\n",
      "Epoch 226/564\n",
      "281/281 [==============================] - 39s 140ms/step - loss: 0.0081 - val_loss: 0.0435\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.00993\n",
      "Epoch 227/564\n",
      "281/281 [==============================] - 40s 143ms/step - loss: 0.0061 - val_loss: 0.0398\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.00993\n",
      "Epoch 228/564\n",
      "281/281 [==============================] - 40s 144ms/step - loss: 0.0070 - val_loss: 0.0465\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.00993\n",
      "Epoch 229/564\n",
      "281/281 [==============================] - 42s 149ms/step - loss: 0.0052 - val_loss: 0.0331\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.00993\n",
      "Epoch 230/564\n",
      "281/281 [==============================] - 40s 142ms/step - loss: 0.0044 - val_loss: 0.0302\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.00993\n",
      "Epoch 231/564\n",
      "281/281 [==============================] - 43s 153ms/step - loss: 0.0050 - val_loss: 0.0360\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.00993\n",
      "Epoch 232/564\n",
      "281/281 [==============================] - 43s 154ms/step - loss: 0.0036 - val_loss: 0.0462\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.00993\n",
      "Epoch 233/564\n",
      "281/281 [==============================] - 43s 154ms/step - loss: 0.0047 - val_loss: 0.0378\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.00993\n",
      "Epoch 234/564\n",
      "281/281 [==============================] - 37s 133ms/step - loss: 0.0050 - val_loss: 0.0242\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.00993\n",
      "Epoch 235/564\n",
      "281/281 [==============================] - 39s 139ms/step - loss: 0.0062 - val_loss: 0.0246\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.00993\n",
      "Epoch 236/564\n",
      "281/281 [==============================] - 43s 153ms/step - loss: 0.0058 - val_loss: 0.0197\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.00993\n",
      "Epoch 237/564\n",
      "281/281 [==============================] - 40s 143ms/step - loss: 0.0054 - val_loss: 0.0196\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.00993\n",
      "Epoch 238/564\n",
      "281/281 [==============================] - 39s 139ms/step - loss: 0.0056 - val_loss: 0.0191\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.00993\n",
      "Epoch 239/564\n",
      "281/281 [==============================] - 42s 148ms/step - loss: 0.0048 - val_loss: 0.0160\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.00993\n",
      "Epoch 240/564\n",
      "281/281 [==============================] - 54s 194ms/step - loss: 0.0051 - val_loss: 0.0184\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.00993\n",
      "Epoch 241/564\n",
      "281/281 [==============================] - 54s 192ms/step - loss: 0.0056 - val_loss: 0.0151\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.00993\n",
      "Epoch 242/564\n",
      "281/281 [==============================] - 48s 171ms/step - loss: 0.0077 - val_loss: 0.0196\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.00993\n",
      "Epoch 243/564\n",
      "281/281 [==============================] - 42s 151ms/step - loss: 0.0080 - val_loss: 0.0393\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.00993\n",
      "Epoch 244/564\n",
      "281/281 [==============================] - 40s 144ms/step - loss: 0.0076 - val_loss: 0.0322\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.00993\n",
      "Epoch 245/564\n",
      "281/281 [==============================] - 45s 161ms/step - loss: 0.0317 - val_loss: 0.1033\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.00993\n",
      "Epoch 246/564\n",
      "281/281 [==============================] - 45s 160ms/step - loss: 0.0171 - val_loss: 0.1385\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.00993\n",
      "Epoch 247/564\n",
      "281/281 [==============================] - 49s 175ms/step - loss: 0.0127 - val_loss: 0.1362\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.00993\n",
      "Epoch 248/564\n",
      "281/281 [==============================] - 56s 198ms/step - loss: 0.0121 - val_loss: 0.1381\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.00993\n",
      "Epoch 249/564\n",
      "281/281 [==============================] - 61s 216ms/step - loss: 0.0046 - val_loss: 0.0979\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.00993\n",
      "Epoch 250/564\n",
      "281/281 [==============================] - 52s 186ms/step - loss: 0.0039 - val_loss: 0.0810\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.00993\n",
      "Epoch 251/564\n",
      "281/281 [==============================] - 47s 167ms/step - loss: 0.0069 - val_loss: 0.0487\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.00993\n",
      "Epoch 252/564\n",
      "281/281 [==============================] - 46s 163ms/step - loss: 0.0071 - val_loss: 0.0533\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.00993\n",
      "Epoch 253/564\n",
      "281/281 [==============================] - 38s 136ms/step - loss: 0.0055 - val_loss: 0.0569\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.00993\n",
      "Epoch 254/564\n",
      "281/281 [==============================] - 44s 158ms/step - loss: 0.0098 - val_loss: 0.0607\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.00993\n",
      "Epoch 255/564\n",
      "281/281 [==============================] - 45s 159ms/step - loss: 0.0068 - val_loss: 0.0592\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.00993\n",
      "Epoch 256/564\n",
      "281/281 [==============================] - 50s 178ms/step - loss: 0.0076 - val_loss: 0.0528\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.00993\n",
      "Epoch 257/564\n",
      "281/281 [==============================] - 53s 189ms/step - loss: 0.0074 - val_loss: 0.0470\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.00993\n",
      "Epoch 258/564\n",
      "281/281 [==============================] - 62s 221ms/step - loss: 0.0061 - val_loss: 0.0479\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.00993\n",
      "Epoch 259/564\n",
      "281/281 [==============================] - 53s 189ms/step - loss: 0.0057 - val_loss: 0.0611\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.00993\n",
      "Epoch 260/564\n",
      "281/281 [==============================] - 45s 160ms/step - loss: 0.0041 - val_loss: 0.0658\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.00993\n",
      "Epoch 261/564\n",
      "281/281 [==============================] - 41s 146ms/step - loss: 0.0034 - val_loss: 0.0627\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.00993\n",
      "Epoch 262/564\n",
      "281/281 [==============================] - 41s 147ms/step - loss: 0.0060 - val_loss: 0.0717\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.00993\n",
      "Epoch 263/564\n",
      "281/281 [==============================] - 42s 150ms/step - loss: 0.0072 - val_loss: 0.0700\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.00993\n",
      "Epoch 264/564\n",
      "281/281 [==============================] - 49s 175ms/step - loss: 0.0086 - val_loss: 0.0735\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.00993\n",
      "Epoch 265/564\n",
      "281/281 [==============================] - 48s 171ms/step - loss: 0.0088 - val_loss: 0.0761\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.00993\n",
      "Epoch 266/564\n",
      "281/281 [==============================] - 52s 185ms/step - loss: 0.0096 - val_loss: 0.0440\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.00993\n",
      "Epoch 267/564\n",
      "281/281 [==============================] - 52s 185ms/step - loss: 0.0072 - val_loss: 0.0433\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.00993\n",
      "Epoch 268/564\n",
      "281/281 [==============================] - 42s 149ms/step - loss: 0.0065 - val_loss: 0.0477\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.00993\n",
      "Epoch 269/564\n",
      "281/281 [==============================] - 48s 170ms/step - loss: 0.0046 - val_loss: 0.0442\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.00993\n",
      "Epoch 270/564\n",
      "281/281 [==============================] - 46s 164ms/step - loss: 0.0045 - val_loss: 0.1730\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.00993\n",
      "Epoch 271/564\n",
      "281/281 [==============================] - 61s 216ms/step - loss: 0.0044 - val_loss: 0.0777\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.00993\n",
      "Epoch 272/564\n",
      "281/281 [==============================] - 61s 219ms/step - loss: 0.0054 - val_loss: 0.0379\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.00993\n",
      "Epoch 273/564\n",
      "281/281 [==============================] - 46s 165ms/step - loss: 0.0055 - val_loss: 0.0542\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.00993\n",
      "Epoch 274/564\n",
      "281/281 [==============================] - 56s 199ms/step - loss: 0.0053 - val_loss: 0.0602\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.00993\n",
      "Epoch 275/564\n",
      "281/281 [==============================] - 58s 206ms/step - loss: 0.0048 - val_loss: 0.0443\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.00993\n",
      "Epoch 276/564\n",
      "281/281 [==============================] - 42s 150ms/step - loss: 0.0037 - val_loss: 0.0536\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.00993\n",
      "Epoch 277/564\n",
      "281/281 [==============================] - 41s 145ms/step - loss: 0.0034 - val_loss: 0.0389\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.00993\n",
      "Epoch 278/564\n",
      "281/281 [==============================] - 41s 146ms/step - loss: 0.0033 - val_loss: 0.0330\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.00993\n",
      "Epoch 279/564\n",
      "281/281 [==============================] - 44s 158ms/step - loss: 0.0051 - val_loss: 0.0382\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.00993\n",
      "Epoch 280/564\n",
      "281/281 [==============================] - 37s 133ms/step - loss: 0.0044 - val_loss: 0.0499\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.00993\n",
      "Epoch 281/564\n",
      "281/281 [==============================] - 40s 141ms/step - loss: 0.0048 - val_loss: 0.0438\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.00993\n",
      "Epoch 282/564\n",
      "281/281 [==============================] - 47s 168ms/step - loss: 0.0093 - val_loss: 0.0458\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.00993\n",
      "Epoch 283/564\n",
      "281/281 [==============================] - 48s 170ms/step - loss: 0.0123 - val_loss: 0.0361\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.00993\n",
      "Epoch 284/564\n",
      "281/281 [==============================] - 44s 156ms/step - loss: 0.0094 - val_loss: 0.0364\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.00993\n",
      "Epoch 285/564\n",
      "281/281 [==============================] - 42s 149ms/step - loss: 0.0108 - val_loss: 0.0321\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.00993\n",
      "Epoch 286/564\n",
      "281/281 [==============================] - 44s 158ms/step - loss: 0.0136 - val_loss: 0.0695\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.00993\n",
      "Epoch 287/564\n",
      "281/281 [==============================] - 53s 189ms/step - loss: 0.0101 - val_loss: 0.0714\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.00993\n",
      "Epoch 288/564\n",
      "281/281 [==============================] - 62s 219ms/step - loss: 0.0106 - val_loss: 0.0618\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.00993\n",
      "Epoch 289/564\n",
      "281/281 [==============================] - 57s 204ms/step - loss: 0.0074 - val_loss: 0.0728\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.00993\n",
      "Epoch 290/564\n",
      "281/281 [==============================] - 53s 189ms/step - loss: 0.0051 - val_loss: 0.0802\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.00993\n",
      "Epoch 291/564\n",
      "281/281 [==============================] - 62s 220ms/step - loss: 0.0042 - val_loss: 0.0713\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.00993\n",
      "Epoch 292/564\n",
      "281/281 [==============================] - 60s 214ms/step - loss: 0.0048 - val_loss: 0.0828\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.00993\n",
      "Epoch 293/564\n",
      "281/281 [==============================] - 59s 211ms/step - loss: 0.0043 - val_loss: 0.0977\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.00993\n",
      "Epoch 294/564\n",
      "281/281 [==============================] - 40s 142ms/step - loss: 0.0042 - val_loss: 0.0746\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.00993\n",
      "Epoch 295/564\n",
      "281/281 [==============================] - 39s 139ms/step - loss: 0.0042 - val_loss: 0.0524\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.00993\n",
      "Epoch 296/564\n",
      "281/281 [==============================] - 41s 145ms/step - loss: 0.0055 - val_loss: 0.0460\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.00993\n",
      "Epoch 297/564\n",
      "281/281 [==============================] - 42s 150ms/step - loss: 0.0062 - val_loss: 0.0218\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.00993\n",
      "Epoch 298/564\n",
      "281/281 [==============================] - 46s 165ms/step - loss: 0.0093 - val_loss: 0.0243\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.00993\n",
      "Epoch 299/564\n",
      "281/281 [==============================] - 49s 173ms/step - loss: 0.0101 - val_loss: 0.0308\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.00993\n",
      "Epoch 300/564\n",
      "281/281 [==============================] - 49s 173ms/step - loss: 0.0082 - val_loss: 0.0341\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.00993\n",
      "Epoch 301/564\n",
      "281/281 [==============================] - 61s 217ms/step - loss: 0.0064 - val_loss: 0.0355\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.00993\n",
      "Epoch 302/564\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.0047 - val_loss: 0.0285\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.00993\n",
      "Epoch 303/564\n",
      "281/281 [==============================] - 56s 200ms/step - loss: 0.0035 - val_loss: 0.0326\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.00993\n",
      "Epoch 304/564\n",
      "281/281 [==============================] - 53s 188ms/step - loss: 0.0034 - val_loss: 0.0352\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.00993\n",
      "Epoch 305/564\n",
      "281/281 [==============================] - 56s 198ms/step - loss: 0.0042 - val_loss: 0.0267\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.00993\n",
      "Epoch 306/564\n",
      "281/281 [==============================] - 40s 143ms/step - loss: 0.0076 - val_loss: 0.0341\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.00993\n",
      "Epoch 307/564\n",
      "281/281 [==============================] - 40s 143ms/step - loss: 0.0068 - val_loss: 0.0667\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.00993\n",
      "Epoch 308/564\n",
      "281/281 [==============================] - 43s 152ms/step - loss: 0.0062 - val_loss: 0.0448\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.00993\n",
      "Epoch 309/564\n",
      "281/281 [==============================] - 40s 144ms/step - loss: 0.0063 - val_loss: 0.0557\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.00993\n",
      "Epoch 310/564\n",
      "281/281 [==============================] - 43s 151ms/step - loss: 0.0062 - val_loss: 0.0905\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.00993\n",
      "Epoch 311/564\n",
      "281/281 [==============================] - 51s 180ms/step - loss: 0.0054 - val_loss: 0.0799\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.00993\n",
      "Epoch 312/564\n",
      "281/281 [==============================] - 54s 191ms/step - loss: 0.0106 - val_loss: 0.0669\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.00993\n",
      "Epoch 313/564\n",
      "281/281 [==============================] - 60s 215ms/step - loss: 0.0060 - val_loss: 0.0916\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.00993\n",
      "Epoch 314/564\n",
      "281/281 [==============================] - 52s 186ms/step - loss: 0.0066 - val_loss: 0.0216\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.00993\n",
      "Epoch 315/564\n",
      "281/281 [==============================] - 57s 203ms/step - loss: 0.0090 - val_loss: 0.0329\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.00993\n",
      "Epoch 316/564\n",
      "281/281 [==============================] - 45s 161ms/step - loss: 0.0089 - val_loss: 0.0431\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.00993\n",
      "Epoch 317/564\n",
      "281/281 [==============================] - 50s 180ms/step - loss: 0.0078 - val_loss: 0.0287\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.00993\n",
      "Epoch 318/564\n",
      "281/281 [==============================] - 59s 211ms/step - loss: 0.0079 - val_loss: 0.0303\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.00993\n",
      "Epoch 319/564\n",
      "281/281 [==============================] - 42s 150ms/step - loss: 0.0080 - val_loss: 0.0371\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.00993\n",
      "Epoch 320/564\n",
      "281/281 [==============================] - 42s 150ms/step - loss: 0.0088 - val_loss: 0.0267\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.00993\n",
      "Epoch 321/564\n",
      "281/281 [==============================] - 43s 154ms/step - loss: 0.0059 - val_loss: 0.0437\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.00993\n",
      "Epoch 322/564\n",
      "281/281 [==============================] - 42s 150ms/step - loss: 0.0049 - val_loss: 0.0447\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.00993\n",
      "Epoch 323/564\n",
      "281/281 [==============================] - 41s 145ms/step - loss: 0.0046 - val_loss: 0.0420\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.00993\n",
      "Epoch 324/564\n",
      "281/281 [==============================] - 51s 180ms/step - loss: 0.0047 - val_loss: 0.0437\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.00993\n",
      "Epoch 325/564\n",
      "281/281 [==============================] - 44s 155ms/step - loss: 0.0061 - val_loss: 0.0319\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.00993\n",
      "Epoch 326/564\n",
      "281/281 [==============================] - 49s 173ms/step - loss: 0.0050 - val_loss: 0.0275\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.00993\n",
      "Epoch 327/564\n",
      "281/281 [==============================] - 44s 156ms/step - loss: 0.0044 - val_loss: 0.0250\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.00993\n",
      "Epoch 328/564\n",
      "281/281 [==============================] - 45s 161ms/step - loss: 0.0042 - val_loss: 0.0293\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.00993\n",
      "Epoch 329/564\n",
      "281/281 [==============================] - 48s 173ms/step - loss: 0.0079 - val_loss: 0.0374\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.00993\n",
      "Epoch 330/564\n",
      "281/281 [==============================] - 65s 230ms/step - loss: 0.0084 - val_loss: 0.0506\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.00993\n",
      "Epoch 331/564\n",
      "281/281 [==============================] - 53s 189ms/step - loss: 0.0081 - val_loss: 0.4099\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.00993\n",
      "Epoch 332/564\n",
      "281/281 [==============================] - 47s 166ms/step - loss: 0.0074 - val_loss: 0.0578\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.00993\n",
      "Epoch 333/564\n",
      "281/281 [==============================] - 64s 226ms/step - loss: 0.0063 - val_loss: 0.0334\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.00993\n",
      "Epoch 334/564\n",
      "281/281 [==============================] - 55s 196ms/step - loss: 0.0111 - val_loss: 0.1964\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.00993\n",
      "Epoch 335/564\n",
      "281/281 [==============================] - 42s 149ms/step - loss: 0.0088 - val_loss: 0.4660\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.00993\n",
      "Epoch 336/564\n",
      "281/281 [==============================] - 46s 165ms/step - loss: 0.0102 - val_loss: 0.7731\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.00993\n",
      "Epoch 337/564\n",
      "281/281 [==============================] - 55s 197ms/step - loss: 0.0143 - val_loss: 0.2158\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.00993\n",
      "Epoch 338/564\n",
      "281/281 [==============================] - 64s 227ms/step - loss: 0.0176 - val_loss: 0.1636\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.00993\n",
      "Epoch 339/564\n",
      "281/281 [==============================] - 63s 223ms/step - loss: 0.0153 - val_loss: 0.1076\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.00993\n",
      "Epoch 340/564\n",
      "281/281 [==============================] - 51s 183ms/step - loss: 0.0127 - val_loss: 0.2652\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.00993\n",
      "Epoch 341/564\n",
      "281/281 [==============================] - 43s 154ms/step - loss: 0.0073 - val_loss: 0.4822\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.00993\n",
      "Epoch 342/564\n",
      "281/281 [==============================] - 47s 166ms/step - loss: 0.0113 - val_loss: 0.8586\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.00993\n",
      "Epoch 343/564\n",
      "281/281 [==============================] - 53s 190ms/step - loss: 0.0068 - val_loss: 1.1362\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.00993\n",
      "Epoch 344/564\n",
      "281/281 [==============================] - 48s 170ms/step - loss: 0.0074 - val_loss: 0.8861\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.00993\n",
      "Epoch 345/564\n",
      "281/281 [==============================] - 44s 156ms/step - loss: 0.0079 - val_loss: 0.5285\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.00993\n",
      "Epoch 346/564\n",
      "281/281 [==============================] - 37s 133ms/step - loss: 0.0147 - val_loss: 0.0978\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.00993\n",
      "Epoch 347/564\n",
      "281/281 [==============================] - 38s 134ms/step - loss: 0.0137 - val_loss: 0.0457\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.00993\n",
      "Epoch 348/564\n",
      "281/281 [==============================] - 37s 133ms/step - loss: 0.0140 - val_loss: 0.0368\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.00993\n",
      "Epoch 349/564\n",
      "281/281 [==============================] - 39s 140ms/step - loss: 0.0188 - val_loss: 0.0397\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.00993\n",
      "Epoch 350/564\n",
      "281/281 [==============================] - 39s 139ms/step - loss: 0.0131 - val_loss: 0.0570\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.00993\n",
      "Epoch 351/564\n",
      "281/281 [==============================] - 41s 146ms/step - loss: 0.0104 - val_loss: 0.0455\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.00993\n",
      "Epoch 352/564\n",
      "281/281 [==============================] - 37s 133ms/step - loss: 0.0132 - val_loss: 0.0533\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.00993\n",
      "Epoch 353/564\n",
      "281/281 [==============================] - 44s 158ms/step - loss: 0.0136 - val_loss: 0.2038\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.00993\n",
      "Epoch 354/564\n",
      "281/281 [==============================] - 38s 134ms/step - loss: 0.0381 - val_loss: 0.0528\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.00993\n",
      "Epoch 355/564\n",
      "281/281 [==============================] - 39s 140ms/step - loss: 0.0250 - val_loss: 0.0540\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.00993\n",
      "Epoch 356/564\n",
      "281/281 [==============================] - 43s 154ms/step - loss: 0.0205 - val_loss: 0.0953\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.00993\n",
      "Epoch 357/564\n",
      "281/281 [==============================] - 42s 149ms/step - loss: 0.0144 - val_loss: 0.0892\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.00993\n",
      "Epoch 358/564\n",
      "281/281 [==============================] - 47s 168ms/step - loss: 0.0117 - val_loss: 0.0610\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.00993\n",
      "Epoch 359/564\n",
      "281/281 [==============================] - 45s 158ms/step - loss: 0.0140 - val_loss: 0.0520\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.00993\n",
      "Epoch 360/564\n",
      "281/281 [==============================] - 42s 150ms/step - loss: 0.0105 - val_loss: 0.0519\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.00993\n",
      "Epoch 361/564\n",
      "281/281 [==============================] - 44s 158ms/step - loss: 0.0105 - val_loss: 0.0477\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.00993\n",
      "Epoch 362/564\n",
      "281/281 [==============================] - 59s 210ms/step - loss: 0.0088 - val_loss: 0.0325\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.00993\n",
      "Epoch 363/564\n",
      "281/281 [==============================] - 61s 219ms/step - loss: 0.0063 - val_loss: 0.0321\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.00993\n",
      "Epoch 364/564\n",
      "281/281 [==============================] - 61s 217ms/step - loss: 0.0060 - val_loss: 0.0374\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.00993\n",
      "Epoch 365/564\n",
      "281/281 [==============================] - 56s 201ms/step - loss: 0.0046 - val_loss: 0.0353\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.00993\n",
      "Epoch 366/564\n",
      "281/281 [==============================] - 56s 199ms/step - loss: 0.0061 - val_loss: 0.0571\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.00993\n",
      "Epoch 367/564\n",
      "281/281 [==============================] - 55s 194ms/step - loss: 0.0071 - val_loss: 0.0667\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.00993\n",
      "Epoch 368/564\n",
      "281/281 [==============================] - 53s 190ms/step - loss: 0.0070 - val_loss: 0.0606\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.00993\n",
      "Epoch 369/564\n",
      "281/281 [==============================] - 52s 186ms/step - loss: 0.0083 - val_loss: 0.0577\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.00993\n",
      "Epoch 370/564\n",
      "281/281 [==============================] - 39s 140ms/step - loss: 0.0096 - val_loss: 0.0514\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.00993\n",
      "Epoch 371/564\n",
      "281/281 [==============================] - 43s 155ms/step - loss: 0.0100 - val_loss: 0.0393\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.00993\n",
      "Epoch 372/564\n",
      "281/281 [==============================] - 41s 146ms/step - loss: 0.0094 - val_loss: 0.0283\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.00993\n",
      "Epoch 373/564\n",
      "281/281 [==============================] - 38s 137ms/step - loss: 0.0104 - val_loss: 0.0399\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.00993\n",
      "Epoch 374/564\n",
      "281/281 [==============================] - 44s 156ms/step - loss: 0.0085 - val_loss: 0.0263\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.00993\n",
      "Epoch 375/564\n",
      "281/281 [==============================] - 49s 174ms/step - loss: 0.0088 - val_loss: 0.0478\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.00993\n",
      "Epoch 376/564\n",
      "281/281 [==============================] - 46s 162ms/step - loss: 0.0068 - val_loss: 0.0290\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.00993\n",
      "Epoch 377/564\n",
      "281/281 [==============================] - 48s 170ms/step - loss: 0.0052 - val_loss: 0.0325\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.00993\n",
      "Epoch 378/564\n",
      "281/281 [==============================] - 62s 219ms/step - loss: 0.0070 - val_loss: 0.0305\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.00993\n",
      "Epoch 379/564\n",
      "281/281 [==============================] - 60s 215ms/step - loss: 0.0082 - val_loss: 0.0280\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.00993\n",
      "Epoch 380/564\n",
      "281/281 [==============================] - 59s 209ms/step - loss: 0.0081 - val_loss: 0.0202\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.00993\n",
      "Epoch 381/564\n",
      "281/281 [==============================] - 55s 195ms/step - loss: 0.0099 - val_loss: 0.0219\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.00993\n",
      "Epoch 382/564\n",
      "281/281 [==============================] - 38s 135ms/step - loss: 0.0125 - val_loss: 0.0222\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.00993\n",
      "Epoch 383/564\n",
      "281/281 [==============================] - 39s 140ms/step - loss: 0.0111 - val_loss: 0.0261\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.00993\n",
      "Epoch 384/564\n",
      "281/281 [==============================] - 41s 147ms/step - loss: 0.0211 - val_loss: 0.0282\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.00993\n",
      "Epoch 385/564\n",
      "281/281 [==============================] - 40s 144ms/step - loss: 0.0207 - val_loss: 0.0323\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.00993\n",
      "Epoch 386/564\n",
      "281/281 [==============================] - 40s 143ms/step - loss: 0.0193 - val_loss: 0.0474\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.00993\n",
      "Epoch 387/564\n",
      "281/281 [==============================] - 39s 138ms/step - loss: 0.0235 - val_loss: 0.0401\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.00993\n",
      "Epoch 388/564\n",
      "281/281 [==============================] - 41s 147ms/step - loss: 0.0177 - val_loss: 0.0430\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.00993\n",
      "Epoch 389/564\n",
      "281/281 [==============================] - 42s 149ms/step - loss: 0.0135 - val_loss: 0.0375\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.00993\n",
      "Epoch 390/564\n",
      "281/281 [==============================] - 42s 149ms/step - loss: 0.0111 - val_loss: 0.0429\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.00993\n",
      "Epoch 391/564\n",
      "281/281 [==============================] - 44s 156ms/step - loss: 0.0089 - val_loss: 0.0731\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.00993\n",
      "Epoch 392/564\n",
      "281/281 [==============================] - 45s 161ms/step - loss: 0.0078 - val_loss: 0.0675\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.00993\n",
      "Epoch 393/564\n",
      "281/281 [==============================] - 51s 181ms/step - loss: 0.0069 - val_loss: 0.0691\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.00993\n",
      "Epoch 394/564\n",
      "281/281 [==============================] - 60s 215ms/step - loss: 0.0158 - val_loss: 0.0859\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.00993\n",
      "Epoch 395/564\n",
      "281/281 [==============================] - 61s 217ms/step - loss: 0.0087 - val_loss: 0.0988\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.00993\n",
      "Epoch 396/564\n",
      "281/281 [==============================] - 63s 223ms/step - loss: 0.0107 - val_loss: 0.0420\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.00993\n",
      "Epoch 397/564\n",
      "281/281 [==============================] - 61s 217ms/step - loss: 0.0089 - val_loss: 0.0257\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.00993\n",
      "Epoch 398/564\n",
      "281/281 [==============================] - 59s 210ms/step - loss: 0.0107 - val_loss: 0.0520\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.00993\n",
      "Epoch 399/564\n",
      "281/281 [==============================] - 59s 211ms/step - loss: 0.0126 - val_loss: 0.0476\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.00993\n",
      "Epoch 400/564\n",
      "281/281 [==============================] - 54s 191ms/step - loss: 0.0080 - val_loss: 0.0314\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.00993\n",
      "Epoch 401/564\n",
      "281/281 [==============================] - 40s 142ms/step - loss: 0.0277 - val_loss: 0.0930\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.00993\n",
      "Epoch 402/564\n",
      "281/281 [==============================] - 37s 132ms/step - loss: 0.0181 - val_loss: 0.2081\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.00993\n",
      "Epoch 403/564\n",
      "281/281 [==============================] - 39s 140ms/step - loss: 0.0131 - val_loss: 0.0632\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.00993\n",
      "Epoch 404/564\n",
      "281/281 [==============================] - 29s 103ms/step - loss: 0.0126 - val_loss: 0.0688\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.00993\n",
      "Epoch 405/564\n",
      "281/281 [==============================] - 38s 134ms/step - loss: 0.0083 - val_loss: 0.0390\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.00993\n",
      "Epoch 406/564\n",
      "281/281 [==============================] - 32s 115ms/step - loss: 0.0135 - val_loss: 0.0322\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.00993\n",
      "Epoch 407/564\n",
      "281/281 [==============================] - 32s 114ms/step - loss: 0.0122 - val_loss: 0.0465\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.00993\n",
      "Epoch 408/564\n",
      "281/281 [==============================] - 32s 114ms/step - loss: 0.0105 - val_loss: 0.0298\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.00993\n",
      "Epoch 409/564\n",
      "281/281 [==============================] - 33s 117ms/step - loss: 0.0152 - val_loss: 0.0237\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.00993\n",
      "Epoch 410/564\n",
      "281/281 [==============================] - 32s 116ms/step - loss: 0.0175 - val_loss: 0.0697\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.00993\n",
      "Epoch 411/564\n",
      "281/281 [==============================] - 32s 115ms/step - loss: 0.0166 - val_loss: 0.0356\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.00993\n",
      "Epoch 412/564\n",
      "281/281 [==============================] - 32s 115ms/step - loss: 0.0130 - val_loss: 0.0376\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.00993\n",
      "Epoch 413/564\n",
      "281/281 [==============================] - 32s 115ms/step - loss: 0.0092 - val_loss: 0.0256\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.00993\n",
      "Epoch 414/564\n",
      "281/281 [==============================] - 32s 114ms/step - loss: 0.0114 - val_loss: 0.0230\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.00993\n",
      "Epoch 415/564\n",
      "281/281 [==============================] - 32s 114ms/step - loss: 0.0128 - val_loss: 0.0194\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.00993\n",
      "Epoch 416/564\n",
      "281/281 [==============================] - 32s 113ms/step - loss: 0.0123 - val_loss: 0.0295\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.00993\n",
      "Epoch 417/564\n",
      "281/281 [==============================] - 32s 113ms/step - loss: 0.0116 - val_loss: 0.0507\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.00993\n",
      "Epoch 418/564\n",
      "281/281 [==============================] - 32s 113ms/step - loss: 0.0102 - val_loss: 0.0357\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.00993\n",
      "Epoch 419/564\n",
      "281/281 [==============================] - 32s 113ms/step - loss: 0.0132 - val_loss: 0.0400\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.00993\n",
      "Epoch 420/564\n",
      "281/281 [==============================] - 32s 114ms/step - loss: 0.0152 - val_loss: 0.0398\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.00993\n",
      "Epoch 421/564\n",
      "281/281 [==============================] - 32s 114ms/step - loss: 0.0110 - val_loss: 0.0398\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.00993\n",
      "Epoch 422/564\n",
      "281/281 [==============================] - 32s 115ms/step - loss: 0.0121 - val_loss: 0.0483\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.00993\n",
      "Epoch 423/564\n",
      "281/281 [==============================] - 32s 114ms/step - loss: 0.0149 - val_loss: 0.0479\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.00993\n",
      "Epoch 424/564\n",
      "281/281 [==============================] - 32s 114ms/step - loss: 0.0101 - val_loss: 0.0573\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.00993\n",
      "Epoch 425/564\n",
      "281/281 [==============================] - 32s 114ms/step - loss: 0.0117 - val_loss: 0.0568\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.00993\n",
      "Epoch 426/564\n",
      "281/281 [==============================] - 32s 114ms/step - loss: 0.0110 - val_loss: 0.0540\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.00993\n",
      "Epoch 427/564\n",
      "281/281 [==============================] - 32s 113ms/step - loss: 0.0137 - val_loss: 0.0486\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.00993\n",
      "Epoch 428/564\n",
      "281/281 [==============================] - 32s 114ms/step - loss: 0.0158 - val_loss: 0.0412\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.00993\n",
      "Epoch 429/564\n",
      "281/281 [==============================] - 32s 113ms/step - loss: 0.0164 - val_loss: 0.0558\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.00993\n",
      "Epoch 430/564\n",
      "281/281 [==============================] - 32s 113ms/step - loss: 0.0146 - val_loss: 0.0676\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.00993\n",
      "Epoch 431/564\n",
      "281/281 [==============================] - 32s 114ms/step - loss: 0.0086 - val_loss: 0.0774\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.00993\n",
      "Epoch 432/564\n",
      "281/281 [==============================] - 32s 113ms/step - loss: 0.0076 - val_loss: 0.0862\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.00993\n",
      "Epoch 433/564\n",
      "281/281 [==============================] - 32s 114ms/step - loss: 0.0083 - val_loss: 0.0778\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.00993\n",
      "Epoch 434/564\n",
      "281/281 [==============================] - 32s 114ms/step - loss: 0.0107 - val_loss: 0.0628\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.00993\n",
      "Epoch 435/564\n",
      "281/281 [==============================] - 32s 114ms/step - loss: 0.0124 - val_loss: 0.0540\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.00993\n",
      "Epoch 436/564\n",
      "281/281 [==============================] - 32s 113ms/step - loss: 0.0138 - val_loss: 0.0458\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.00993\n",
      "Epoch 437/564\n",
      "281/281 [==============================] - 32s 114ms/step - loss: 0.0132 - val_loss: 0.0338\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.00993\n",
      "Epoch 438/564\n",
      "281/281 [==============================] - 29s 102ms/step - loss: 0.0089 - val_loss: 0.0384\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.00993\n",
      "Epoch 439/564\n",
      "281/281 [==============================] - 25s 88ms/step - loss: 0.0108 - val_loss: 0.0364\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.00993\n",
      "Epoch 440/564\n",
      "281/281 [==============================] - 25s 89ms/step - loss: 0.0121 - val_loss: 0.0341\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.00993\n",
      "Epoch 441/564\n",
      "281/281 [==============================] - 25s 90ms/step - loss: 0.0082 - val_loss: 0.0321\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.00993\n",
      "Epoch 442/564\n",
      "281/281 [==============================] - 25s 90ms/step - loss: 0.0088 - val_loss: 0.0431\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.00993\n",
      "Epoch 443/564\n",
      "281/281 [==============================] - 25s 90ms/step - loss: 0.0082 - val_loss: 0.0497\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.00993\n",
      "Epoch 444/564\n",
      "281/281 [==============================] - 25s 90ms/step - loss: 0.0085 - val_loss: 0.0561\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.00993\n",
      "Epoch 445/564\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.0095 - val_loss: 0.1140\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.00993\n",
      "Epoch 446/564\n",
      "281/281 [==============================] - 25s 91ms/step - loss: 0.0120 - val_loss: 0.0488\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.00993\n",
      "Epoch 447/564\n",
      "281/281 [==============================] - 25s 90ms/step - loss: 0.0109 - val_loss: 0.0847\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.00993\n",
      "Epoch 448/564\n",
      "281/281 [==============================] - 25s 90ms/step - loss: 0.0181 - val_loss: 0.0694\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.00993\n",
      "Epoch 449/564\n",
      "281/281 [==============================] - 25s 90ms/step - loss: 0.0140 - val_loss: 0.0497\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.00993\n",
      "Epoch 450/564\n",
      "281/281 [==============================] - 25s 90ms/step - loss: 0.0415 - val_loss: 0.0515\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.00993\n",
      "Epoch 451/564\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.0374 - val_loss: 0.0504\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.00993\n",
      "Epoch 452/564\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.0336 - val_loss: 0.0410\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.00993\n",
      "Epoch 453/564\n",
      "281/281 [==============================] - 25s 91ms/step - loss: 0.0237 - val_loss: 0.0320\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.00993\n",
      "Epoch 454/564\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.0091 - val_loss: 0.0292\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.00993\n",
      "Epoch 455/564\n",
      "281/281 [==============================] - 25s 90ms/step - loss: 0.0122 - val_loss: 0.0298\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.00993\n",
      "Epoch 456/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0185 - val_loss: 0.0324\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.00993\n",
      "Epoch 457/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0173 - val_loss: 0.0321\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.00993\n",
      "Epoch 458/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0144 - val_loss: 0.0309\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.00993\n",
      "Epoch 459/564\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.0132 - val_loss: 0.0355\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.00993\n",
      "Epoch 460/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0107 - val_loss: 0.0336\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.00993\n",
      "Epoch 461/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0141 - val_loss: 0.0255\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.00993\n",
      "Epoch 462/564\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.0173 - val_loss: 0.0266\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.00993\n",
      "Epoch 463/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0122 - val_loss: 0.0253\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.00993\n",
      "Epoch 464/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0109 - val_loss: 0.0259\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.00993\n",
      "Epoch 465/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0087 - val_loss: 0.0405\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.00993\n",
      "Epoch 466/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0075 - val_loss: 0.0382\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.00993\n",
      "Epoch 467/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0077 - val_loss: 0.0391\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.00993\n",
      "Epoch 468/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0090 - val_loss: 0.0360\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.00993\n",
      "Epoch 469/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0074 - val_loss: 0.0366\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.00993\n",
      "Epoch 470/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0133 - val_loss: 0.0462\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.00993\n",
      "Epoch 471/564\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.0081 - val_loss: 0.0539\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.00993\n",
      "Epoch 472/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0343 - val_loss: 0.0742\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.00993\n",
      "Epoch 473/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0421 - val_loss: 0.0755\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.00993\n",
      "Epoch 474/564\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.0425 - val_loss: 0.0687\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.00993\n",
      "Epoch 475/564\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.0343 - val_loss: 0.0748\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.00993\n",
      "Epoch 476/564\n",
      "281/281 [==============================] - 25s 91ms/step - loss: 0.0115 - val_loss: 0.0741\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.00993\n",
      "Epoch 477/564\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.0095 - val_loss: 0.0899\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.00993\n",
      "Epoch 478/564\n",
      "281/281 [==============================] - 25s 91ms/step - loss: 0.0080 - val_loss: 0.0741\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.00993\n",
      "Epoch 479/564\n",
      "281/281 [==============================] - 25s 91ms/step - loss: 0.0074 - val_loss: 0.0726\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.00993\n",
      "Epoch 480/564\n",
      "281/281 [==============================] - 25s 91ms/step - loss: 0.0128 - val_loss: 0.0711\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.00993\n",
      "Epoch 481/564\n",
      "281/281 [==============================] - 25s 91ms/step - loss: 0.0154 - val_loss: 0.0784\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.00993\n",
      "Epoch 482/564\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.0163 - val_loss: 0.0643\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.00993\n",
      "Epoch 483/564\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.0149 - val_loss: 0.0568\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.00993\n",
      "Epoch 484/564\n",
      "281/281 [==============================] - 25s 90ms/step - loss: 0.0085 - val_loss: 0.0511\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.00993\n",
      "Epoch 485/564\n",
      "281/281 [==============================] - 25s 91ms/step - loss: 0.0082 - val_loss: 0.0555\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.00993\n",
      "Epoch 486/564\n",
      "281/281 [==============================] - 25s 90ms/step - loss: 0.0072 - val_loss: 0.0506\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.00993\n",
      "Epoch 487/564\n",
      "281/281 [==============================] - 25s 91ms/step - loss: 0.0088 - val_loss: 0.0547\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.00993\n",
      "Epoch 488/564\n",
      "281/281 [==============================] - 25s 90ms/step - loss: 0.0105 - val_loss: 0.0537\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.00993\n",
      "Epoch 489/564\n",
      "281/281 [==============================] - 25s 90ms/step - loss: 0.0110 - val_loss: 0.0305\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.00993\n",
      "Epoch 490/564\n",
      "281/281 [==============================] - 25s 90ms/step - loss: 0.0081 - val_loss: 0.0296\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.00993\n",
      "Epoch 491/564\n",
      "281/281 [==============================] - 25s 90ms/step - loss: 0.0094 - val_loss: 0.0299\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.00993\n",
      "Epoch 492/564\n",
      "281/281 [==============================] - 25s 91ms/step - loss: 0.0090 - val_loss: 0.0342\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.00993\n",
      "Epoch 493/564\n",
      "281/281 [==============================] - 25s 91ms/step - loss: 0.0122 - val_loss: 0.0408\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.00993\n",
      "Epoch 494/564\n",
      "281/281 [==============================] - 25s 90ms/step - loss: 0.0201 - val_loss: 0.0502\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.00993\n",
      "Epoch 495/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0221 - val_loss: 0.0393\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.00993\n",
      "Epoch 496/564\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.0195 - val_loss: 0.0507\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.00993\n",
      "Epoch 497/564\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.0152 - val_loss: 0.0952\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.00993\n",
      "Epoch 498/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0122 - val_loss: 0.1289\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.00993\n",
      "Epoch 499/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0223 - val_loss: 0.1784\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.00993\n",
      "Epoch 500/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0207 - val_loss: 0.1386\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.00993\n",
      "Epoch 501/564\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.0141 - val_loss: 0.1972\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.00993\n",
      "Epoch 502/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0148 - val_loss: 0.1368\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.00993\n",
      "Epoch 503/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0159 - val_loss: 0.0971\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.00993\n",
      "Epoch 504/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0201 - val_loss: 0.0690\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.00993\n",
      "Epoch 505/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0127 - val_loss: 0.0802\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.00993\n",
      "Epoch 506/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0131 - val_loss: 0.0547\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.00993\n",
      "Epoch 507/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0158 - val_loss: 0.0624\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.00993\n",
      "Epoch 508/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0144 - val_loss: 0.0536\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.00993\n",
      "Epoch 509/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0140 - val_loss: 0.0526\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.00993\n",
      "Epoch 510/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0131 - val_loss: 0.0525\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.00993\n",
      "Epoch 511/564\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.0092 - val_loss: 0.0602\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.00993\n",
      "Epoch 512/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0053 - val_loss: 0.0584\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.00993\n",
      "Epoch 513/564\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.0095 - val_loss: 0.0548\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.00993\n",
      "Epoch 514/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0126 - val_loss: 0.0547\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.00993\n",
      "Epoch 515/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0166 - val_loss: 0.0453\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.00993\n",
      "Epoch 516/564\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.0137 - val_loss: 0.0507\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.00993\n",
      "Epoch 517/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0112 - val_loss: 0.0435\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.00993\n",
      "Epoch 518/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0148 - val_loss: 0.0466\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.00993\n",
      "Epoch 519/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0156 - val_loss: 0.0497\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.00993\n",
      "Epoch 520/564\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.0134 - val_loss: 0.0492\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.00993\n",
      "Epoch 521/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0140 - val_loss: 0.0405\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.00993\n",
      "Epoch 522/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0209 - val_loss: 0.0657\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.00993\n",
      "Epoch 523/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0218 - val_loss: 0.0671\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.00993\n",
      "Epoch 524/564\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.0212 - val_loss: 0.0703\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.00993\n",
      "Epoch 525/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0201 - val_loss: 0.0746\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.00993\n",
      "Epoch 526/564\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.0182 - val_loss: 0.0502\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.00993\n",
      "Epoch 527/564\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.0161 - val_loss: 0.0336\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.00993\n",
      "Epoch 528/564\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.0154 - val_loss: 0.0343\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 0.00993\n",
      "Epoch 529/564\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.0146 - val_loss: 0.0457\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 0.00993\n",
      "Epoch 530/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0081 - val_loss: 0.0563\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.00993\n",
      "Epoch 531/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0078 - val_loss: 0.0442\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.00993\n",
      "Epoch 532/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0101 - val_loss: 0.0370\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.00993\n",
      "Epoch 533/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0153 - val_loss: 0.0305\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.00993\n",
      "Epoch 534/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0184 - val_loss: 0.0271\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.00993\n",
      "Epoch 535/564\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.0177 - val_loss: 0.0270\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.00993\n",
      "Epoch 536/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0167 - val_loss: 0.0318\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.00993\n",
      "Epoch 537/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0233 - val_loss: 0.0316\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.00993\n",
      "Epoch 538/564\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.0317 - val_loss: 0.0308\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.00993\n",
      "Epoch 539/564\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.0286 - val_loss: 0.0572\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.00993\n",
      "Epoch 540/564\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.0224 - val_loss: 0.0378\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.00993\n",
      "Epoch 541/564\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.0226 - val_loss: 0.0372\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.00993\n",
      "Epoch 542/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0181 - val_loss: 0.0445\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.00993\n",
      "Epoch 543/564\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.0132 - val_loss: 0.0410\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.00993\n",
      "Epoch 544/564\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.0152 - val_loss: 0.0423\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.00993\n",
      "Epoch 545/564\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.0117 - val_loss: 0.0625\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.00993\n",
      "Epoch 546/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0117 - val_loss: 0.0552\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.00993\n",
      "Epoch 547/564\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.0181 - val_loss: 0.0638\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.00993\n",
      "Epoch 548/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0176 - val_loss: 0.0552\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.00993\n",
      "Epoch 549/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0149 - val_loss: 0.0594\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.00993\n",
      "Epoch 550/564\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.0217 - val_loss: 0.0583\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.00993\n",
      "Epoch 551/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0185 - val_loss: 0.0713\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.00993\n",
      "Epoch 552/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0179 - val_loss: 0.0715\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.00993\n",
      "Epoch 553/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0114 - val_loss: 0.0700\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 0.00993\n",
      "Epoch 554/564\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.0068 - val_loss: 0.0682\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.00993\n",
      "Epoch 555/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0095 - val_loss: 0.0544\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 0.00993\n",
      "Epoch 556/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0352 - val_loss: 0.0642\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 0.00993\n",
      "Epoch 557/564\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.0499 - val_loss: 0.0842\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 0.00993\n",
      "Epoch 558/564\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.0550 - val_loss: 0.0967\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 0.00993\n",
      "Epoch 559/564\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.0557 - val_loss: 0.1035\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 0.00993\n",
      "Epoch 560/564\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.0275 - val_loss: 0.0923\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.00993\n",
      "Epoch 561/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0264 - val_loss: 0.0890\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 0.00993\n",
      "Epoch 562/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0440 - val_loss: 0.0790\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 0.00993\n",
      "Epoch 563/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0420 - val_loss: 0.0975\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 0.00993\n",
      "Epoch 564/564\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.0359 - val_loss: 0.0962\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 0.00993\n",
      "Time to train: 22232.831793785095 (s)\n"
     ]
    }
   ],
   "source": [
    "epoches = 1000\n",
    "num_epoch = 0\n",
    "model_name = 'pfn_stmc_v2_dg_1'\n",
    "chkpoint = tf.keras.callbacks.ModelCheckpoint('model/' + model_name + '.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "history_logger = tf.keras.callbacks.CSVLogger('log/' + model_name + '.log', separator=',', append=True)\n",
    "t0 = t.time()\n",
    "\"\"\"history_ct = pfn.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=500,\n",
    "                    validation_data=(X_val, Y_val),\n",
    "                    callbacks=[chkpoint, history_logger])\"\"\"\n",
    "if os.path.isfile('model/' + model_name + '.h5'):\n",
    "    pfn = load_model('model/' + model_name + '.h5')\n",
    "    # read how many epochs it has been trained\n",
    "    pandas_log = pd.read_csv('log/' + model_name + '.log', sep=',')\n",
    "    num_epoch = pandas_log.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "history_ct = pfn.fit(minibatches(data, target, batch_size=1024),\n",
    "                    steps_per_epoch=len(data)//1024,\n",
    "                    validation_data=(minibatches(val_data, val_target, batch_size=1024)),\n",
    "                    validation_steps=len(val_data)//1024,\n",
    "                    epochs=epoches-num_epoch,\n",
    "                    verbose=1,\n",
    "                    callbacks=[chkpoint, history_logger])\n",
    "t1 = t.time()\n",
    "print('Time to train: '+str(t1-t0)+' (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load log\n",
    "pfn_log = pd.read_csv('log/' + model_name + '.log', sep=',')\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.plot(pfn_log['val_loss'], label=\"Validation\",linestyle='dashed')\n",
    "plt.plot(pfn_log['loss'].history['loss'], label=\"Training\")\n",
    "plt.yscale('log')\n",
    "plt.ylim(.001,10)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.xlim(0,1000)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.xlabel('Epochs', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "plt.legend(loc='upper right', ncol=1)\n",
    "plt.text(1000, 1.5, 'LR=2e-3', fontsize=13)\n",
    "plt.text(1000, 1, 'Epoch: 1000', fontsize=13)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('Regression_Plots/July/XY_STSC_lossCurves_3000batch_LR1e-2_2021-07-016.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "# from . import plot_util as pu\n",
    "from util import plot_util as pu\n",
    "\n",
    "def _iqrOverMed(x):\n",
    "    # get the IQR via the percentile function\n",
    "    # 84 is median + 1 sigma, 16 is median - 1 sigma\n",
    "    q16, q84 = np.percentile(x, [16, 84])\n",
    "    return (q84 - q16) / (2 * np.median(x))\n",
    "\n",
    "def resolutionPlot(x, y, figfile='',\n",
    "                   xlabel='True Energy [GeV]', ylabel='Response IQR / (2 x Median)',\n",
    "                   atlas_x=-1, atlas_y=-1, simulation=False,\n",
    "                   xlim=(0.3,1000), ylim=(0,1), \n",
    "                   textlist=[]):\n",
    "    xbin = [10**exp for exp in  np.arange(-1.0, 3.1, 0.1)]\n",
    "    xcenter = [(xbin[i] + xbin[i+1]) / 2 for i in range(len(xbin)-1)]\n",
    "\n",
    "    resolution = stats.binned_statistic(x, y, bins=xbin, statistic=_iqrOverMed).statistic\n",
    "    \n",
    "    plt.cla(); plt.clf()\n",
    "    fig = plt.figure()\n",
    "    fig.patch.set_facecolor('white')\n",
    "    plt.plot(xcenter, resolution)\n",
    "    plt.xscale('log')\n",
    "    plt.xlim(xlim)\n",
    "    plt.ylim(ylim)\n",
    "    pu.ampl.set_xlabel(xlabel)\n",
    "    pu.ampl.set_ylabel(ylabel)\n",
    "\n",
    "    pu.drawLabels(fig, atlas_x, atlas_y, simulation, textlist)\n",
    "\n",
    "    if figfile != '':\n",
    "        plt.savefig(figfile)\n",
    "    plt.show()\n",
    "\n",
    "    return xcenter, resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "\n",
    "def point_mask_fn(X, mask_val=0.):\n",
    "    return Kb.cast(Kb.any(Kb.not_equal(X, mask_val), axis=-1), Kb.dtype(X))\n",
    "\n",
    "def convert_to_tensor(X):\n",
    "    return tf.concat([tfp.distributions.Distribution.mean(X), tfp.distributions.Distribution.stddev(X)],1)\n",
    "\n",
    "def ParticleFlow_MDN(num_features, name=\"PFN_MDN_Network\"):\n",
    "    \n",
    "    event_shape = [1]\n",
    "    num_components = 3\n",
    "    params_size = tfp.layers.MixtureNormal.params_size(num_components, event_shape)\n",
    "\n",
    "\n",
    "    inputs = keras.Input(shape=(None, num_features), name='input')\n",
    "\n",
    "    dense_0 = layers.Dense(100)\n",
    "    t_dist_0 = layers.TimeDistributed(dense_0, name='t_dist_0')(inputs)\n",
    "    activation_0 = layers.Activation('relu', name=\"activation_0\")(t_dist_0)\n",
    "    \n",
    "    dense_1 = layers.Dense(100)\n",
    "    t_dist_1 = layers.TimeDistributed(dense_1, name='t_dist_1')(activation_0)\n",
    "    activation_1 = layers.Activation('relu', name='activation_1')(t_dist_1)\n",
    "    \n",
    "    dense_2 = layers.Dense(128)\n",
    "    t_dist_2 = layers.TimeDistributed(dense_2, name='t_dist_2')(activation_1)\n",
    "    activation_2 = layers.Activation('relu', name='activation_2')(t_dist_2)\n",
    "    \n",
    "    lambda_layer = layers.Lambda(point_mask_fn, output_shape=(None, None),\n",
    "                                mask=None,\n",
    "                                name='mask')(inputs)\n",
    "\n",
    "    sum_layer = layers.Dot(axes=(1,1), name='sum')([lambda_layer, activation_2])\n",
    "    \n",
    "    dense_3 = layers.Dense(100, name='dense_0')(sum_layer)\n",
    "    activation_3 = layers.Activation('relu', name=\"activation_3\")(dense_3)\n",
    "    \n",
    "    dense_4 = layers.Dense(100, name='dense_1')(activation_3)\n",
    "    activation_4 = layers.Activation('relu', name=\"activation_4\")(dense_4)\n",
    "    \n",
    "    dense_5 = layers.Dense(100, name='dense_2')(activation_4)\n",
    "    activation_5 = layers.Activation('relu', name=\"activation_5\")(dense_5)\n",
    "    \n",
    "    dense_6 = layers.Dense(units=params_size, activation=lambda x: tf.clip_by_value(x, -30., 30.))(activation_5)\n",
    "\n",
    "    \n",
    "    mdn_0 = tfp.layers.MixtureNormal(num_components, event_shape, validate_args=True,\n",
    "                                          convert_to_tensor_fn=convert_to_tensor)(dense_6)\n",
    "    \n",
    "    return keras.Model(inputs=inputs, outputs=mdn_0, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"PFN_MDN_Network\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 5)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "t_dist_0 (TimeDistributed)      (None, None, 100)    600         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_0 (Activation)       (None, None, 100)    0           t_dist_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "t_dist_1 (TimeDistributed)      (None, None, 100)    10100       activation_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, 100)    0           t_dist_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "t_dist_2 (TimeDistributed)      (None, None, 128)    12928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, 128)    0           t_dist_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 128)          0           mask[0][0]                       \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 100)          12900       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 100)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          10100       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          10100       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 100)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 9)            909         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "mixture_normal (MixtureNormal)  multiple             0           dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 57,637\n",
      "Trainable params: 57,637\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Kb.clear_session()\n",
    "\n",
    "netOpt = tf.keras.optimizers.Adam(\n",
    "    learning_rate=.002,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-09,\n",
    "    amsgrad=False)\n",
    "\n",
    "PFN_mdn = ParticleFlow_MDN(num_features=5)\n",
    "PFN_mdn.compile(optimizer = netOpt, loss=lambda y, p_y: -p_y.log_prob(y))\n",
    "PFN_mdn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "281/281 [==============================] - 28s 95ms/step - loss: 1.3118 - val_loss: 0.0419\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04187, saving model to model\\PFN_MDN_STMC_v2_1.h5\n",
      "Epoch 2/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -0.0036 - val_loss: 0.0813\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04187\n",
      "Epoch 3/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -0.3798 - val_loss: -0.4696\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04187 to -0.46956, saving model to model\\PFN_MDN_STMC_v2_1.h5\n",
      "Epoch 4/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -0.5533 - val_loss: -0.0111\n",
      "\n",
      "Epoch 00004: val_loss did not improve from -0.46956\n",
      "Epoch 5/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -0.8691 - val_loss: -0.2491\n",
      "\n",
      "Epoch 00005: val_loss did not improve from -0.46956\n",
      "Epoch 6/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -0.9005 - val_loss: -0.5649\n",
      "\n",
      "Epoch 00006: val_loss improved from -0.46956 to -0.56494, saving model to model\\PFN_MDN_STMC_v2_1.h5\n",
      "Epoch 7/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -0.9714 - val_loss: -0.6575\n",
      "\n",
      "Epoch 00007: val_loss improved from -0.56494 to -0.65750, saving model to model\\PFN_MDN_STMC_v2_1.h5\n",
      "Epoch 8/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -0.9495 - val_loss: -0.6725\n",
      "\n",
      "Epoch 00008: val_loss improved from -0.65750 to -0.67250, saving model to model\\PFN_MDN_STMC_v2_1.h5\n",
      "Epoch 9/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.1716 - val_loss: -0.0651\n",
      "\n",
      "Epoch 00009: val_loss did not improve from -0.67250\n",
      "Epoch 10/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.1578 - val_loss: -0.2114\n",
      "\n",
      "Epoch 00010: val_loss did not improve from -0.67250\n",
      "Epoch 11/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -0.7406 - val_loss: -0.7678\n",
      "\n",
      "Epoch 00011: val_loss improved from -0.67250 to -0.76780, saving model to model\\PFN_MDN_STMC_v2_1.h5\n",
      "Epoch 12/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -0.9260 - val_loss: -0.9355\n",
      "\n",
      "Epoch 00012: val_loss improved from -0.76780 to -0.93553, saving model to model\\PFN_MDN_STMC_v2_1.h5\n",
      "Epoch 13/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -0.8953 - val_loss: -0.7556\n",
      "\n",
      "Epoch 00013: val_loss did not improve from -0.93553\n",
      "Epoch 14/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.2425 - val_loss: -1.0649\n",
      "\n",
      "Epoch 00014: val_loss improved from -0.93553 to -1.06492, saving model to model\\PFN_MDN_STMC_v2_1.h5\n",
      "Epoch 15/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -1.1619 - val_loss: -0.9944\n",
      "\n",
      "Epoch 00015: val_loss did not improve from -1.06492\n",
      "Epoch 16/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.4041 - val_loss: -1.0119\n",
      "\n",
      "Epoch 00016: val_loss did not improve from -1.06492\n",
      "Epoch 17/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.2715 - val_loss: -0.9957\n",
      "\n",
      "Epoch 00017: val_loss did not improve from -1.06492\n",
      "Epoch 18/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.5142 - val_loss: -0.6686\n",
      "\n",
      "Epoch 00018: val_loss did not improve from -1.06492\n",
      "Epoch 19/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.4032 - val_loss: -0.9054\n",
      "\n",
      "Epoch 00019: val_loss did not improve from -1.06492\n",
      "Epoch 20/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.2857 - val_loss: -0.9554\n",
      "\n",
      "Epoch 00020: val_loss did not improve from -1.06492\n",
      "Epoch 21/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.2582 - val_loss: -0.8035\n",
      "\n",
      "Epoch 00021: val_loss did not improve from -1.06492\n",
      "Epoch 22/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.5910 - val_loss: 0.5347\n",
      "\n",
      "Epoch 00022: val_loss did not improve from -1.06492\n",
      "Epoch 23/1000\n",
      "281/281 [==============================] - 27s 94ms/step - loss: -1.5343 - val_loss: -1.1360\n",
      "\n",
      "Epoch 00023: val_loss improved from -1.06492 to -1.13603, saving model to model\\PFN_MDN_STMC_v2_1.h5\n",
      "Epoch 24/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.4134 - val_loss: -0.8705\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -1.13603\n",
      "Epoch 25/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -1.5877 - val_loss: -0.7735\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -1.13603\n",
      "Epoch 26/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -1.6297 - val_loss: -0.8082\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -1.13603\n",
      "Epoch 27/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: -1.6510 - val_loss: 0.6426\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -1.13603\n",
      "Epoch 28/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -1.7134 - val_loss: 0.1032\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -1.13603\n",
      "Epoch 29/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -1.6889 - val_loss: 3.3109\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -1.13603\n",
      "Epoch 30/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -1.5780 - val_loss: -0.6984\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -1.13603\n",
      "Epoch 31/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: -1.6445 - val_loss: -0.6767\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -1.13603\n",
      "Epoch 32/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -1.5060 - val_loss: -1.0032\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -1.13603\n",
      "Epoch 33/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -1.5930 - val_loss: -0.8567\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -1.13603\n",
      "Epoch 34/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -1.6857 - val_loss: -0.6400\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -1.13603\n",
      "Epoch 35/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -1.7642 - val_loss: -0.8548\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -1.13603\n",
      "Epoch 36/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -1.7586 - val_loss: -0.5726\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -1.13603\n",
      "Epoch 37/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -1.7662 - val_loss: 0.5781\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -1.13603\n",
      "Epoch 38/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -1.3503 - val_loss: -0.2862\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -1.13603\n",
      "Epoch 39/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: -1.4001 - val_loss: 1.9496\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -1.13603\n",
      "Epoch 40/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -1.7382 - val_loss: 0.0737\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -1.13603\n",
      "Epoch 41/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: -1.7536 - val_loss: 3.9090\n",
      "\n",
      "Epoch 00041: val_loss did not improve from -1.13603\n",
      "Epoch 42/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: -1.2234 - val_loss: 0.3053\n",
      "\n",
      "Epoch 00042: val_loss did not improve from -1.13603\n",
      "Epoch 43/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: -1.7971 - val_loss: -0.3540\n",
      "\n",
      "Epoch 00043: val_loss did not improve from -1.13603\n",
      "Epoch 44/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: -1.7412 - val_loss: -0.8797\n",
      "\n",
      "Epoch 00044: val_loss did not improve from -1.13603\n",
      "Epoch 45/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: -1.7620 - val_loss: -0.8736\n",
      "\n",
      "Epoch 00045: val_loss did not improve from -1.13603\n",
      "Epoch 46/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.6587 - val_loss: -0.5563\n",
      "\n",
      "Epoch 00046: val_loss did not improve from -1.13603\n",
      "Epoch 47/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.7403 - val_loss: 1.2304\n",
      "\n",
      "Epoch 00047: val_loss did not improve from -1.13603\n",
      "Epoch 48/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.5586 - val_loss: 1.3708\n",
      "\n",
      "Epoch 00048: val_loss did not improve from -1.13603\n",
      "Epoch 49/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.6410 - val_loss: 0.5631\n",
      "\n",
      "Epoch 00049: val_loss did not improve from -1.13603\n",
      "Epoch 50/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -2.0200 - val_loss: -0.1140\n",
      "\n",
      "Epoch 00050: val_loss did not improve from -1.13603\n",
      "Epoch 51/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.6994 - val_loss: 0.0257\n",
      "\n",
      "Epoch 00051: val_loss did not improve from -1.13603\n",
      "Epoch 52/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.6865 - val_loss: -0.3437\n",
      "\n",
      "Epoch 00052: val_loss did not improve from -1.13603\n",
      "Epoch 53/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.6806 - val_loss: 0.0868\n",
      "\n",
      "Epoch 00053: val_loss did not improve from -1.13603\n",
      "Epoch 54/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: -1.4556 - val_loss: -1.0628\n",
      "\n",
      "Epoch 00054: val_loss did not improve from -1.13603\n",
      "Epoch 55/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.4628 - val_loss: -1.0607\n",
      "\n",
      "Epoch 00055: val_loss did not improve from -1.13603\n",
      "Epoch 56/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.7401 - val_loss: -1.0351\n",
      "\n",
      "Epoch 00056: val_loss did not improve from -1.13603\n",
      "Epoch 57/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.8399 - val_loss: -0.2693\n",
      "\n",
      "Epoch 00057: val_loss did not improve from -1.13603\n",
      "Epoch 58/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.6473 - val_loss: -0.6050\n",
      "\n",
      "Epoch 00058: val_loss did not improve from -1.13603\n",
      "Epoch 59/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.9428 - val_loss: 0.4693\n",
      "\n",
      "Epoch 00059: val_loss did not improve from -1.13603\n",
      "Epoch 60/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.6636 - val_loss: -0.6959\n",
      "\n",
      "Epoch 00060: val_loss did not improve from -1.13603\n",
      "Epoch 61/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.7487 - val_loss: 12.9740\n",
      "\n",
      "Epoch 00061: val_loss did not improve from -1.13603\n",
      "Epoch 62/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.9398 - val_loss: -0.8297\n",
      "\n",
      "Epoch 00062: val_loss did not improve from -1.13603\n",
      "Epoch 63/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.7079 - val_loss: -0.3632\n",
      "\n",
      "Epoch 00063: val_loss did not improve from -1.13603\n",
      "Epoch 64/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.6763 - val_loss: -0.9665\n",
      "\n",
      "Epoch 00064: val_loss did not improve from -1.13603\n",
      "Epoch 65/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 179874.0312 - val_loss: 7.2006\n",
      "\n",
      "Epoch 00065: val_loss did not improve from -1.13603\n",
      "Epoch 66/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 1.1288 - val_loss: -4.4284e-04\n",
      "\n",
      "Epoch 00066: val_loss did not improve from -1.13603\n",
      "Epoch 67/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -0.7127 - val_loss: 10.6755\n",
      "\n",
      "Epoch 00067: val_loss did not improve from -1.13603\n",
      "Epoch 68/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -0.9702 - val_loss: 25.0636\n",
      "\n",
      "Epoch 00068: val_loss did not improve from -1.13603\n",
      "Epoch 69/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -0.9875 - val_loss: 0.8440\n",
      "\n",
      "Epoch 00069: val_loss did not improve from -1.13603\n",
      "Epoch 70/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: -1.0760 - val_loss: 4.7180\n",
      "\n",
      "Epoch 00070: val_loss did not improve from -1.13603\n",
      "Epoch 71/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: -1.1902 - val_loss: 1.1038\n",
      "\n",
      "Epoch 00071: val_loss did not improve from -1.13603\n",
      "Epoch 72/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: -1.2284 - val_loss: 0.1766\n",
      "\n",
      "Epoch 00072: val_loss did not improve from -1.13603\n",
      "Epoch 73/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -1.2965 - val_loss: 1.4858\n",
      "\n",
      "Epoch 00073: val_loss did not improve from -1.13603\n",
      "Epoch 74/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -1.3660 - val_loss: 0.1268\n",
      "\n",
      "Epoch 00074: val_loss did not improve from -1.13603\n",
      "Epoch 75/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -1.3971 - val_loss: 0.4704\n",
      "\n",
      "Epoch 00075: val_loss did not improve from -1.13603\n",
      "Epoch 76/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -1.4174 - val_loss: 10.5859\n",
      "\n",
      "Epoch 00076: val_loss did not improve from -1.13603\n",
      "Epoch 77/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -1.4479 - val_loss: -0.1057\n",
      "\n",
      "Epoch 00077: val_loss did not improve from -1.13603\n",
      "Epoch 78/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -1.5814 - val_loss: 3.3110\n",
      "\n",
      "Epoch 00078: val_loss did not improve from -1.13603\n",
      "Epoch 79/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -1.6001 - val_loss: 0.6296\n",
      "\n",
      "Epoch 00079: val_loss did not improve from -1.13603\n",
      "Epoch 80/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: -1.5605 - val_loss: 9.8914\n",
      "\n",
      "Epoch 00080: val_loss did not improve from -1.13603\n",
      "Epoch 81/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: -1.6379 - val_loss: 0.3300\n",
      "\n",
      "Epoch 00081: val_loss did not improve from -1.13603\n",
      "Epoch 82/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: -1.6446 - val_loss: 0.0094\n",
      "\n",
      "Epoch 00082: val_loss did not improve from -1.13603\n",
      "Epoch 83/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: -1.6061 - val_loss: 1.8760\n",
      "\n",
      "Epoch 00083: val_loss did not improve from -1.13603\n",
      "Epoch 84/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: -1.6217 - val_loss: 2.2694\n",
      "\n",
      "Epoch 00084: val_loss did not improve from -1.13603\n",
      "Epoch 85/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.5516 - val_loss: -0.4427\n",
      "\n",
      "Epoch 00085: val_loss did not improve from -1.13603\n",
      "Epoch 86/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: -0.8525 - val_loss: -0.1330\n",
      "\n",
      "Epoch 00086: val_loss did not improve from -1.13603\n",
      "Epoch 87/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: -1.2413 - val_loss: 0.7075\n",
      "\n",
      "Epoch 00087: val_loss did not improve from -1.13603\n",
      "Epoch 88/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: -1.4181 - val_loss: 1.2380\n",
      "\n",
      "Epoch 00088: val_loss did not improve from -1.13603\n",
      "Epoch 89/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.4977 - val_loss: 5.7416\n",
      "\n",
      "Epoch 00089: val_loss did not improve from -1.13603\n",
      "Epoch 90/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: -1.4909 - val_loss: 5.7244\n",
      "\n",
      "Epoch 00090: val_loss did not improve from -1.13603\n",
      "Epoch 91/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -1.5007 - val_loss: 10.1827\n",
      "\n",
      "Epoch 00091: val_loss did not improve from -1.13603\n",
      "Epoch 92/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 9.6807 - val_loss: 3.4193\n",
      "\n",
      "Epoch 00092: val_loss did not improve from -1.13603\n",
      "Epoch 93/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 1.6956 - val_loss: 0.6450\n",
      "\n",
      "Epoch 00093: val_loss did not improve from -1.13603\n",
      "Epoch 94/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -0.0547 - val_loss: 0.4879\n",
      "\n",
      "Epoch 00094: val_loss did not improve from -1.13603\n",
      "Epoch 95/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -0.3692 - val_loss: 0.6052\n",
      "\n",
      "Epoch 00095: val_loss did not improve from -1.13603\n",
      "Epoch 96/1000\n",
      "281/281 [==============================] - 27s 95ms/step - loss: -0.5076 - val_loss: 0.8970\n",
      "\n",
      "Epoch 00096: val_loss did not improve from -1.13603\n",
      "Epoch 97/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 0.2784 - val_loss: 1.5210\n",
      "\n",
      "Epoch 00097: val_loss did not improve from -1.13603\n",
      "Epoch 98/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 1.3261 - val_loss: 0.6792\n",
      "\n",
      "Epoch 00098: val_loss did not improve from -1.13603\n",
      "Epoch 99/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 0.0829 - val_loss: 0.6588\n",
      "\n",
      "Epoch 00099: val_loss did not improve from -1.13603\n",
      "Epoch 100/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -0.2093 - val_loss: 2.2106\n",
      "\n",
      "Epoch 00100: val_loss did not improve from -1.13603\n",
      "Epoch 101/1000\n",
      "281/281 [==============================] - 27s 94ms/step - loss: -0.4948 - val_loss: 1.1324\n",
      "\n",
      "Epoch 00101: val_loss did not improve from -1.13603\n",
      "Epoch 102/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -0.5783 - val_loss: 2.7188\n",
      "\n",
      "Epoch 00102: val_loss did not improve from -1.13603\n",
      "Epoch 103/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -0.6578 - val_loss: 0.0801\n",
      "\n",
      "Epoch 00103: val_loss did not improve from -1.13603\n",
      "Epoch 104/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -0.6969 - val_loss: 1.3188\n",
      "\n",
      "Epoch 00104: val_loss did not improve from -1.13603\n",
      "Epoch 105/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: -0.7742 - val_loss: 1.8280\n",
      "\n",
      "Epoch 00105: val_loss did not improve from -1.13603\n",
      "Epoch 106/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: -0.8809 - val_loss: 0.4361\n",
      "\n",
      "Epoch 00106: val_loss did not improve from -1.13603\n",
      "Epoch 107/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: -0.8843 - val_loss: 74.3106\n",
      "\n",
      "Epoch 00107: val_loss did not improve from -1.13603\n",
      "Epoch 108/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: -0.9192 - val_loss: 1838.6334\n",
      "\n",
      "Epoch 00108: val_loss did not improve from -1.13603\n",
      "Epoch 109/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 3.8031 - val_loss: 1.3692\n",
      "\n",
      "Epoch 00109: val_loss did not improve from -1.13603\n",
      "Epoch 110/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 33849.6719 - val_loss: 4.3267\n",
      "\n",
      "Epoch 00110: val_loss did not improve from -1.13603\n",
      "Epoch 111/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 4.3199 - val_loss: 4.2961\n",
      "\n",
      "Epoch 00111: val_loss did not improve from -1.13603\n",
      "Epoch 112/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 4.1514 - val_loss: 4.1298\n",
      "\n",
      "Epoch 00112: val_loss did not improve from -1.13603\n",
      "Epoch 113/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 2.8435 - val_loss: 3.1199\n",
      "\n",
      "Epoch 00113: val_loss did not improve from -1.13603\n",
      "Epoch 114/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 225978361496066532048896.0000 - val_loss: 4.3234\n",
      "\n",
      "Epoch 00114: val_loss did not improve from -1.13603\n",
      "Epoch 115/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 4.3216 - val_loss: 4.3226\n",
      "\n",
      "Epoch 00115: val_loss did not improve from -1.13603\n",
      "Epoch 116/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 4.3216 - val_loss: 4.3220\n",
      "\n",
      "Epoch 00116: val_loss did not improve from -1.13603\n",
      "Epoch 117/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 4.3216 - val_loss: 4.3217\n",
      "\n",
      "Epoch 00117: val_loss did not improve from -1.13603\n",
      "Epoch 118/1000\n",
      "281/281 [==============================] - 27s 94ms/step - loss: 4.3213 - val_loss: 4.3212\n",
      "\n",
      "Epoch 00118: val_loss did not improve from -1.13603\n",
      "Epoch 119/1000\n",
      "281/281 [==============================] - 27s 94ms/step - loss: 4.3223 - val_loss: 4.3215\n",
      "\n",
      "Epoch 00119: val_loss did not improve from -1.13603\n",
      "Epoch 120/1000\n",
      "281/281 [==============================] - 27s 94ms/step - loss: 4.3217 - val_loss: 4.3218\n",
      "\n",
      "Epoch 00120: val_loss did not improve from -1.13603\n",
      "Epoch 121/1000\n",
      "281/281 [==============================] - 27s 94ms/step - loss: 4.3219 - val_loss: 4.3212\n",
      "\n",
      "Epoch 00121: val_loss did not improve from -1.13603\n",
      "Epoch 122/1000\n",
      "281/281 [==============================] - 27s 95ms/step - loss: 4.3209 - val_loss: 4.3215\n",
      "\n",
      "Epoch 00122: val_loss did not improve from -1.13603\n",
      "Epoch 123/1000\n",
      "281/281 [==============================] - 27s 94ms/step - loss: 4.3212 - val_loss: 4.3207\n",
      "\n",
      "Epoch 00123: val_loss did not improve from -1.13603\n",
      "Epoch 124/1000\n",
      "281/281 [==============================] - 27s 95ms/step - loss: 4.3205 - val_loss: 4.3206\n",
      "\n",
      "Epoch 00124: val_loss did not improve from -1.13603\n",
      "Epoch 125/1000\n",
      "281/281 [==============================] - 27s 94ms/step - loss: 4.3208 - val_loss: 4.3213\n",
      "\n",
      "Epoch 00125: val_loss did not improve from -1.13603\n",
      "Epoch 126/1000\n",
      "281/281 [==============================] - 27s 95ms/step - loss: 4.3200 - val_loss: 4.3189\n",
      "\n",
      "Epoch 00126: val_loss did not improve from -1.13603\n",
      "Epoch 127/1000\n",
      "281/281 [==============================] - 27s 95ms/step - loss: 4.2883 - val_loss: 4.1298\n",
      "\n",
      "Epoch 00127: val_loss did not improve from -1.13603\n",
      "Epoch 128/1000\n",
      "281/281 [==============================] - 27s 95ms/step - loss: 4.2687 - val_loss: 4.2707\n",
      "\n",
      "Epoch 00128: val_loss did not improve from -1.13603\n",
      "Epoch 129/1000\n",
      "281/281 [==============================] - 27s 94ms/step - loss: 4.3035 - val_loss: 4.8638\n",
      "\n",
      "Epoch 00129: val_loss did not improve from -1.13603\n",
      "Epoch 130/1000\n",
      "281/281 [==============================] - 27s 95ms/step - loss: 4.3353 - val_loss: 3.7251\n",
      "\n",
      "Epoch 00130: val_loss did not improve from -1.13603\n",
      "Epoch 131/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 4.3767 - val_loss: 4.3917\n",
      "\n",
      "Epoch 00131: val_loss did not improve from -1.13603\n",
      "Epoch 132/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 4.2639 - val_loss: 4.7717\n",
      "\n",
      "Epoch 00132: val_loss did not improve from -1.13603\n",
      "Epoch 133/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 4.4340 - val_loss: 4.3247\n",
      "\n",
      "Epoch 00133: val_loss did not improve from -1.13603\n",
      "Epoch 134/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 4.3235 - val_loss: 4.3229\n",
      "\n",
      "Epoch 00134: val_loss did not improve from -1.13603\n",
      "Epoch 135/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 4.3184 - val_loss: 4.3209\n",
      "\n",
      "Epoch 00135: val_loss did not improve from -1.13603\n",
      "Epoch 136/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 4.3006 - val_loss: 4.3352\n",
      "\n",
      "Epoch 00136: val_loss did not improve from -1.13603\n",
      "Epoch 137/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 4.3252 - val_loss: 4.3199\n",
      "\n",
      "Epoch 00137: val_loss did not improve from -1.13603\n",
      "Epoch 138/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 4.3745 - val_loss: 4.3419\n",
      "\n",
      "Epoch 00138: val_loss did not improve from -1.13603\n",
      "Epoch 139/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 4.3232 - val_loss: 4.3217\n",
      "\n",
      "Epoch 00139: val_loss did not improve from -1.13603\n",
      "Epoch 140/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 4.3205 - val_loss: 4.3214\n",
      "\n",
      "Epoch 00140: val_loss did not improve from -1.13603\n",
      "Epoch 141/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 4.3203 - val_loss: 4.3218\n",
      "\n",
      "Epoch 00141: val_loss did not improve from -1.13603\n",
      "Epoch 142/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 4.3196 - val_loss: 4.3202\n",
      "\n",
      "Epoch 00142: val_loss did not improve from -1.13603\n",
      "Epoch 143/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 4.3057 - val_loss: 4.2610\n",
      "\n",
      "Epoch 00143: val_loss did not improve from -1.13603\n",
      "Epoch 144/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 4.4076 - val_loss: 4.3229\n",
      "\n",
      "Epoch 00144: val_loss did not improve from -1.13603\n",
      "Epoch 145/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 4.3232 - val_loss: 4.3227\n",
      "\n",
      "Epoch 00145: val_loss did not improve from -1.13603\n",
      "Epoch 146/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 4.3222 - val_loss: 4.3233\n",
      "\n",
      "Epoch 00146: val_loss did not improve from -1.13603\n",
      "Epoch 147/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 4.3219 - val_loss: 4.3222\n",
      "\n",
      "Epoch 00147: val_loss did not improve from -1.13603\n",
      "Epoch 148/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 4.3216 - val_loss: 4.3208\n",
      "\n",
      "Epoch 00148: val_loss did not improve from -1.13603\n",
      "Epoch 149/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 4.3204 - val_loss: 4.3129\n",
      "\n",
      "Epoch 00149: val_loss did not improve from -1.13603\n",
      "Epoch 150/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 4.2831 - val_loss: 4.3181\n",
      "\n",
      "Epoch 00150: val_loss did not improve from -1.13603\n",
      "Epoch 151/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 4.2364 - val_loss: 4.3112\n",
      "\n",
      "Epoch 00151: val_loss did not improve from -1.13603\n",
      "Epoch 152/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 4.2589 - val_loss: 4.3053\n",
      "\n",
      "Epoch 00152: val_loss did not improve from -1.13603\n",
      "Epoch 153/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 4.1975 - val_loss: 4.0609\n",
      "\n",
      "Epoch 00153: val_loss did not improve from -1.13603\n",
      "Epoch 154/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 4.6124 - val_loss: 2.1368\n",
      "\n",
      "Epoch 00154: val_loss did not improve from -1.13603\n",
      "Epoch 155/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 1.7771 - val_loss: 1.5596\n",
      "\n",
      "Epoch 00155: val_loss did not improve from -1.13603\n",
      "Epoch 156/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 1.4001 - val_loss: 1.3183\n",
      "\n",
      "Epoch 00156: val_loss did not improve from -1.13603\n",
      "Epoch 157/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 1.1316 - val_loss: 1.0185\n",
      "\n",
      "Epoch 00157: val_loss did not improve from -1.13603\n",
      "Epoch 158/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 0.9445 - val_loss: 0.8757\n",
      "\n",
      "Epoch 00158: val_loss did not improve from -1.13603\n",
      "Epoch 159/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 0.9305 - val_loss: 0.9482\n",
      "\n",
      "Epoch 00159: val_loss did not improve from -1.13603\n",
      "Epoch 160/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 1.1154 - val_loss: 0.8313\n",
      "\n",
      "Epoch 00160: val_loss did not improve from -1.13603\n",
      "Epoch 161/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 0.9233 - val_loss: 0.7702\n",
      "\n",
      "Epoch 00161: val_loss did not improve from -1.13603\n",
      "Epoch 162/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.6908 - val_loss: 1.0534\n",
      "\n",
      "Epoch 00162: val_loss did not improve from -1.13603\n",
      "Epoch 163/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 1.1089 - val_loss: 2.0490\n",
      "\n",
      "Epoch 00163: val_loss did not improve from -1.13603\n",
      "Epoch 164/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 1.0599 - val_loss: 0.8080\n",
      "\n",
      "Epoch 00164: val_loss did not improve from -1.13603\n",
      "Epoch 165/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 0.7727 - val_loss: 1221315840.0000\n",
      "\n",
      "Epoch 00165: val_loss did not improve from -1.13603\n",
      "Epoch 166/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 0.6448 - val_loss: 72.7582\n",
      "\n",
      "Epoch 00166: val_loss did not improve from -1.13603\n",
      "Epoch 167/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 1.8012 - val_loss: 1.4926\n",
      "\n",
      "Epoch 00167: val_loss did not improve from -1.13603\n",
      "Epoch 168/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 1.0032 - val_loss: 0.8329\n",
      "\n",
      "Epoch 00168: val_loss did not improve from -1.13603\n",
      "Epoch 169/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.7884 - val_loss: 0.8538\n",
      "\n",
      "Epoch 00169: val_loss did not improve from -1.13603\n",
      "Epoch 170/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 1.3837 - val_loss: 2.1131\n",
      "\n",
      "Epoch 00170: val_loss did not improve from -1.13603\n",
      "Epoch 171/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 1.2144 - val_loss: 0.8716\n",
      "\n",
      "Epoch 00171: val_loss did not improve from -1.13603\n",
      "Epoch 172/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.8877 - val_loss: 0.7425\n",
      "\n",
      "Epoch 00172: val_loss did not improve from -1.13603\n",
      "Epoch 173/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.8312 - val_loss: 0.7599\n",
      "\n",
      "Epoch 00173: val_loss did not improve from -1.13603\n",
      "Epoch 174/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.7717 - val_loss: 0.7117\n",
      "\n",
      "Epoch 00174: val_loss did not improve from -1.13603\n",
      "Epoch 175/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.8628 - val_loss: 0.8943\n",
      "\n",
      "Epoch 00175: val_loss did not improve from -1.13603\n",
      "Epoch 176/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.5981 - val_loss: 0.7374\n",
      "\n",
      "Epoch 00176: val_loss did not improve from -1.13603\n",
      "Epoch 177/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.6180 - val_loss: 0.6567\n",
      "\n",
      "Epoch 00177: val_loss did not improve from -1.13603\n",
      "Epoch 178/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 0.9166 - val_loss: 0.7116\n",
      "\n",
      "Epoch 00178: val_loss did not improve from -1.13603\n",
      "Epoch 179/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.6928 - val_loss: 0.8055\n",
      "\n",
      "Epoch 00179: val_loss did not improve from -1.13603\n",
      "Epoch 180/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.9387 - val_loss: 1.4959\n",
      "\n",
      "Epoch 00180: val_loss did not improve from -1.13603\n",
      "Epoch 181/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 1.5977 - val_loss: 1.4188\n",
      "\n",
      "Epoch 00181: val_loss did not improve from -1.13603\n",
      "Epoch 182/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 1.6558 - val_loss: 1.7837\n",
      "\n",
      "Epoch 00182: val_loss did not improve from -1.13603\n",
      "Epoch 183/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 1.0578 - val_loss: 0.7247\n",
      "\n",
      "Epoch 00183: val_loss did not improve from -1.13603\n",
      "Epoch 184/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.7810 - val_loss: 0.5905\n",
      "\n",
      "Epoch 00184: val_loss did not improve from -1.13603\n",
      "Epoch 185/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 0.8130 - val_loss: 1.0968\n",
      "\n",
      "Epoch 00185: val_loss did not improve from -1.13603\n",
      "Epoch 186/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.7001 - val_loss: 0.5796\n",
      "\n",
      "Epoch 00186: val_loss did not improve from -1.13603\n",
      "Epoch 187/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 0.6382 - val_loss: 0.6675\n",
      "\n",
      "Epoch 00187: val_loss did not improve from -1.13603\n",
      "Epoch 188/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 0.5941 - val_loss: 0.9559\n",
      "\n",
      "Epoch 00188: val_loss did not improve from -1.13603\n",
      "Epoch 189/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 0.6651 - val_loss: 1.0484\n",
      "\n",
      "Epoch 00189: val_loss did not improve from -1.13603\n",
      "Epoch 190/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 0.6508 - val_loss: 0.6298\n",
      "\n",
      "Epoch 00190: val_loss did not improve from -1.13603\n",
      "Epoch 191/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.5886 - val_loss: 0.8194\n",
      "\n",
      "Epoch 00191: val_loss did not improve from -1.13603\n",
      "Epoch 192/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 0.6269 - val_loss: 0.5445\n",
      "\n",
      "Epoch 00192: val_loss did not improve from -1.13603\n",
      "Epoch 193/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 0.5669 - val_loss: 0.5479\n",
      "\n",
      "Epoch 00193: val_loss did not improve from -1.13603\n",
      "Epoch 194/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.5316 - val_loss: 0.4904\n",
      "\n",
      "Epoch 00194: val_loss did not improve from -1.13603\n",
      "Epoch 195/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 0.5859 - val_loss: 0.4967\n",
      "\n",
      "Epoch 00195: val_loss did not improve from -1.13603\n",
      "Epoch 196/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.5068 - val_loss: 0.8372\n",
      "\n",
      "Epoch 00196: val_loss did not improve from -1.13603\n",
      "Epoch 197/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 1.1181 - val_loss: 1.0731\n",
      "\n",
      "Epoch 00197: val_loss did not improve from -1.13603\n",
      "Epoch 198/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.7705 - val_loss: 0.3988\n",
      "\n",
      "Epoch 00198: val_loss did not improve from -1.13603\n",
      "Epoch 199/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 0.5009 - val_loss: 0.5314\n",
      "\n",
      "Epoch 00199: val_loss did not improve from -1.13603\n",
      "Epoch 200/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.6608 - val_loss: 0.6359\n",
      "\n",
      "Epoch 00200: val_loss did not improve from -1.13603\n",
      "Epoch 201/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.7748 - val_loss: 0.4978\n",
      "\n",
      "Epoch 00201: val_loss did not improve from -1.13603\n",
      "Epoch 202/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.4092 - val_loss: 0.6065\n",
      "\n",
      "Epoch 00202: val_loss did not improve from -1.13603\n",
      "Epoch 203/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.4964 - val_loss: 1.6165\n",
      "\n",
      "Epoch 00203: val_loss did not improve from -1.13603\n",
      "Epoch 204/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.6947 - val_loss: 0.5041\n",
      "\n",
      "Epoch 00204: val_loss did not improve from -1.13603\n",
      "Epoch 205/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.4739 - val_loss: 0.5476\n",
      "\n",
      "Epoch 00205: val_loss did not improve from -1.13603\n",
      "Epoch 206/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.7224 - val_loss: 0.3596\n",
      "\n",
      "Epoch 00206: val_loss did not improve from -1.13603\n",
      "Epoch 207/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.7849 - val_loss: 0.4159\n",
      "\n",
      "Epoch 00207: val_loss did not improve from -1.13603\n",
      "Epoch 208/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.8855 - val_loss: 0.5620\n",
      "\n",
      "Epoch 00208: val_loss did not improve from -1.13603\n",
      "Epoch 209/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.6752 - val_loss: 0.7697\n",
      "\n",
      "Epoch 00209: val_loss did not improve from -1.13603\n",
      "Epoch 210/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.6693 - val_loss: 1.2018\n",
      "\n",
      "Epoch 00210: val_loss did not improve from -1.13603\n",
      "Epoch 211/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 1.2291 - val_loss: 1.0040\n",
      "\n",
      "Epoch 00211: val_loss did not improve from -1.13603\n",
      "Epoch 212/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.9394 - val_loss: 0.5199\n",
      "\n",
      "Epoch 00212: val_loss did not improve from -1.13603\n",
      "Epoch 213/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.4033 - val_loss: 0.3603\n",
      "\n",
      "Epoch 00213: val_loss did not improve from -1.13603\n",
      "Epoch 214/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.4471 - val_loss: 0.3644\n",
      "\n",
      "Epoch 00214: val_loss did not improve from -1.13603\n",
      "Epoch 215/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.5498 - val_loss: 0.3412\n",
      "\n",
      "Epoch 00215: val_loss did not improve from -1.13603\n",
      "Epoch 216/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.4994 - val_loss: 0.5603\n",
      "\n",
      "Epoch 00216: val_loss did not improve from -1.13603\n",
      "Epoch 217/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.4521 - val_loss: 0.5598\n",
      "\n",
      "Epoch 00217: val_loss did not improve from -1.13603\n",
      "Epoch 218/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.5272 - val_loss: 0.4211\n",
      "\n",
      "Epoch 00218: val_loss did not improve from -1.13603\n",
      "Epoch 219/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.7838 - val_loss: 0.4302\n",
      "\n",
      "Epoch 00219: val_loss did not improve from -1.13603\n",
      "Epoch 220/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.5063 - val_loss: 0.6073\n",
      "\n",
      "Epoch 00220: val_loss did not improve from -1.13603\n",
      "Epoch 221/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 0.4863 - val_loss: 0.3426\n",
      "\n",
      "Epoch 00221: val_loss did not improve from -1.13603\n",
      "Epoch 222/1000\n",
      "281/281 [==============================] - 27s 95ms/step - loss: 532860215360548090413056.0000 - val_loss: 1.7331\n",
      "\n",
      "Epoch 00222: val_loss did not improve from -1.13603\n",
      "Epoch 223/1000\n",
      "281/281 [==============================] - 27s 95ms/step - loss: 1.6685 - val_loss: 1.6943\n",
      "\n",
      "Epoch 00223: val_loss did not improve from -1.13603\n",
      "Epoch 224/1000\n",
      "281/281 [==============================] - 27s 95ms/step - loss: 1.6185 - val_loss: 1.6955\n",
      "\n",
      "Epoch 00224: val_loss did not improve from -1.13603\n",
      "Epoch 225/1000\n",
      "281/281 [==============================] - 26s 94ms/step - loss: 1.6053 - val_loss: 1.6591\n",
      "\n",
      "Epoch 00225: val_loss did not improve from -1.13603\n",
      "Epoch 226/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 1.5963 - val_loss: 1.5574\n",
      "\n",
      "Epoch 00226: val_loss did not improve from -1.13603\n",
      "Epoch 227/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 1.7247 - val_loss: 1.3314\n",
      "\n",
      "Epoch 00227: val_loss did not improve from -1.13603\n",
      "Epoch 228/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 1.3538 - val_loss: 1.1007\n",
      "\n",
      "Epoch 00228: val_loss did not improve from -1.13603\n",
      "Epoch 229/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 1.0122 - val_loss: 0.9560\n",
      "\n",
      "Epoch 00229: val_loss did not improve from -1.13603\n",
      "Epoch 230/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 1.0250 - val_loss: 1.1299\n",
      "\n",
      "Epoch 00230: val_loss did not improve from -1.13603\n",
      "Epoch 231/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 1.0538 - val_loss: 0.9087\n",
      "\n",
      "Epoch 00231: val_loss did not improve from -1.13603\n",
      "Epoch 232/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.8366 - val_loss: 0.7891\n",
      "\n",
      "Epoch 00232: val_loss did not improve from -1.13603\n",
      "Epoch 233/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.9890 - val_loss: 1.1478\n",
      "\n",
      "Epoch 00233: val_loss did not improve from -1.13603\n",
      "Epoch 234/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.9569 - val_loss: 1.6717\n",
      "\n",
      "Epoch 00234: val_loss did not improve from -1.13603\n",
      "Epoch 235/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 1.2228 - val_loss: 1.0756\n",
      "\n",
      "Epoch 00235: val_loss did not improve from -1.13603\n",
      "Epoch 236/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.9235 - val_loss: 1.5083\n",
      "\n",
      "Epoch 00236: val_loss did not improve from -1.13603\n",
      "Epoch 237/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 1.4489 - val_loss: 1.9119\n",
      "\n",
      "Epoch 00237: val_loss did not improve from -1.13603\n",
      "Epoch 238/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.7187 - val_loss: 0.5299\n",
      "\n",
      "Epoch 00238: val_loss did not improve from -1.13603\n",
      "Epoch 239/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.5325 - val_loss: 0.4855\n",
      "\n",
      "Epoch 00239: val_loss did not improve from -1.13603\n",
      "Epoch 240/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.5264 - val_loss: 0.4786\n",
      "\n",
      "Epoch 00240: val_loss did not improve from -1.13603\n",
      "Epoch 241/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.5913 - val_loss: 0.4294\n",
      "\n",
      "Epoch 00241: val_loss did not improve from -1.13603\n",
      "Epoch 242/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 1.1165 - val_loss: 0.3864\n",
      "\n",
      "Epoch 00242: val_loss did not improve from -1.13603\n",
      "Epoch 243/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.7464 - val_loss: 1.5829\n",
      "\n",
      "Epoch 00243: val_loss did not improve from -1.13603\n",
      "Epoch 244/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.8482 - val_loss: 0.9596\n",
      "\n",
      "Epoch 00244: val_loss did not improve from -1.13603\n",
      "Epoch 245/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.9465 - val_loss: 0.7876\n",
      "\n",
      "Epoch 00245: val_loss did not improve from -1.13603\n",
      "Epoch 246/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.7430 - val_loss: 0.6593\n",
      "\n",
      "Epoch 00246: val_loss did not improve from -1.13603\n",
      "Epoch 247/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 1.2407 - val_loss: 1.0116\n",
      "\n",
      "Epoch 00247: val_loss did not improve from -1.13603\n",
      "Epoch 248/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.8059 - val_loss: 0.6553\n",
      "\n",
      "Epoch 00248: val_loss did not improve from -1.13603\n",
      "Epoch 249/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.8889 - val_loss: 1.8467\n",
      "\n",
      "Epoch 00249: val_loss did not improve from -1.13603\n",
      "Epoch 250/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 1.1950 - val_loss: 1.7750\n",
      "\n",
      "Epoch 00250: val_loss did not improve from -1.13603\n",
      "Epoch 251/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.8610 - val_loss: 0.6629\n",
      "\n",
      "Epoch 00251: val_loss did not improve from -1.13603\n",
      "Epoch 252/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.5862 - val_loss: 0.4851\n",
      "\n",
      "Epoch 00252: val_loss did not improve from -1.13603\n",
      "Epoch 253/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.7468 - val_loss: 1.1594\n",
      "\n",
      "Epoch 00253: val_loss did not improve from -1.13603\n",
      "Epoch 254/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 1.0406 - val_loss: 0.8308\n",
      "\n",
      "Epoch 00254: val_loss did not improve from -1.13603\n",
      "Epoch 255/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.8040 - val_loss: 0.5383\n",
      "\n",
      "Epoch 00255: val_loss did not improve from -1.13603\n",
      "Epoch 256/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 1.1393 - val_loss: 1.1290\n",
      "\n",
      "Epoch 00256: val_loss did not improve from -1.13603\n",
      "Epoch 257/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.7736 - val_loss: 0.5341\n",
      "\n",
      "Epoch 00257: val_loss did not improve from -1.13603\n",
      "Epoch 258/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.6109 - val_loss: 0.6483\n",
      "\n",
      "Epoch 00258: val_loss did not improve from -1.13603\n",
      "Epoch 259/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 1.0653 - val_loss: 0.7150\n",
      "\n",
      "Epoch 00259: val_loss did not improve from -1.13603\n",
      "Epoch 260/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.6178 - val_loss: 0.5202\n",
      "\n",
      "Epoch 00260: val_loss did not improve from -1.13603\n",
      "Epoch 261/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.9500 - val_loss: 0.4700\n",
      "\n",
      "Epoch 00261: val_loss did not improve from -1.13603\n",
      "Epoch 262/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 1.0152 - val_loss: 1.2247\n",
      "\n",
      "Epoch 00262: val_loss did not improve from -1.13603\n",
      "Epoch 263/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 1.3959 - val_loss: 1.1204\n",
      "\n",
      "Epoch 00263: val_loss did not improve from -1.13603\n",
      "Epoch 264/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 2.3043 - val_loss: 1.9475\n",
      "\n",
      "Epoch 00264: val_loss did not improve from -1.13603\n",
      "Epoch 265/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 1.9527 - val_loss: 1.9422\n",
      "\n",
      "Epoch 00265: val_loss did not improve from -1.13603\n",
      "Epoch 266/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 1.9562 - val_loss: 1.9423\n",
      "\n",
      "Epoch 00266: val_loss did not improve from -1.13603\n",
      "Epoch 267/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 1.9483 - val_loss: 1.9341\n",
      "\n",
      "Epoch 00267: val_loss did not improve from -1.13603\n",
      "Epoch 268/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 1.9018 - val_loss: 1.9029\n",
      "\n",
      "Epoch 00268: val_loss did not improve from -1.13603\n",
      "Epoch 269/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 1.3478 - val_loss: 0.9180\n",
      "\n",
      "Epoch 00269: val_loss did not improve from -1.13603\n",
      "Epoch 270/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.9715 - val_loss: 0.6606\n",
      "\n",
      "Epoch 00270: val_loss did not improve from -1.13603\n",
      "Epoch 271/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.9647 - val_loss: 1.2509\n",
      "\n",
      "Epoch 00271: val_loss did not improve from -1.13603\n",
      "Epoch 272/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.6741 - val_loss: 1.2034\n",
      "\n",
      "Epoch 00272: val_loss did not improve from -1.13603\n",
      "Epoch 273/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 1.0406 - val_loss: 0.7636\n",
      "\n",
      "Epoch 00273: val_loss did not improve from -1.13603\n",
      "Epoch 274/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.8050 - val_loss: 0.5070\n",
      "\n",
      "Epoch 00274: val_loss did not improve from -1.13603\n",
      "Epoch 275/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 1.0847 - val_loss: 2.0419\n",
      "\n",
      "Epoch 00275: val_loss did not improve from -1.13603\n",
      "Epoch 276/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 2.4584 - val_loss: 1.7898\n",
      "\n",
      "Epoch 00276: val_loss did not improve from -1.13603\n",
      "Epoch 277/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 1.3614 - val_loss: 0.5166\n",
      "\n",
      "Epoch 00277: val_loss did not improve from -1.13603\n",
      "Epoch 278/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.6713 - val_loss: 0.5534\n",
      "\n",
      "Epoch 00278: val_loss did not improve from -1.13603\n",
      "Epoch 279/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.7735 - val_loss: 0.4658\n",
      "\n",
      "Epoch 00279: val_loss did not improve from -1.13603\n",
      "Epoch 280/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.5174 - val_loss: 0.6346\n",
      "\n",
      "Epoch 00280: val_loss did not improve from -1.13603\n",
      "Epoch 281/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.6285 - val_loss: 0.5510\n",
      "\n",
      "Epoch 00281: val_loss did not improve from -1.13603\n",
      "Epoch 282/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.5674 - val_loss: 0.5565\n",
      "\n",
      "Epoch 00282: val_loss did not improve from -1.13603\n",
      "Epoch 283/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.4834 - val_loss: 0.5569\n",
      "\n",
      "Epoch 00283: val_loss did not improve from -1.13603\n",
      "Epoch 284/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.6019 - val_loss: 1.3044\n",
      "\n",
      "Epoch 00284: val_loss did not improve from -1.13603\n",
      "Epoch 285/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.5254 - val_loss: 0.5031\n",
      "\n",
      "Epoch 00285: val_loss did not improve from -1.13603\n",
      "Epoch 286/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.6151 - val_loss: 1.9858\n",
      "\n",
      "Epoch 00286: val_loss did not improve from -1.13603\n",
      "Epoch 287/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.8629 - val_loss: 1.8162\n",
      "\n",
      "Epoch 00287: val_loss did not improve from -1.13603\n",
      "Epoch 288/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.5260 - val_loss: 0.4894\n",
      "\n",
      "Epoch 00288: val_loss did not improve from -1.13603\n",
      "Epoch 289/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.7921 - val_loss: 0.8037\n",
      "\n",
      "Epoch 00289: val_loss did not improve from -1.13603\n",
      "Epoch 290/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 1.0092 - val_loss: 0.6338\n",
      "\n",
      "Epoch 00290: val_loss did not improve from -1.13603\n",
      "Epoch 291/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 1.9121 - val_loss: 1.5947\n",
      "\n",
      "Epoch 00291: val_loss did not improve from -1.13603\n",
      "Epoch 292/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 1.5160 - val_loss: 1.8862\n",
      "\n",
      "Epoch 00292: val_loss did not improve from -1.13603\n",
      "Epoch 293/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 1.3233 - val_loss: 1.1161\n",
      "\n",
      "Epoch 00293: val_loss did not improve from -1.13603\n",
      "Epoch 294/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 1.2692 - val_loss: 1.2187\n",
      "\n",
      "Epoch 00294: val_loss did not improve from -1.13603\n",
      "Epoch 295/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.9043 - val_loss: 0.7094\n",
      "\n",
      "Epoch 00295: val_loss did not improve from -1.13603\n",
      "Epoch 296/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.8063 - val_loss: 1.0742\n",
      "\n",
      "Epoch 00296: val_loss did not improve from -1.13603\n",
      "Epoch 297/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.9378 - val_loss: 0.6404\n",
      "\n",
      "Epoch 00297: val_loss did not improve from -1.13603\n",
      "Epoch 298/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.9560 - val_loss: 0.6532\n",
      "\n",
      "Epoch 00298: val_loss did not improve from -1.13603\n",
      "Epoch 299/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.6102 - val_loss: 0.6250\n",
      "\n",
      "Epoch 00299: val_loss did not improve from -1.13603\n",
      "Epoch 300/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.5692 - val_loss: 1.5209\n",
      "\n",
      "Epoch 00300: val_loss did not improve from -1.13603\n",
      "Epoch 301/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.7956 - val_loss: 0.5314\n",
      "\n",
      "Epoch 00301: val_loss did not improve from -1.13603\n",
      "Epoch 302/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.8401 - val_loss: 1.5666\n",
      "\n",
      "Epoch 00302: val_loss did not improve from -1.13603\n",
      "Epoch 303/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 1.4293 - val_loss: 0.7228\n",
      "\n",
      "Epoch 00303: val_loss did not improve from -1.13603\n",
      "Epoch 304/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.7681 - val_loss: 0.7567\n",
      "\n",
      "Epoch 00304: val_loss did not improve from -1.13603\n",
      "Epoch 305/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.7197 - val_loss: 0.7108\n",
      "\n",
      "Epoch 00305: val_loss did not improve from -1.13603\n",
      "Epoch 306/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.5482 - val_loss: 0.5115\n",
      "\n",
      "Epoch 00306: val_loss did not improve from -1.13603\n",
      "Epoch 307/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.7016 - val_loss: 0.4594\n",
      "\n",
      "Epoch 00307: val_loss did not improve from -1.13603\n",
      "Epoch 308/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 1.1907 - val_loss: 0.7337\n",
      "\n",
      "Epoch 00308: val_loss did not improve from -1.13603\n",
      "Epoch 309/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.8253 - val_loss: 0.7872\n",
      "\n",
      "Epoch 00309: val_loss did not improve from -1.13603\n",
      "Epoch 310/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.6389 - val_loss: 0.5177\n",
      "\n",
      "Epoch 00310: val_loss did not improve from -1.13603\n",
      "Epoch 311/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.5377 - val_loss: 0.5568\n",
      "\n",
      "Epoch 00311: val_loss did not improve from -1.13603\n",
      "Epoch 312/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.4627 - val_loss: 0.9108\n",
      "\n",
      "Epoch 00312: val_loss did not improve from -1.13603\n",
      "Epoch 313/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.4600 - val_loss: 0.3968\n",
      "\n",
      "Epoch 00313: val_loss did not improve from -1.13603\n",
      "Epoch 314/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 1.0986 - val_loss: 1.1485\n",
      "\n",
      "Epoch 00314: val_loss did not improve from -1.13603\n",
      "Epoch 315/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.6377 - val_loss: 1.0236\n",
      "\n",
      "Epoch 00315: val_loss did not improve from -1.13603\n",
      "Epoch 316/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: 0.5713 - val_loss: 0.4175\n",
      "\n",
      "Epoch 00316: val_loss did not improve from -1.13603\n",
      "Epoch 317/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.6128 - val_loss: 0.4832\n",
      "\n",
      "Epoch 00317: val_loss did not improve from -1.13603\n",
      "Epoch 318/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.4151 - val_loss: 1.0067\n",
      "\n",
      "Epoch 00318: val_loss did not improve from -1.13603\n",
      "Epoch 319/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.6415 - val_loss: 0.5709\n",
      "\n",
      "Epoch 00319: val_loss did not improve from -1.13603\n",
      "Epoch 320/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.6542 - val_loss: 0.8890\n",
      "\n",
      "Epoch 00320: val_loss did not improve from -1.13603\n",
      "Epoch 321/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.8807 - val_loss: 0.6135\n",
      "\n",
      "Epoch 00321: val_loss did not improve from -1.13603\n",
      "Epoch 322/1000\n",
      "281/281 [==============================] - 25s 91ms/step - loss: 0.6338 - val_loss: 0.5861\n",
      "\n",
      "Epoch 00322: val_loss did not improve from -1.13603\n",
      "Epoch 323/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.6548 - val_loss: 0.5478\n",
      "\n",
      "Epoch 00323: val_loss did not improve from -1.13603\n",
      "Epoch 324/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 1.4429 - val_loss: 1.5708\n",
      "\n",
      "Epoch 00324: val_loss did not improve from -1.13603\n",
      "Epoch 325/1000\n",
      "281/281 [==============================] - 25s 91ms/step - loss: 1.8420 - val_loss: 2.0429\n",
      "\n",
      "Epoch 00325: val_loss did not improve from -1.13603\n",
      "Epoch 326/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 1.9524 - val_loss: 1.7820\n",
      "\n",
      "Epoch 00326: val_loss did not improve from -1.13603\n",
      "Epoch 327/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 1.4540 - val_loss: 0.8897\n",
      "\n",
      "Epoch 00327: val_loss did not improve from -1.13603\n",
      "Epoch 328/1000\n",
      "281/281 [==============================] - 25s 91ms/step - loss: 1.5601 - val_loss: 1.3670\n",
      "\n",
      "Epoch 00328: val_loss did not improve from -1.13603\n",
      "Epoch 329/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.6988 - val_loss: 0.5333\n",
      "\n",
      "Epoch 00329: val_loss did not improve from -1.13603\n",
      "Epoch 330/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.4895 - val_loss: 0.8737\n",
      "\n",
      "Epoch 00330: val_loss did not improve from -1.13603\n",
      "Epoch 331/1000\n",
      "281/281 [==============================] - 25s 91ms/step - loss: 0.9830 - val_loss: 0.7178\n",
      "\n",
      "Epoch 00331: val_loss did not improve from -1.13603\n",
      "Epoch 332/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 1.5863 - val_loss: 0.9301\n",
      "\n",
      "Epoch 00332: val_loss did not improve from -1.13603\n",
      "Epoch 333/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.7215 - val_loss: 0.4556\n",
      "\n",
      "Epoch 00333: val_loss did not improve from -1.13603\n",
      "Epoch 334/1000\n",
      "281/281 [==============================] - 25s 91ms/step - loss: 0.5102 - val_loss: 0.6894\n",
      "\n",
      "Epoch 00334: val_loss did not improve from -1.13603\n",
      "Epoch 335/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: 0.3562 - val_loss: 1.1554\n",
      "\n",
      "Epoch 00335: val_loss did not improve from -1.13603\n",
      "Epoch 336/1000\n",
      "281/281 [==============================] - 25s 91ms/step - loss: 0.3571 - val_loss: 0.2848\n",
      "\n",
      "Epoch 00336: val_loss did not improve from -1.13603\n",
      "Epoch 337/1000\n",
      "281/281 [==============================] - 25s 91ms/step - loss: 0.2598 - val_loss: 0.3122\n",
      "\n",
      "Epoch 00337: val_loss did not improve from -1.13603\n",
      "Epoch 338/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: 0.1911 - val_loss: 0.2127\n",
      "\n",
      "Epoch 00338: val_loss did not improve from -1.13603\n",
      "Epoch 339/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: 0.1753 - val_loss: 0.0944\n",
      "\n",
      "Epoch 00339: val_loss did not improve from -1.13603\n",
      "Epoch 340/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.1042 - val_loss: 0.0686\n",
      "\n",
      "Epoch 00340: val_loss did not improve from -1.13603\n",
      "Epoch 341/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.1328 - val_loss: 0.0193\n",
      "\n",
      "Epoch 00341: val_loss did not improve from -1.13603\n",
      "Epoch 342/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: 0.1917 - val_loss: 0.4824\n",
      "\n",
      "Epoch 00342: val_loss did not improve from -1.13603\n",
      "Epoch 343/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: 0.2129 - val_loss: 0.3451\n",
      "\n",
      "Epoch 00343: val_loss did not improve from -1.13603\n",
      "Epoch 344/1000\n",
      "281/281 [==============================] - 25s 91ms/step - loss: 0.1823 - val_loss: 0.1305\n",
      "\n",
      "Epoch 00344: val_loss did not improve from -1.13603\n",
      "Epoch 345/1000\n",
      "281/281 [==============================] - 25s 91ms/step - loss: -0.0330 - val_loss: 1.9603\n",
      "\n",
      "Epoch 00345: val_loss did not improve from -1.13603\n",
      "Epoch 346/1000\n",
      "281/281 [==============================] - 25s 91ms/step - loss: 0.1260 - val_loss: -0.0699\n",
      "\n",
      "Epoch 00346: val_loss did not improve from -1.13603\n",
      "Epoch 347/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.0912 - val_loss: -0.1618\n",
      "\n",
      "Epoch 00347: val_loss did not improve from -1.13603\n",
      "Epoch 348/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: -0.1119 - val_loss: -0.0118\n",
      "\n",
      "Epoch 00348: val_loss did not improve from -1.13603\n",
      "Epoch 349/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -0.2084 - val_loss: -0.2270\n",
      "\n",
      "Epoch 00349: val_loss did not improve from -1.13603\n",
      "Epoch 350/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.1355 - val_loss: 0.7257\n",
      "\n",
      "Epoch 00350: val_loss did not improve from -1.13603\n",
      "Epoch 351/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: -0.2227 - val_loss: 0.1273\n",
      "\n",
      "Epoch 00351: val_loss did not improve from -1.13603\n",
      "Epoch 352/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.2623 - val_loss: -0.2651\n",
      "\n",
      "Epoch 00352: val_loss did not improve from -1.13603\n",
      "Epoch 353/1000\n",
      "281/281 [==============================] - 25s 91ms/step - loss: -0.2434 - val_loss: -0.1185\n",
      "\n",
      "Epoch 00353: val_loss did not improve from -1.13603\n",
      "Epoch 354/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.1758 - val_loss: 0.0726\n",
      "\n",
      "Epoch 00354: val_loss did not improve from -1.13603\n",
      "Epoch 355/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: -0.1979 - val_loss: -0.2776\n",
      "\n",
      "Epoch 00355: val_loss did not improve from -1.13603\n",
      "Epoch 356/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.1099 - val_loss: -0.1878\n",
      "\n",
      "Epoch 00356: val_loss did not improve from -1.13603\n",
      "Epoch 357/1000\n",
      "281/281 [==============================] - 25s 91ms/step - loss: -0.2484 - val_loss: -0.2850\n",
      "\n",
      "Epoch 00357: val_loss did not improve from -1.13603\n",
      "Epoch 358/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.3117 - val_loss: -0.3516\n",
      "\n",
      "Epoch 00358: val_loss did not improve from -1.13603\n",
      "Epoch 359/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.1252 - val_loss: -0.3290\n",
      "\n",
      "Epoch 00359: val_loss did not improve from -1.13603\n",
      "Epoch 360/1000\n",
      "281/281 [==============================] - 25s 91ms/step - loss: -0.3501 - val_loss: -0.1436\n",
      "\n",
      "Epoch 00360: val_loss did not improve from -1.13603\n",
      "Epoch 361/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: -0.3942 - val_loss: -0.4532\n",
      "\n",
      "Epoch 00361: val_loss did not improve from -1.13603\n",
      "Epoch 362/1000\n",
      "281/281 [==============================] - 25s 91ms/step - loss: -0.5176 - val_loss: -0.4557\n",
      "\n",
      "Epoch 00362: val_loss did not improve from -1.13603\n",
      "Epoch 363/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.5037 - val_loss: -0.1633\n",
      "\n",
      "Epoch 00363: val_loss did not improve from -1.13603\n",
      "Epoch 364/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.5447 - val_loss: -0.1159\n",
      "\n",
      "Epoch 00364: val_loss did not improve from -1.13603\n",
      "Epoch 365/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.5513 - val_loss: 0.5860\n",
      "\n",
      "Epoch 00365: val_loss did not improve from -1.13603\n",
      "Epoch 366/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.5611 - val_loss: -0.5579\n",
      "\n",
      "Epoch 00366: val_loss did not improve from -1.13603\n",
      "Epoch 367/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.5181 - val_loss: -0.2041\n",
      "\n",
      "Epoch 00367: val_loss did not improve from -1.13603\n",
      "Epoch 368/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.5341 - val_loss: -0.5888\n",
      "\n",
      "Epoch 00368: val_loss did not improve from -1.13603\n",
      "Epoch 369/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.5754 - val_loss: -0.5452\n",
      "\n",
      "Epoch 00369: val_loss did not improve from -1.13603\n",
      "Epoch 370/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.4717 - val_loss: -0.1546\n",
      "\n",
      "Epoch 00370: val_loss did not improve from -1.13603\n",
      "Epoch 371/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.4740 - val_loss: -0.4609\n",
      "\n",
      "Epoch 00371: val_loss did not improve from -1.13603\n",
      "Epoch 372/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: 0.0368 - val_loss: 0.5782\n",
      "\n",
      "Epoch 00372: val_loss did not improve from -1.13603\n",
      "Epoch 373/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: 0.1225 - val_loss: -0.0591\n",
      "\n",
      "Epoch 00373: val_loss did not improve from -1.13603\n",
      "Epoch 374/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: 0.0443 - val_loss: -0.1266\n",
      "\n",
      "Epoch 00374: val_loss did not improve from -1.13603\n",
      "Epoch 375/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.2935 - val_loss: -0.1459\n",
      "\n",
      "Epoch 00375: val_loss did not improve from -1.13603\n",
      "Epoch 376/1000\n",
      "281/281 [==============================] - 26s 93ms/step - loss: -0.3585 - val_loss: -0.1984\n",
      "\n",
      "Epoch 00376: val_loss did not improve from -1.13603\n",
      "Epoch 377/1000\n",
      "281/281 [==============================] - 25s 91ms/step - loss: -0.3993 - val_loss: -0.2853\n",
      "\n",
      "Epoch 00377: val_loss did not improve from -1.13603\n",
      "Epoch 378/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.1733 - val_loss: 0.0238\n",
      "\n",
      "Epoch 00378: val_loss did not improve from -1.13603\n",
      "Epoch 379/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -0.2391 - val_loss: -0.2107\n",
      "\n",
      "Epoch 00379: val_loss did not improve from -1.13603\n",
      "Epoch 380/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -0.2923 - val_loss: -0.2476\n",
      "\n",
      "Epoch 00380: val_loss did not improve from -1.13603\n",
      "Epoch 381/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -0.2743 - val_loss: -0.2524\n",
      "\n",
      "Epoch 00381: val_loss did not improve from -1.13603\n",
      "Epoch 382/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -0.3064 - val_loss: -0.2684\n",
      "\n",
      "Epoch 00382: val_loss did not improve from -1.13603\n",
      "Epoch 383/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: -0.3593 - val_loss: -0.0843\n",
      "\n",
      "Epoch 00383: val_loss did not improve from -1.13603\n",
      "Epoch 384/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.4732 - val_loss: -0.1604\n",
      "\n",
      "Epoch 00384: val_loss did not improve from -1.13603\n",
      "Epoch 385/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.3986 - val_loss: -0.4067\n",
      "\n",
      "Epoch 00385: val_loss did not improve from -1.13603\n",
      "Epoch 386/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.5043 - val_loss: -0.3481\n",
      "\n",
      "Epoch 00386: val_loss did not improve from -1.13603\n",
      "Epoch 387/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.5235 - val_loss: -0.3907\n",
      "\n",
      "Epoch 00387: val_loss did not improve from -1.13603\n",
      "Epoch 388/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -0.5434 - val_loss: -0.4359\n",
      "\n",
      "Epoch 00388: val_loss did not improve from -1.13603\n",
      "Epoch 389/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.6077 - val_loss: -0.0033\n",
      "\n",
      "Epoch 00389: val_loss did not improve from -1.13603\n",
      "Epoch 390/1000\n",
      "281/281 [==============================] - 25s 91ms/step - loss: -0.6454 - val_loss: -0.3797\n",
      "\n",
      "Epoch 00390: val_loss did not improve from -1.13603\n",
      "Epoch 391/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -0.6817 - val_loss: -0.4134\n",
      "\n",
      "Epoch 00391: val_loss did not improve from -1.13603\n",
      "Epoch 392/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -0.7103 - val_loss: -0.5665\n",
      "\n",
      "Epoch 00392: val_loss did not improve from -1.13603\n",
      "Epoch 393/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -0.7080 - val_loss: -0.4135\n",
      "\n",
      "Epoch 00393: val_loss did not improve from -1.13603\n",
      "Epoch 394/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: -0.7884 - val_loss: -0.4019\n",
      "\n",
      "Epoch 00394: val_loss did not improve from -1.13603\n",
      "Epoch 395/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: -0.5919 - val_loss: -0.4672\n",
      "\n",
      "Epoch 00395: val_loss did not improve from -1.13603\n",
      "Epoch 396/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.6794 - val_loss: -0.4261\n",
      "\n",
      "Epoch 00396: val_loss did not improve from -1.13603\n",
      "Epoch 397/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.6569 - val_loss: -0.3379\n",
      "\n",
      "Epoch 00397: val_loss did not improve from -1.13603\n",
      "Epoch 398/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -0.7057 - val_loss: -0.5717\n",
      "\n",
      "Epoch 00398: val_loss did not improve from -1.13603\n",
      "Epoch 399/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.7899 - val_loss: -0.5582\n",
      "\n",
      "Epoch 00399: val_loss did not improve from -1.13603\n",
      "Epoch 400/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.7897 - val_loss: -0.6396\n",
      "\n",
      "Epoch 00400: val_loss did not improve from -1.13603\n",
      "Epoch 401/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.8581 - val_loss: -0.6729\n",
      "\n",
      "Epoch 00401: val_loss did not improve from -1.13603\n",
      "Epoch 402/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.6904 - val_loss: -0.5760\n",
      "\n",
      "Epoch 00402: val_loss did not improve from -1.13603\n",
      "Epoch 403/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.8265 - val_loss: -0.5289\n",
      "\n",
      "Epoch 00403: val_loss did not improve from -1.13603\n",
      "Epoch 404/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.8286 - val_loss: -0.2431\n",
      "\n",
      "Epoch 00404: val_loss did not improve from -1.13603\n",
      "Epoch 405/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: -0.7051 - val_loss: -0.4314\n",
      "\n",
      "Epoch 00405: val_loss did not improve from -1.13603\n",
      "Epoch 406/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -0.7033 - val_loss: -0.4535\n",
      "\n",
      "Epoch 00406: val_loss did not improve from -1.13603\n",
      "Epoch 407/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: -0.7196 - val_loss: -0.4991\n",
      "\n",
      "Epoch 00407: val_loss did not improve from -1.13603\n",
      "Epoch 408/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: -0.7401 - val_loss: -0.4065\n",
      "\n",
      "Epoch 00408: val_loss did not improve from -1.13603\n",
      "Epoch 409/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: -0.7407 - val_loss: -0.5408\n",
      "\n",
      "Epoch 00409: val_loss did not improve from -1.13603\n",
      "Epoch 410/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: -0.7572 - val_loss: -0.5316\n",
      "\n",
      "Epoch 00410: val_loss did not improve from -1.13603\n",
      "Epoch 411/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: -0.6851 - val_loss: -0.5192\n",
      "\n",
      "Epoch 00411: val_loss did not improve from -1.13603\n",
      "Epoch 412/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.7613 - val_loss: -0.3148\n",
      "\n",
      "Epoch 00412: val_loss did not improve from -1.13603\n",
      "Epoch 413/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: -0.7634 - val_loss: -0.5630\n",
      "\n",
      "Epoch 00413: val_loss did not improve from -1.13603\n",
      "Epoch 414/1000\n",
      "281/281 [==============================] - 25s 91ms/step - loss: -0.7581 - val_loss: -0.2887\n",
      "\n",
      "Epoch 00414: val_loss did not improve from -1.13603\n",
      "Epoch 415/1000\n",
      "281/281 [==============================] - 25s 91ms/step - loss: -0.7891 - val_loss: -0.5380\n",
      "\n",
      "Epoch 00415: val_loss did not improve from -1.13603\n",
      "Epoch 416/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.6226 - val_loss: 0.0344\n",
      "\n",
      "Epoch 00416: val_loss did not improve from -1.13603\n",
      "Epoch 417/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.6512 - val_loss: -0.6027\n",
      "\n",
      "Epoch 00417: val_loss did not improve from -1.13603\n",
      "Epoch 418/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.7353 - val_loss: -0.6308\n",
      "\n",
      "Epoch 00418: val_loss did not improve from -1.13603\n",
      "Epoch 419/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.6694 - val_loss: -0.4903\n",
      "\n",
      "Epoch 00419: val_loss did not improve from -1.13603\n",
      "Epoch 420/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.7320 - val_loss: -0.5759\n",
      "\n",
      "Epoch 00420: val_loss did not improve from -1.13603\n",
      "Epoch 421/1000\n",
      "281/281 [==============================] - 26s 92ms/step - loss: -0.7404 - val_loss: -0.5948\n",
      "\n",
      "Epoch 00421: val_loss did not improve from -1.13603\n",
      "Epoch 422/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.7692 - val_loss: -0.6515\n",
      "\n",
      "Epoch 00422: val_loss did not improve from -1.13603\n",
      "Epoch 423/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.7945 - val_loss: 0.0109\n",
      "\n",
      "Epoch 00423: val_loss did not improve from -1.13603\n",
      "Epoch 424/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.6004 - val_loss: -0.2026\n",
      "\n",
      "Epoch 00424: val_loss did not improve from -1.13603\n",
      "Epoch 425/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.7126 - val_loss: 10.9984\n",
      "\n",
      "Epoch 00425: val_loss did not improve from -1.13603\n",
      "Epoch 426/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.7863 - val_loss: -0.5614\n",
      "\n",
      "Epoch 00426: val_loss did not improve from -1.13603\n",
      "Epoch 427/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.8242 - val_loss: -0.6319\n",
      "\n",
      "Epoch 00427: val_loss did not improve from -1.13603\n",
      "Epoch 428/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.7915 - val_loss: -0.6371\n",
      "\n",
      "Epoch 00428: val_loss did not improve from -1.13603\n",
      "Epoch 429/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.8792 - val_loss: -0.5924\n",
      "\n",
      "Epoch 00429: val_loss did not improve from -1.13603\n",
      "Epoch 430/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.7253 - val_loss: 0.0087\n",
      "\n",
      "Epoch 00430: val_loss did not improve from -1.13603\n",
      "Epoch 431/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.6669 - val_loss: -0.6671\n",
      "\n",
      "Epoch 00431: val_loss did not improve from -1.13603\n",
      "Epoch 432/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.8872 - val_loss: -0.4791\n",
      "\n",
      "Epoch 00432: val_loss did not improve from -1.13603\n",
      "Epoch 433/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.8344 - val_loss: -0.6345\n",
      "\n",
      "Epoch 00433: val_loss did not improve from -1.13603\n",
      "Epoch 434/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.8729 - val_loss: -0.5683\n",
      "\n",
      "Epoch 00434: val_loss did not improve from -1.13603\n",
      "Epoch 435/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.8003 - val_loss: -0.5101\n",
      "\n",
      "Epoch 00435: val_loss did not improve from -1.13603\n",
      "Epoch 436/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.8896 - val_loss: -0.4122\n",
      "\n",
      "Epoch 00436: val_loss did not improve from -1.13603\n",
      "Epoch 437/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.7401 - val_loss: -0.1004\n",
      "\n",
      "Epoch 00437: val_loss did not improve from -1.13603\n",
      "Epoch 438/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.7481 - val_loss: -0.1561\n",
      "\n",
      "Epoch 00438: val_loss did not improve from -1.13603\n",
      "Epoch 439/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.7957 - val_loss: -0.5517\n",
      "\n",
      "Epoch 00439: val_loss did not improve from -1.13603\n",
      "Epoch 440/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.8281 - val_loss: -0.3476\n",
      "\n",
      "Epoch 00440: val_loss did not improve from -1.13603\n",
      "Epoch 441/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.6847 - val_loss: -0.6463\n",
      "\n",
      "Epoch 00441: val_loss did not improve from -1.13603\n",
      "Epoch 442/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.8347 - val_loss: -0.6547\n",
      "\n",
      "Epoch 00442: val_loss did not improve from -1.13603\n",
      "Epoch 443/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.8165 - val_loss: -0.3417\n",
      "\n",
      "Epoch 00443: val_loss did not improve from -1.13603\n",
      "Epoch 444/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.8156 - val_loss: -0.7094\n",
      "\n",
      "Epoch 00444: val_loss did not improve from -1.13603\n",
      "Epoch 445/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.8580 - val_loss: -0.5233\n",
      "\n",
      "Epoch 00445: val_loss did not improve from -1.13603\n",
      "Epoch 446/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.7642 - val_loss: -0.6773\n",
      "\n",
      "Epoch 00446: val_loss did not improve from -1.13603\n",
      "Epoch 447/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.8104 - val_loss: -0.3681\n",
      "\n",
      "Epoch 00447: val_loss did not improve from -1.13603\n",
      "Epoch 448/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.9188 - val_loss: -0.5729\n",
      "\n",
      "Epoch 00448: val_loss did not improve from -1.13603\n",
      "Epoch 449/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.9454 - val_loss: -0.2493\n",
      "\n",
      "Epoch 00449: val_loss did not improve from -1.13603\n",
      "Epoch 450/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.9453 - val_loss: -0.6769\n",
      "\n",
      "Epoch 00450: val_loss did not improve from -1.13603\n",
      "Epoch 451/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.9716 - val_loss: -0.5571\n",
      "\n",
      "Epoch 00451: val_loss did not improve from -1.13603\n",
      "Epoch 452/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.9078 - val_loss: -0.5157\n",
      "\n",
      "Epoch 00452: val_loss did not improve from -1.13603\n",
      "Epoch 453/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.9070 - val_loss: -0.8115\n",
      "\n",
      "Epoch 00453: val_loss did not improve from -1.13603\n",
      "Epoch 454/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.8893 - val_loss: -0.5605\n",
      "\n",
      "Epoch 00454: val_loss did not improve from -1.13603\n",
      "Epoch 455/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.8197 - val_loss: -0.4223\n",
      "\n",
      "Epoch 00455: val_loss did not improve from -1.13603\n",
      "Epoch 456/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.8212 - val_loss: -0.5803\n",
      "\n",
      "Epoch 00456: val_loss did not improve from -1.13603\n",
      "Epoch 457/1000\n",
      "281/281 [==============================] - 26s 91ms/step - loss: -0.9313 - val_loss: -0.7797\n",
      "\n",
      "Epoch 00457: val_loss did not improve from -1.13603\n",
      "Epoch 458/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.8377 - val_loss: -0.5282\n",
      "\n",
      "Epoch 00458: val_loss did not improve from -1.13603\n",
      "Epoch 459/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.8236 - val_loss: -0.5445\n",
      "\n",
      "Epoch 00459: val_loss did not improve from -1.13603\n",
      "Epoch 460/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.8745 - val_loss: -0.0644\n",
      "\n",
      "Epoch 00460: val_loss did not improve from -1.13603\n",
      "Epoch 461/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.9220 - val_loss: -0.4088\n",
      "\n",
      "Epoch 00461: val_loss did not improve from -1.13603\n",
      "Epoch 462/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.9470 - val_loss: -0.4294\n",
      "\n",
      "Epoch 00462: val_loss did not improve from -1.13603\n",
      "Epoch 463/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.5438 - val_loss: -0.3009\n",
      "\n",
      "Epoch 00463: val_loss did not improve from -1.13603\n",
      "Epoch 464/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.6505 - val_loss: -0.4292\n",
      "\n",
      "Epoch 00464: val_loss did not improve from -1.13603\n",
      "Epoch 465/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.6093 - val_loss: -0.3922\n",
      "\n",
      "Epoch 00465: val_loss did not improve from -1.13603\n",
      "Epoch 466/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.7023 - val_loss: -0.3973\n",
      "\n",
      "Epoch 00466: val_loss did not improve from -1.13603\n",
      "Epoch 467/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.8454 - val_loss: -0.3231\n",
      "\n",
      "Epoch 00467: val_loss did not improve from -1.13603\n",
      "Epoch 468/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.8229 - val_loss: -0.1552\n",
      "\n",
      "Epoch 00468: val_loss did not improve from -1.13603\n",
      "Epoch 469/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.7226 - val_loss: -0.3704\n",
      "\n",
      "Epoch 00469: val_loss did not improve from -1.13603\n",
      "Epoch 470/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.7956 - val_loss: 0.0996\n",
      "\n",
      "Epoch 00470: val_loss did not improve from -1.13603\n",
      "Epoch 471/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.7536 - val_loss: -0.3931\n",
      "\n",
      "Epoch 00471: val_loss did not improve from -1.13603\n",
      "Epoch 472/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.8585 - val_loss: -0.5375\n",
      "\n",
      "Epoch 00472: val_loss did not improve from -1.13603\n",
      "Epoch 473/1000\n",
      "281/281 [==============================] - 25s 87ms/step - loss: -0.9049 - val_loss: -0.5634\n",
      "\n",
      "Epoch 00473: val_loss did not improve from -1.13603\n",
      "Epoch 474/1000\n",
      "281/281 [==============================] - 25s 87ms/step - loss: -0.9487 - val_loss: -0.7343\n",
      "\n",
      "Epoch 00474: val_loss did not improve from -1.13603\n",
      "Epoch 475/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.9936 - val_loss: -0.7769\n",
      "\n",
      "Epoch 00475: val_loss did not improve from -1.13603\n",
      "Epoch 476/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.8801 - val_loss: -0.5838\n",
      "\n",
      "Epoch 00476: val_loss did not improve from -1.13603\n",
      "Epoch 477/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.9186 - val_loss: -0.5064\n",
      "\n",
      "Epoch 00477: val_loss did not improve from -1.13603\n",
      "Epoch 478/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.8438 - val_loss: -0.7407\n",
      "\n",
      "Epoch 00478: val_loss did not improve from -1.13603\n",
      "Epoch 479/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.8359 - val_loss: -0.4005\n",
      "\n",
      "Epoch 00479: val_loss did not improve from -1.13603\n",
      "Epoch 480/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.7671 - val_loss: -0.7625\n",
      "\n",
      "Epoch 00480: val_loss did not improve from -1.13603\n",
      "Epoch 481/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -1.0223 - val_loss: -0.7576\n",
      "\n",
      "Epoch 00481: val_loss did not improve from -1.13603\n",
      "Epoch 482/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -1.0222 - val_loss: -0.5573\n",
      "\n",
      "Epoch 00482: val_loss did not improve from -1.13603\n",
      "Epoch 483/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -1.0239 - val_loss: -0.5782\n",
      "\n",
      "Epoch 00483: val_loss did not improve from -1.13603\n",
      "Epoch 484/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -1.0687 - val_loss: -0.8002\n",
      "\n",
      "Epoch 00484: val_loss did not improve from -1.13603\n",
      "Epoch 485/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.9087 - val_loss: -0.5114\n",
      "\n",
      "Epoch 00485: val_loss did not improve from -1.13603\n",
      "Epoch 486/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.8819 - val_loss: -0.4669\n",
      "\n",
      "Epoch 00486: val_loss did not improve from -1.13603\n",
      "Epoch 487/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.9017 - val_loss: -0.8620\n",
      "\n",
      "Epoch 00487: val_loss did not improve from -1.13603\n",
      "Epoch 488/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.9353 - val_loss: -0.8192\n",
      "\n",
      "Epoch 00488: val_loss did not improve from -1.13603\n",
      "Epoch 489/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.9366 - val_loss: -0.7089\n",
      "\n",
      "Epoch 00489: val_loss did not improve from -1.13603\n",
      "Epoch 490/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -1.0601 - val_loss: -0.8059\n",
      "\n",
      "Epoch 00490: val_loss did not improve from -1.13603\n",
      "Epoch 491/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.9640 - val_loss: -0.6930\n",
      "\n",
      "Epoch 00491: val_loss did not improve from -1.13603\n",
      "Epoch 492/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.9698 - val_loss: -0.5178\n",
      "\n",
      "Epoch 00492: val_loss did not improve from -1.13603\n",
      "Epoch 493/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.9971 - val_loss: 0.5562\n",
      "\n",
      "Epoch 00493: val_loss did not improve from -1.13603\n",
      "Epoch 494/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -1.0040 - val_loss: -0.3435\n",
      "\n",
      "Epoch 00494: val_loss did not improve from -1.13603\n",
      "Epoch 495/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.9596 - val_loss: -0.6211\n",
      "\n",
      "Epoch 00495: val_loss did not improve from -1.13603\n",
      "Epoch 496/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: 0.6358 - val_loss: 0.6691\n",
      "\n",
      "Epoch 00496: val_loss did not improve from -1.13603\n",
      "Epoch 497/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: 0.0732 - val_loss: 0.0012\n",
      "\n",
      "Epoch 00497: val_loss did not improve from -1.13603\n",
      "Epoch 498/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.1506 - val_loss: -0.1484\n",
      "\n",
      "Epoch 00498: val_loss did not improve from -1.13603\n",
      "Epoch 499/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.2286 - val_loss: -0.1951\n",
      "\n",
      "Epoch 00499: val_loss did not improve from -1.13603\n",
      "Epoch 500/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.2983 - val_loss: -0.1231\n",
      "\n",
      "Epoch 00500: val_loss did not improve from -1.13603\n",
      "Epoch 501/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.3319 - val_loss: -0.2741\n",
      "\n",
      "Epoch 00501: val_loss did not improve from -1.13603\n",
      "Epoch 502/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.4474 - val_loss: 0.0779\n",
      "\n",
      "Epoch 00502: val_loss did not improve from -1.13603\n",
      "Epoch 503/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.4652 - val_loss: -0.3314\n",
      "\n",
      "Epoch 00503: val_loss did not improve from -1.13603\n",
      "Epoch 504/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.4948 - val_loss: -0.2762\n",
      "\n",
      "Epoch 00504: val_loss did not improve from -1.13603\n",
      "Epoch 505/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.3251 - val_loss: 0.0506\n",
      "\n",
      "Epoch 00505: val_loss did not improve from -1.13603\n",
      "Epoch 506/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.4291 - val_loss: -0.3067\n",
      "\n",
      "Epoch 00506: val_loss did not improve from -1.13603\n",
      "Epoch 507/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.5534 - val_loss: -0.3710\n",
      "\n",
      "Epoch 00507: val_loss did not improve from -1.13603\n",
      "Epoch 508/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.3520 - val_loss: -0.0287\n",
      "\n",
      "Epoch 00508: val_loss did not improve from -1.13603\n",
      "Epoch 509/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.4846 - val_loss: -0.2957\n",
      "\n",
      "Epoch 00509: val_loss did not improve from -1.13603\n",
      "Epoch 510/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.4256 - val_loss: -0.1035\n",
      "\n",
      "Epoch 00510: val_loss did not improve from -1.13603\n",
      "Epoch 511/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.4618 - val_loss: -0.4551\n",
      "\n",
      "Epoch 00511: val_loss did not improve from -1.13603\n",
      "Epoch 512/1000\n",
      "281/281 [==============================] - 25s 87ms/step - loss: -0.5031 - val_loss: -0.3976\n",
      "\n",
      "Epoch 00512: val_loss did not improve from -1.13603\n",
      "Epoch 513/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.4450 - val_loss: -0.0944\n",
      "\n",
      "Epoch 00513: val_loss did not improve from -1.13603\n",
      "Epoch 514/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.2354 - val_loss: -0.1088\n",
      "\n",
      "Epoch 00514: val_loss did not improve from -1.13603\n",
      "Epoch 515/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.5056 - val_loss: -0.1507\n",
      "\n",
      "Epoch 00515: val_loss did not improve from -1.13603\n",
      "Epoch 516/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.5834 - val_loss: -0.3718\n",
      "\n",
      "Epoch 00516: val_loss did not improve from -1.13603\n",
      "Epoch 517/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.6220 - val_loss: -0.3201\n",
      "\n",
      "Epoch 00517: val_loss did not improve from -1.13603\n",
      "Epoch 518/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.5878 - val_loss: -0.3352\n",
      "\n",
      "Epoch 00518: val_loss did not improve from -1.13603\n",
      "Epoch 519/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.1192 - val_loss: -0.1453\n",
      "\n",
      "Epoch 00519: val_loss did not improve from -1.13603\n",
      "Epoch 520/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.6088 - val_loss: -0.2763\n",
      "\n",
      "Epoch 00520: val_loss did not improve from -1.13603\n",
      "Epoch 521/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.6939 - val_loss: -0.4722\n",
      "\n",
      "Epoch 00521: val_loss did not improve from -1.13603\n",
      "Epoch 522/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.5799 - val_loss: -0.4697\n",
      "\n",
      "Epoch 00522: val_loss did not improve from -1.13603\n",
      "Epoch 523/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.6343 - val_loss: -0.5814\n",
      "\n",
      "Epoch 00523: val_loss did not improve from -1.13603\n",
      "Epoch 524/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.5090 - val_loss: -0.1590\n",
      "\n",
      "Epoch 00524: val_loss did not improve from -1.13603\n",
      "Epoch 525/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.5200 - val_loss: -0.6579\n",
      "\n",
      "Epoch 00525: val_loss did not improve from -1.13603\n",
      "Epoch 526/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.6136 - val_loss: -0.6649\n",
      "\n",
      "Epoch 00526: val_loss did not improve from -1.13603\n",
      "Epoch 527/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.6168 - val_loss: -0.4167\n",
      "\n",
      "Epoch 00527: val_loss did not improve from -1.13603\n",
      "Epoch 528/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.5060 - val_loss: -0.4944\n",
      "\n",
      "Epoch 00528: val_loss did not improve from -1.13603\n",
      "Epoch 529/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.5717 - val_loss: 0.1384\n",
      "\n",
      "Epoch 00529: val_loss did not improve from -1.13603\n",
      "Epoch 530/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.5340 - val_loss: -0.5122\n",
      "\n",
      "Epoch 00530: val_loss did not improve from -1.13603\n",
      "Epoch 531/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.5961 - val_loss: -0.4097\n",
      "\n",
      "Epoch 00531: val_loss did not improve from -1.13603\n",
      "Epoch 532/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.6138 - val_loss: -0.4222\n",
      "\n",
      "Epoch 00532: val_loss did not improve from -1.13603\n",
      "Epoch 533/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.6440 - val_loss: -0.5742\n",
      "\n",
      "Epoch 00533: val_loss did not improve from -1.13603\n",
      "Epoch 534/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.6740 - val_loss: -0.5550\n",
      "\n",
      "Epoch 00534: val_loss did not improve from -1.13603\n",
      "Epoch 535/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.6957 - val_loss: -0.5056\n",
      "\n",
      "Epoch 00535: val_loss did not improve from -1.13603\n",
      "Epoch 536/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.6970 - val_loss: -0.3604\n",
      "\n",
      "Epoch 00536: val_loss did not improve from -1.13603\n",
      "Epoch 537/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.6616 - val_loss: -0.3257\n",
      "\n",
      "Epoch 00537: val_loss did not improve from -1.13603\n",
      "Epoch 538/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.6802 - val_loss: -0.3274\n",
      "\n",
      "Epoch 00538: val_loss did not improve from -1.13603\n",
      "Epoch 539/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.6546 - val_loss: -0.2413\n",
      "\n",
      "Epoch 00539: val_loss did not improve from -1.13603\n",
      "Epoch 540/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.7979 - val_loss: 0.2209\n",
      "\n",
      "Epoch 00540: val_loss did not improve from -1.13603\n",
      "Epoch 541/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.7912 - val_loss: 0.2208\n",
      "\n",
      "Epoch 00541: val_loss did not improve from -1.13603\n",
      "Epoch 542/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.7334 - val_loss: -0.5660\n",
      "\n",
      "Epoch 00542: val_loss did not improve from -1.13603\n",
      "Epoch 543/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.7931 - val_loss: -0.3038\n",
      "\n",
      "Epoch 00543: val_loss did not improve from -1.13603\n",
      "Epoch 544/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.8414 - val_loss: -0.6024\n",
      "\n",
      "Epoch 00544: val_loss did not improve from -1.13603\n",
      "Epoch 545/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.7133 - val_loss: -0.4559\n",
      "\n",
      "Epoch 00545: val_loss did not improve from -1.13603\n",
      "Epoch 546/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.8744 - val_loss: -0.1838\n",
      "\n",
      "Epoch 00546: val_loss did not improve from -1.13603\n",
      "Epoch 547/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.7510 - val_loss: 0.7382\n",
      "\n",
      "Epoch 00547: val_loss did not improve from -1.13603\n",
      "Epoch 548/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.7827 - val_loss: -0.2719\n",
      "\n",
      "Epoch 00548: val_loss did not improve from -1.13603\n",
      "Epoch 549/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.4278 - val_loss: -0.2409\n",
      "\n",
      "Epoch 00549: val_loss did not improve from -1.13603\n",
      "Epoch 550/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.6397 - val_loss: -0.5986\n",
      "\n",
      "Epoch 00550: val_loss did not improve from -1.13603\n",
      "Epoch 551/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.6916 - val_loss: -0.3484\n",
      "\n",
      "Epoch 00551: val_loss did not improve from -1.13603\n",
      "Epoch 552/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.6376 - val_loss: -0.4868\n",
      "\n",
      "Epoch 00552: val_loss did not improve from -1.13603\n",
      "Epoch 553/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.7722 - val_loss: -0.6384\n",
      "\n",
      "Epoch 00553: val_loss did not improve from -1.13603\n",
      "Epoch 554/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.5949 - val_loss: -0.5983\n",
      "\n",
      "Epoch 00554: val_loss did not improve from -1.13603\n",
      "Epoch 555/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.6695 - val_loss: -0.5886\n",
      "\n",
      "Epoch 00555: val_loss did not improve from -1.13603\n",
      "Epoch 556/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.8041 - val_loss: -0.4700\n",
      "\n",
      "Epoch 00556: val_loss did not improve from -1.13603\n",
      "Epoch 557/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.7911 - val_loss: -0.5277\n",
      "\n",
      "Epoch 00557: val_loss did not improve from -1.13603\n",
      "Epoch 558/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.8016 - val_loss: -0.5682\n",
      "\n",
      "Epoch 00558: val_loss did not improve from -1.13603\n",
      "Epoch 559/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.7768 - val_loss: -0.5513\n",
      "\n",
      "Epoch 00559: val_loss did not improve from -1.13603\n",
      "Epoch 560/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.8300 - val_loss: -0.6443\n",
      "\n",
      "Epoch 00560: val_loss did not improve from -1.13603\n",
      "Epoch 561/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.7999 - val_loss: -0.2463\n",
      "\n",
      "Epoch 00561: val_loss did not improve from -1.13603\n",
      "Epoch 562/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.7804 - val_loss: -0.6592\n",
      "\n",
      "Epoch 00562: val_loss did not improve from -1.13603\n",
      "Epoch 563/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.2965 - val_loss: -0.5475\n",
      "\n",
      "Epoch 00563: val_loss did not improve from -1.13603\n",
      "Epoch 564/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.4994 - val_loss: -0.3306\n",
      "\n",
      "Epoch 00564: val_loss did not improve from -1.13603\n",
      "Epoch 565/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.4905 - val_loss: -0.5824\n",
      "\n",
      "Epoch 00565: val_loss did not improve from -1.13603\n",
      "Epoch 566/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.3922 - val_loss: 1.5581\n",
      "\n",
      "Epoch 00566: val_loss did not improve from -1.13603\n",
      "Epoch 567/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.4908 - val_loss: -0.4983\n",
      "\n",
      "Epoch 00567: val_loss did not improve from -1.13603\n",
      "Epoch 568/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.3483 - val_loss: -0.5050\n",
      "\n",
      "Epoch 00568: val_loss did not improve from -1.13603\n",
      "Epoch 569/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.6237 - val_loss: -0.6219\n",
      "\n",
      "Epoch 00569: val_loss did not improve from -1.13603\n",
      "Epoch 570/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.6539 - val_loss: -0.4912\n",
      "\n",
      "Epoch 00570: val_loss did not improve from -1.13603\n",
      "Epoch 571/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.5914 - val_loss: -0.5200\n",
      "\n",
      "Epoch 00571: val_loss did not improve from -1.13603\n",
      "Epoch 572/1000\n",
      "281/281 [==============================] - 25s 91ms/step - loss: -0.6319 - val_loss: 0.2077\n",
      "\n",
      "Epoch 00572: val_loss did not improve from -1.13603\n",
      "Epoch 573/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: -0.6201 - val_loss: -0.6654\n",
      "\n",
      "Epoch 00573: val_loss did not improve from -1.13603\n",
      "Epoch 574/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: -0.5097 - val_loss: -0.6195\n",
      "\n",
      "Epoch 00574: val_loss did not improve from -1.13603\n",
      "Epoch 575/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.4981 - val_loss: -0.5076\n",
      "\n",
      "Epoch 00575: val_loss did not improve from -1.13603\n",
      "Epoch 576/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.6997 - val_loss: -0.6828\n",
      "\n",
      "Epoch 00576: val_loss did not improve from -1.13603\n",
      "Epoch 577/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.7020 - val_loss: -0.6865\n",
      "\n",
      "Epoch 00577: val_loss did not improve from -1.13603\n",
      "Epoch 578/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.7633 - val_loss: -0.7921\n",
      "\n",
      "Epoch 00578: val_loss did not improve from -1.13603\n",
      "Epoch 579/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.7567 - val_loss: -0.6308\n",
      "\n",
      "Epoch 00579: val_loss did not improve from -1.13603\n",
      "Epoch 580/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.7630 - val_loss: -0.7415\n",
      "\n",
      "Epoch 00580: val_loss did not improve from -1.13603\n",
      "Epoch 581/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.8221 - val_loss: -0.7531\n",
      "\n",
      "Epoch 00581: val_loss did not improve from -1.13603\n",
      "Epoch 582/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.8118 - val_loss: -0.5221\n",
      "\n",
      "Epoch 00582: val_loss did not improve from -1.13603\n",
      "Epoch 583/1000\n",
      "281/281 [==============================] - 28s 99ms/step - loss: -0.8700 - val_loss: -0.5925\n",
      "\n",
      "Epoch 00583: val_loss did not improve from -1.13603\n",
      "Epoch 584/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.8698 - val_loss: -0.7258\n",
      "\n",
      "Epoch 00584: val_loss did not improve from -1.13603\n",
      "Epoch 585/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.8396 - val_loss: -0.4603\n",
      "\n",
      "Epoch 00585: val_loss did not improve from -1.13603\n",
      "Epoch 586/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.8322 - val_loss: -0.6176\n",
      "\n",
      "Epoch 00586: val_loss did not improve from -1.13603\n",
      "Epoch 587/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.7912 - val_loss: -0.6824\n",
      "\n",
      "Epoch 00587: val_loss did not improve from -1.13603\n",
      "Epoch 588/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.8850 - val_loss: -0.8266\n",
      "\n",
      "Epoch 00588: val_loss did not improve from -1.13603\n",
      "Epoch 589/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.9072 - val_loss: -0.7782\n",
      "\n",
      "Epoch 00589: val_loss did not improve from -1.13603\n",
      "Epoch 590/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: -0.5570 - val_loss: 3.0382\n",
      "\n",
      "Epoch 00590: val_loss did not improve from -1.13603\n",
      "Epoch 591/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 1.4528 - val_loss: 0.7816\n",
      "\n",
      "Epoch 00591: val_loss did not improve from -1.13603\n",
      "Epoch 592/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 0.6215 - val_loss: 0.4535\n",
      "\n",
      "Epoch 00592: val_loss did not improve from -1.13603\n",
      "Epoch 593/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 0.2268 - val_loss: 0.2418\n",
      "\n",
      "Epoch 00593: val_loss did not improve from -1.13603\n",
      "Epoch 594/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: -0.0823 - val_loss: 0.0093\n",
      "\n",
      "Epoch 00594: val_loss did not improve from -1.13603\n",
      "Epoch 595/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.1913 - val_loss: 2046.3810\n",
      "\n",
      "Epoch 00595: val_loss did not improve from -1.13603\n",
      "Epoch 596/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.1376 - val_loss: 0.0145\n",
      "\n",
      "Epoch 00596: val_loss did not improve from -1.13603\n",
      "Epoch 597/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.1155 - val_loss: 50019612067358740316160.0000\n",
      "\n",
      "Epoch 00597: val_loss did not improve from -1.13603\n",
      "Epoch 598/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.2257 - val_loss: 57.1603\n",
      "\n",
      "Epoch 00598: val_loss did not improve from -1.13603\n",
      "Epoch 599/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.2799 - val_loss: -0.1782\n",
      "\n",
      "Epoch 00599: val_loss did not improve from -1.13603\n",
      "Epoch 600/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.2149 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00600: val_loss did not improve from -1.13603\n",
      "Epoch 601/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.4145 - val_loss: -0.2047\n",
      "\n",
      "Epoch 00601: val_loss did not improve from -1.13603\n",
      "Epoch 602/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.5009 - val_loss: -0.3803\n",
      "\n",
      "Epoch 00602: val_loss did not improve from -1.13603\n",
      "Epoch 603/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: -0.5391 - val_loss: -0.3753\n",
      "\n",
      "Epoch 00603: val_loss did not improve from -1.13603\n",
      "Epoch 604/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: -0.4761 - val_loss: -0.1435\n",
      "\n",
      "Epoch 00604: val_loss did not improve from -1.13603\n",
      "Epoch 605/1000\n",
      "281/281 [==============================] - 29s 103ms/step - loss: -0.4058 - val_loss: -0.1780\n",
      "\n",
      "Epoch 00605: val_loss did not improve from -1.13603\n",
      "Epoch 606/1000\n",
      "281/281 [==============================] - 29s 103ms/step - loss: -0.4850 - val_loss: 0.0310\n",
      "\n",
      "Epoch 00606: val_loss did not improve from -1.13603\n",
      "Epoch 607/1000\n",
      "281/281 [==============================] - 29s 103ms/step - loss: -0.4734 - val_loss: -0.3141\n",
      "\n",
      "Epoch 00607: val_loss did not improve from -1.13603\n",
      "Epoch 608/1000\n",
      "281/281 [==============================] - 29s 103ms/step - loss: -0.5370 - val_loss: -0.3441\n",
      "\n",
      "Epoch 00608: val_loss did not improve from -1.13603\n",
      "Epoch 609/1000\n",
      "281/281 [==============================] - 29s 103ms/step - loss: -0.6026 - val_loss: -0.3669\n",
      "\n",
      "Epoch 00609: val_loss did not improve from -1.13603\n",
      "Epoch 610/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: -0.6295 - val_loss: -0.3450\n",
      "\n",
      "Epoch 00610: val_loss did not improve from -1.13603\n",
      "Epoch 611/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: -0.6027 - val_loss: -0.5885\n",
      "\n",
      "Epoch 00611: val_loss did not improve from -1.13603\n",
      "Epoch 612/1000\n",
      "281/281 [==============================] - 29s 103ms/step - loss: -0.6694 - val_loss: -0.5435\n",
      "\n",
      "Epoch 00612: val_loss did not improve from -1.13603\n",
      "Epoch 613/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: -0.6702 - val_loss: -0.4837\n",
      "\n",
      "Epoch 00613: val_loss did not improve from -1.13603\n",
      "Epoch 614/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: -0.6324 - val_loss: -0.4229\n",
      "\n",
      "Epoch 00614: val_loss did not improve from -1.13603\n",
      "Epoch 615/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.7238 - val_loss: -0.5698\n",
      "\n",
      "Epoch 00615: val_loss did not improve from -1.13603\n",
      "Epoch 616/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.7332 - val_loss: -0.6008\n",
      "\n",
      "Epoch 00616: val_loss did not improve from -1.13603\n",
      "Epoch 617/1000\n",
      "281/281 [==============================] - 28s 99ms/step - loss: -0.7679 - val_loss: -0.5294\n",
      "\n",
      "Epoch 00617: val_loss did not improve from -1.13603\n",
      "Epoch 618/1000\n",
      "281/281 [==============================] - 28s 99ms/step - loss: -0.8042 - val_loss: -0.5895\n",
      "\n",
      "Epoch 00618: val_loss did not improve from -1.13603\n",
      "Epoch 619/1000\n",
      "281/281 [==============================] - 27s 98ms/step - loss: -0.5511 - val_loss: -0.0729\n",
      "\n",
      "Epoch 00619: val_loss did not improve from -1.13603\n",
      "Epoch 620/1000\n",
      "281/281 [==============================] - 27s 98ms/step - loss: -0.6812 - val_loss: -0.5930\n",
      "\n",
      "Epoch 00620: val_loss did not improve from -1.13603\n",
      "Epoch 621/1000\n",
      "281/281 [==============================] - 27s 98ms/step - loss: -0.7061 - val_loss: -0.5162\n",
      "\n",
      "Epoch 00621: val_loss did not improve from -1.13603\n",
      "Epoch 622/1000\n",
      "281/281 [==============================] - 28s 99ms/step - loss: -0.7681 - val_loss: -0.7056\n",
      "\n",
      "Epoch 00622: val_loss did not improve from -1.13603\n",
      "Epoch 623/1000\n",
      "281/281 [==============================] - 28s 99ms/step - loss: -0.8641 - val_loss: -0.5018\n",
      "\n",
      "Epoch 00623: val_loss did not improve from -1.13603\n",
      "Epoch 624/1000\n",
      "281/281 [==============================] - 28s 98ms/step - loss: -0.6595 - val_loss: -0.7324\n",
      "\n",
      "Epoch 00624: val_loss did not improve from -1.13603\n",
      "Epoch 625/1000\n",
      "281/281 [==============================] - 28s 98ms/step - loss: -0.6575 - val_loss: -0.6934\n",
      "\n",
      "Epoch 00625: val_loss did not improve from -1.13603\n",
      "Epoch 626/1000\n",
      "281/281 [==============================] - 28s 99ms/step - loss: -0.6764 - val_loss: -0.6777\n",
      "\n",
      "Epoch 00626: val_loss did not improve from -1.13603\n",
      "Epoch 627/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: -0.7194 - val_loss: -0.5409\n",
      "\n",
      "Epoch 00627: val_loss did not improve from -1.13603\n",
      "Epoch 628/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.7072 - val_loss: -0.7037\n",
      "\n",
      "Epoch 00628: val_loss did not improve from -1.13603\n",
      "Epoch 629/1000\n",
      "281/281 [==============================] - 29s 103ms/step - loss: -0.3953 - val_loss: -0.6540\n",
      "\n",
      "Epoch 00629: val_loss did not improve from -1.13603\n",
      "Epoch 630/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.7245 - val_loss: -0.2821\n",
      "\n",
      "Epoch 00630: val_loss did not improve from -1.13603\n",
      "Epoch 631/1000\n",
      "281/281 [==============================] - 29s 103ms/step - loss: -0.8209 - val_loss: -0.7908\n",
      "\n",
      "Epoch 00631: val_loss did not improve from -1.13603\n",
      "Epoch 632/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.7679 - val_loss: -0.5310\n",
      "\n",
      "Epoch 00632: val_loss did not improve from -1.13603\n",
      "Epoch 633/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: -0.8547 - val_loss: -0.4459\n",
      "\n",
      "Epoch 00633: val_loss did not improve from -1.13603\n",
      "Epoch 634/1000\n",
      "281/281 [==============================] - 29s 103ms/step - loss: -0.8869 - val_loss: -0.5845\n",
      "\n",
      "Epoch 00634: val_loss did not improve from -1.13603\n",
      "Epoch 635/1000\n",
      "281/281 [==============================] - 29s 103ms/step - loss: -0.8410 - val_loss: -0.5353\n",
      "\n",
      "Epoch 00635: val_loss did not improve from -1.13603\n",
      "Epoch 636/1000\n",
      "281/281 [==============================] - 29s 103ms/step - loss: -0.8998 - val_loss: 0.3387\n",
      "\n",
      "Epoch 00636: val_loss did not improve from -1.13603\n",
      "Epoch 637/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 840169684992.0000 - val_loss: 1.8007\n",
      "\n",
      "Epoch 00637: val_loss did not improve from -1.13603\n",
      "Epoch 638/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 0.9739 - val_loss: 0.5821\n",
      "\n",
      "Epoch 00638: val_loss did not improve from -1.13603\n",
      "Epoch 639/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 0.1932 - val_loss: 0.2121\n",
      "\n",
      "Epoch 00639: val_loss did not improve from -1.13603\n",
      "Epoch 640/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.0501 - val_loss: -0.1100\n",
      "\n",
      "Epoch 00640: val_loss did not improve from -1.13603\n",
      "Epoch 641/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.2599 - val_loss: -0.2611\n",
      "\n",
      "Epoch 00641: val_loss did not improve from -1.13603\n",
      "Epoch 642/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.3664 - val_loss: -0.2339\n",
      "\n",
      "Epoch 00642: val_loss did not improve from -1.13603\n",
      "Epoch 643/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: -0.4304 - val_loss: -0.2894\n",
      "\n",
      "Epoch 00643: val_loss did not improve from -1.13603\n",
      "Epoch 644/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: -0.4731 - val_loss: -0.3242\n",
      "\n",
      "Epoch 00644: val_loss did not improve from -1.13603\n",
      "Epoch 645/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.5244 - val_loss: -0.2892\n",
      "\n",
      "Epoch 00645: val_loss did not improve from -1.13603\n",
      "Epoch 646/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.4806 - val_loss: -0.2712\n",
      "\n",
      "Epoch 00646: val_loss did not improve from -1.13603\n",
      "Epoch 647/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.5749 - val_loss: -0.4163\n",
      "\n",
      "Epoch 00647: val_loss did not improve from -1.13603\n",
      "Epoch 648/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.3378 - val_loss: 0.0456\n",
      "\n",
      "Epoch 00648: val_loss did not improve from -1.13603\n",
      "Epoch 649/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.0105 - val_loss: 0.1480\n",
      "\n",
      "Epoch 00649: val_loss did not improve from -1.13603\n",
      "Epoch 650/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.0423 - val_loss: 0.0315\n",
      "\n",
      "Epoch 00650: val_loss did not improve from -1.13603\n",
      "Epoch 651/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.1152 - val_loss: -0.0255\n",
      "\n",
      "Epoch 00651: val_loss did not improve from -1.13603\n",
      "Epoch 652/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.2144 - val_loss: -0.0958\n",
      "\n",
      "Epoch 00652: val_loss did not improve from -1.13603\n",
      "Epoch 653/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.2920 - val_loss: 0.2030\n",
      "\n",
      "Epoch 00653: val_loss did not improve from -1.13603\n",
      "Epoch 654/1000\n",
      "281/281 [==============================] - 28s 99ms/step - loss: -0.2520 - val_loss: 0.4481\n",
      "\n",
      "Epoch 00654: val_loss did not improve from -1.13603\n",
      "Epoch 655/1000\n",
      "281/281 [==============================] - 27s 98ms/step - loss: -0.2284 - val_loss: 1.7505\n",
      "\n",
      "Epoch 00655: val_loss did not improve from -1.13603\n",
      "Epoch 656/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.2568 - val_loss: -0.0058\n",
      "\n",
      "Epoch 00656: val_loss did not improve from -1.13603\n",
      "Epoch 657/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.3027 - val_loss: 0.0083\n",
      "\n",
      "Epoch 00657: val_loss did not improve from -1.13603\n",
      "Epoch 658/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.3855 - val_loss: -0.0378\n",
      "\n",
      "Epoch 00658: val_loss did not improve from -1.13603\n",
      "Epoch 659/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.3741 - val_loss: 2.0573\n",
      "\n",
      "Epoch 00659: val_loss did not improve from -1.13603\n",
      "Epoch 660/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 1.7814 - val_loss: 1.5973\n",
      "\n",
      "Epoch 00660: val_loss did not improve from -1.13603\n",
      "Epoch 661/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 1.5966 - val_loss: 1.6306\n",
      "\n",
      "Epoch 00661: val_loss did not improve from -1.13603\n",
      "Epoch 662/1000\n",
      "281/281 [==============================] - 28s 99ms/step - loss: 1.6273 - val_loss: 1.5659\n",
      "\n",
      "Epoch 00662: val_loss did not improve from -1.13603\n",
      "Epoch 663/1000\n",
      "281/281 [==============================] - 28s 99ms/step - loss: 1.2820 - val_loss: 0.8629\n",
      "\n",
      "Epoch 00663: val_loss did not improve from -1.13603\n",
      "Epoch 664/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 0.5323 - val_loss: 0.7953\n",
      "\n",
      "Epoch 00664: val_loss did not improve from -1.13603\n",
      "Epoch 665/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 0.2904 - val_loss: 0.3476\n",
      "\n",
      "Epoch 00665: val_loss did not improve from -1.13603\n",
      "Epoch 666/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 0.0918 - val_loss: 0.2287\n",
      "\n",
      "Epoch 00666: val_loss did not improve from -1.13603\n",
      "Epoch 667/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 0.0106 - val_loss: 0.0544\n",
      "\n",
      "Epoch 00667: val_loss did not improve from -1.13603\n",
      "Epoch 668/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.0258 - val_loss: 0.0439\n",
      "\n",
      "Epoch 00668: val_loss did not improve from -1.13603\n",
      "Epoch 669/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.0273 - val_loss: -0.0085\n",
      "\n",
      "Epoch 00669: val_loss did not improve from -1.13603\n",
      "Epoch 670/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.1216 - val_loss: 0.0327\n",
      "\n",
      "Epoch 00670: val_loss did not improve from -1.13603\n",
      "Epoch 671/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.3145 - val_loss: -0.2202\n",
      "\n",
      "Epoch 00671: val_loss did not improve from -1.13603\n",
      "Epoch 672/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.4182 - val_loss: -0.2023\n",
      "\n",
      "Epoch 00672: val_loss did not improve from -1.13603\n",
      "Epoch 673/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.4639 - val_loss: -0.2579\n",
      "\n",
      "Epoch 00673: val_loss did not improve from -1.13603\n",
      "Epoch 674/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.4609 - val_loss: -0.1873\n",
      "\n",
      "Epoch 00674: val_loss did not improve from -1.13603\n",
      "Epoch 675/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.4795 - val_loss: -0.3180\n",
      "\n",
      "Epoch 00675: val_loss did not improve from -1.13603\n",
      "Epoch 676/1000\n",
      "281/281 [==============================] - 29s 103ms/step - loss: -0.4851 - val_loss: -0.3624\n",
      "\n",
      "Epoch 00676: val_loss did not improve from -1.13603\n",
      "Epoch 677/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.5128 - val_loss: -0.1109\n",
      "\n",
      "Epoch 00677: val_loss did not improve from -1.13603\n",
      "Epoch 678/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.5320 - val_loss: -0.3223\n",
      "\n",
      "Epoch 00678: val_loss did not improve from -1.13603\n",
      "Epoch 679/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.5528 - val_loss: -0.2954\n",
      "\n",
      "Epoch 00679: val_loss did not improve from -1.13603\n",
      "Epoch 680/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.5327 - val_loss: -0.3240\n",
      "\n",
      "Epoch 00680: val_loss did not improve from -1.13603\n",
      "Epoch 681/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: -0.5026 - val_loss: -0.4036\n",
      "\n",
      "Epoch 00681: val_loss did not improve from -1.13603\n",
      "Epoch 682/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.6024 - val_loss: -0.4887\n",
      "\n",
      "Epoch 00682: val_loss did not improve from -1.13603\n",
      "Epoch 683/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.6185 - val_loss: -0.4379\n",
      "\n",
      "Epoch 00683: val_loss did not improve from -1.13603\n",
      "Epoch 684/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.6004 - val_loss: -0.3788\n",
      "\n",
      "Epoch 00684: val_loss did not improve from -1.13603\n",
      "Epoch 685/1000\n",
      "281/281 [==============================] - 28s 99ms/step - loss: -0.6407 - val_loss: -0.4052\n",
      "\n",
      "Epoch 00685: val_loss did not improve from -1.13603\n",
      "Epoch 686/1000\n",
      "281/281 [==============================] - 28s 98ms/step - loss: -0.6711 - val_loss: -0.4181\n",
      "\n",
      "Epoch 00686: val_loss did not improve from -1.13603\n",
      "Epoch 687/1000\n",
      "281/281 [==============================] - 28s 99ms/step - loss: -0.6863 - val_loss: -0.4178\n",
      "\n",
      "Epoch 00687: val_loss did not improve from -1.13603\n",
      "Epoch 688/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.7436 - val_loss: -0.2633\n",
      "\n",
      "Epoch 00688: val_loss did not improve from -1.13603\n",
      "Epoch 689/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.6682 - val_loss: -0.1701\n",
      "\n",
      "Epoch 00689: val_loss did not improve from -1.13603\n",
      "Epoch 690/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.5744 - val_loss: 0.5641\n",
      "\n",
      "Epoch 00690: val_loss did not improve from -1.13603\n",
      "Epoch 691/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.7525 - val_loss: 0.3836\n",
      "\n",
      "Epoch 00691: val_loss did not improve from -1.13603\n",
      "Epoch 692/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.7616 - val_loss: -0.0566\n",
      "\n",
      "Epoch 00692: val_loss did not improve from -1.13603\n",
      "Epoch 693/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.7799 - val_loss: -0.1315\n",
      "\n",
      "Epoch 00693: val_loss did not improve from -1.13603\n",
      "Epoch 694/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.7435 - val_loss: -0.0576\n",
      "\n",
      "Epoch 00694: val_loss did not improve from -1.13603\n",
      "Epoch 695/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.7301 - val_loss: -0.1474\n",
      "\n",
      "Epoch 00695: val_loss did not improve from -1.13603\n",
      "Epoch 696/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.6907 - val_loss: -0.3015\n",
      "\n",
      "Epoch 00696: val_loss did not improve from -1.13603\n",
      "Epoch 697/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.6246 - val_loss: -0.3289\n",
      "\n",
      "Epoch 00697: val_loss did not improve from -1.13603\n",
      "Epoch 698/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.6931 - val_loss: -0.3915\n",
      "\n",
      "Epoch 00698: val_loss did not improve from -1.13603\n",
      "Epoch 699/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.6599 - val_loss: -0.4271\n",
      "\n",
      "Epoch 00699: val_loss did not improve from -1.13603\n",
      "Epoch 700/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.7243 - val_loss: -0.3841\n",
      "\n",
      "Epoch 00700: val_loss did not improve from -1.13603\n",
      "Epoch 701/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.7001 - val_loss: -0.1805\n",
      "\n",
      "Epoch 00701: val_loss did not improve from -1.13603\n",
      "Epoch 702/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.7048 - val_loss: -0.4600\n",
      "\n",
      "Epoch 00702: val_loss did not improve from -1.13603\n",
      "Epoch 703/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.7015 - val_loss: -0.4567\n",
      "\n",
      "Epoch 00703: val_loss did not improve from -1.13603\n",
      "Epoch 704/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.7616 - val_loss: -0.3708\n",
      "\n",
      "Epoch 00704: val_loss did not improve from -1.13603\n",
      "Epoch 705/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.7658 - val_loss: -0.6219\n",
      "\n",
      "Epoch 00705: val_loss did not improve from -1.13603\n",
      "Epoch 706/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.8149 - val_loss: -0.5108\n",
      "\n",
      "Epoch 00706: val_loss did not improve from -1.13603\n",
      "Epoch 707/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: -0.8234 - val_loss: -0.4582\n",
      "\n",
      "Epoch 00707: val_loss did not improve from -1.13603\n",
      "Epoch 708/1000\n",
      "281/281 [==============================] - 29s 103ms/step - loss: -0.7805 - val_loss: -0.5899\n",
      "\n",
      "Epoch 00708: val_loss did not improve from -1.13603\n",
      "Epoch 709/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: -0.8032 - val_loss: -0.5192\n",
      "\n",
      "Epoch 00709: val_loss did not improve from -1.13603\n",
      "Epoch 710/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.7872 - val_loss: -0.5908\n",
      "\n",
      "Epoch 00710: val_loss did not improve from -1.13603\n",
      "Epoch 711/1000\n",
      "281/281 [==============================] - 24s 86ms/step - loss: -0.6479 - val_loss: -0.5741\n",
      "\n",
      "Epoch 00711: val_loss did not improve from -1.13603\n",
      "Epoch 712/1000\n",
      "281/281 [==============================] - 24s 87ms/step - loss: -0.6668 - val_loss: -0.5998\n",
      "\n",
      "Epoch 00712: val_loss did not improve from -1.13603\n",
      "Epoch 713/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.7043 - val_loss: -0.6355\n",
      "\n",
      "Epoch 00713: val_loss did not improve from -1.13603\n",
      "Epoch 714/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.7178 - val_loss: -0.4249\n",
      "\n",
      "Epoch 00714: val_loss did not improve from -1.13603\n",
      "Epoch 715/1000\n",
      "281/281 [==============================] - 25s 87ms/step - loss: -0.8056 - val_loss: -0.5472\n",
      "\n",
      "Epoch 00715: val_loss did not improve from -1.13603\n",
      "Epoch 716/1000\n",
      "281/281 [==============================] - 25s 87ms/step - loss: -0.8372 - val_loss: -0.5644\n",
      "\n",
      "Epoch 00716: val_loss did not improve from -1.13603\n",
      "Epoch 717/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.7914 - val_loss: -0.4447\n",
      "\n",
      "Epoch 00717: val_loss did not improve from -1.13603\n",
      "Epoch 718/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.8428 - val_loss: -0.5044\n",
      "\n",
      "Epoch 00718: val_loss did not improve from -1.13603\n",
      "Epoch 719/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.8596 - val_loss: -0.5759\n",
      "\n",
      "Epoch 00719: val_loss did not improve from -1.13603\n",
      "Epoch 720/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.9012 - val_loss: -0.5578\n",
      "\n",
      "Epoch 00720: val_loss did not improve from -1.13603\n",
      "Epoch 721/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.9050 - val_loss: -0.5790\n",
      "\n",
      "Epoch 00721: val_loss did not improve from -1.13603\n",
      "Epoch 722/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.8434 - val_loss: -0.6987\n",
      "\n",
      "Epoch 00722: val_loss did not improve from -1.13603\n",
      "Epoch 723/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.8114 - val_loss: -0.6724\n",
      "\n",
      "Epoch 00723: val_loss did not improve from -1.13603\n",
      "Epoch 724/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.3106 - val_loss: -0.1996\n",
      "\n",
      "Epoch 00724: val_loss did not improve from -1.13603\n",
      "Epoch 725/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.1737 - val_loss: -0.1699\n",
      "\n",
      "Epoch 00725: val_loss did not improve from -1.13603\n",
      "Epoch 726/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.3932 - val_loss: -0.3122\n",
      "\n",
      "Epoch 00726: val_loss did not improve from -1.13603\n",
      "Epoch 727/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.4323 - val_loss: -0.4210\n",
      "\n",
      "Epoch 00727: val_loss did not improve from -1.13603\n",
      "Epoch 728/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.4538 - val_loss: -0.3558\n",
      "\n",
      "Epoch 00728: val_loss did not improve from -1.13603\n",
      "Epoch 729/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.4897 - val_loss: -0.3186\n",
      "\n",
      "Epoch 00729: val_loss did not improve from -1.13603\n",
      "Epoch 730/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.4961 - val_loss: -0.2017\n",
      "\n",
      "Epoch 00730: val_loss did not improve from -1.13603\n",
      "Epoch 731/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.5585 - val_loss: -0.2470\n",
      "\n",
      "Epoch 00731: val_loss did not improve from -1.13603\n",
      "Epoch 732/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.5756 - val_loss: -0.3281\n",
      "\n",
      "Epoch 00732: val_loss did not improve from -1.13603\n",
      "Epoch 733/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.6472 - val_loss: -0.5102\n",
      "\n",
      "Epoch 00733: val_loss did not improve from -1.13603\n",
      "Epoch 734/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.7104 - val_loss: -0.5499\n",
      "\n",
      "Epoch 00734: val_loss did not improve from -1.13603\n",
      "Epoch 735/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.6592 - val_loss: -0.4950\n",
      "\n",
      "Epoch 00735: val_loss did not improve from -1.13603\n",
      "Epoch 736/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.7103 - val_loss: -0.6102\n",
      "\n",
      "Epoch 00736: val_loss did not improve from -1.13603\n",
      "Epoch 737/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.6734 - val_loss: -0.5021\n",
      "\n",
      "Epoch 00737: val_loss did not improve from -1.13603\n",
      "Epoch 738/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.6870 - val_loss: -0.5284\n",
      "\n",
      "Epoch 00738: val_loss did not improve from -1.13603\n",
      "Epoch 739/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.7887 - val_loss: 5.5495\n",
      "\n",
      "Epoch 00739: val_loss did not improve from -1.13603\n",
      "Epoch 740/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.8375 - val_loss: -0.4453\n",
      "\n",
      "Epoch 00740: val_loss did not improve from -1.13603\n",
      "Epoch 741/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.8342 - val_loss: -0.3142\n",
      "\n",
      "Epoch 00741: val_loss did not improve from -1.13603\n",
      "Epoch 742/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.7700 - val_loss: -0.5589\n",
      "\n",
      "Epoch 00742: val_loss did not improve from -1.13603\n",
      "Epoch 743/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.7655 - val_loss: -0.5864\n",
      "\n",
      "Epoch 00743: val_loss did not improve from -1.13603\n",
      "Epoch 744/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.7319 - val_loss: -0.6531\n",
      "\n",
      "Epoch 00744: val_loss did not improve from -1.13603\n",
      "Epoch 745/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.7365 - val_loss: -0.3334\n",
      "\n",
      "Epoch 00745: val_loss did not improve from -1.13603\n",
      "Epoch 746/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.7533 - val_loss: -0.3111\n",
      "\n",
      "Epoch 00746: val_loss did not improve from -1.13603\n",
      "Epoch 747/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.7480 - val_loss: -0.0467\n",
      "\n",
      "Epoch 00747: val_loss did not improve from -1.13603\n",
      "Epoch 748/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.7655 - val_loss: 0.8364\n",
      "\n",
      "Epoch 00748: val_loss did not improve from -1.13603\n",
      "Epoch 749/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.7040 - val_loss: -0.6284\n",
      "\n",
      "Epoch 00749: val_loss did not improve from -1.13603\n",
      "Epoch 750/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.8086 - val_loss: -0.5398\n",
      "\n",
      "Epoch 00750: val_loss did not improve from -1.13603\n",
      "Epoch 751/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.8498 - val_loss: -0.6259\n",
      "\n",
      "Epoch 00751: val_loss did not improve from -1.13603\n",
      "Epoch 752/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.8341 - val_loss: -0.6447\n",
      "\n",
      "Epoch 00752: val_loss did not improve from -1.13603\n",
      "Epoch 753/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.8475 - val_loss: -0.5898\n",
      "\n",
      "Epoch 00753: val_loss did not improve from -1.13603\n",
      "Epoch 754/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.8378 - val_loss: -0.6548\n",
      "\n",
      "Epoch 00754: val_loss did not improve from -1.13603\n",
      "Epoch 755/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.8344 - val_loss: -0.2893\n",
      "\n",
      "Epoch 00755: val_loss did not improve from -1.13603\n",
      "Epoch 756/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.7945 - val_loss: -0.1547\n",
      "\n",
      "Epoch 00756: val_loss did not improve from -1.13603\n",
      "Epoch 757/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.7644 - val_loss: 1.0835\n",
      "\n",
      "Epoch 00757: val_loss did not improve from -1.13603\n",
      "Epoch 758/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.5181 - val_loss: 0.1166\n",
      "\n",
      "Epoch 00758: val_loss did not improve from -1.13603\n",
      "Epoch 759/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.6177 - val_loss: 0.2407\n",
      "\n",
      "Epoch 00759: val_loss did not improve from -1.13603\n",
      "Epoch 760/1000\n",
      "281/281 [==============================] - 25s 90ms/step - loss: -0.7963 - val_loss: -0.0219\n",
      "\n",
      "Epoch 00760: val_loss did not improve from -1.13603\n",
      "Epoch 761/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.6073 - val_loss: -0.1309\n",
      "\n",
      "Epoch 00761: val_loss did not improve from -1.13603\n",
      "Epoch 762/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.4011 - val_loss: -0.0204\n",
      "\n",
      "Epoch 00762: val_loss did not improve from -1.13603\n",
      "Epoch 763/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.2746 - val_loss: -0.0735\n",
      "\n",
      "Epoch 00763: val_loss did not improve from -1.13603\n",
      "Epoch 764/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.6713 - val_loss: 5.4009\n",
      "\n",
      "Epoch 00764: val_loss did not improve from -1.13603\n",
      "Epoch 765/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.3650 - val_loss: -0.4270\n",
      "\n",
      "Epoch 00765: val_loss did not improve from -1.13603\n",
      "Epoch 766/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.6058 - val_loss: -0.3597\n",
      "\n",
      "Epoch 00766: val_loss did not improve from -1.13603\n",
      "Epoch 767/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: 0.2103 - val_loss: 0.9162\n",
      "\n",
      "Epoch 00767: val_loss did not improve from -1.13603\n",
      "Epoch 768/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: 0.0543 - val_loss: -0.2302\n",
      "\n",
      "Epoch 00768: val_loss did not improve from -1.13603\n",
      "Epoch 769/1000\n",
      "281/281 [==============================] - 25s 87ms/step - loss: -0.3647 - val_loss: -0.2379\n",
      "\n",
      "Epoch 00769: val_loss did not improve from -1.13603\n",
      "Epoch 770/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.4046 - val_loss: -0.3106\n",
      "\n",
      "Epoch 00770: val_loss did not improve from -1.13603\n",
      "Epoch 771/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.4412 - val_loss: -0.2122\n",
      "\n",
      "Epoch 00771: val_loss did not improve from -1.13603\n",
      "Epoch 772/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.5789 - val_loss: -0.3807\n",
      "\n",
      "Epoch 00772: val_loss did not improve from -1.13603\n",
      "Epoch 773/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.6363 - val_loss: -0.2075\n",
      "\n",
      "Epoch 00773: val_loss did not improve from -1.13603\n",
      "Epoch 774/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.7220 - val_loss: -0.2962\n",
      "\n",
      "Epoch 00774: val_loss did not improve from -1.13603\n",
      "Epoch 775/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.7033 - val_loss: -0.5036\n",
      "\n",
      "Epoch 00775: val_loss did not improve from -1.13603\n",
      "Epoch 776/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.6368 - val_loss: -0.4904\n",
      "\n",
      "Epoch 00776: val_loss did not improve from -1.13603\n",
      "Epoch 777/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.7359 - val_loss: -0.4234\n",
      "\n",
      "Epoch 00777: val_loss did not improve from -1.13603\n",
      "Epoch 778/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.7651 - val_loss: -0.4568\n",
      "\n",
      "Epoch 00778: val_loss did not improve from -1.13603\n",
      "Epoch 779/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.6956 - val_loss: -0.3889\n",
      "\n",
      "Epoch 00779: val_loss did not improve from -1.13603\n",
      "Epoch 780/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: -0.8032 - val_loss: -0.3267\n",
      "\n",
      "Epoch 00780: val_loss did not improve from -1.13603\n",
      "Epoch 781/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.8165 - val_loss: -0.3353\n",
      "\n",
      "Epoch 00781: val_loss did not improve from -1.13603\n",
      "Epoch 782/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.7863 - val_loss: -0.3212\n",
      "\n",
      "Epoch 00782: val_loss did not improve from -1.13603\n",
      "Epoch 783/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.7857 - val_loss: -0.3235\n",
      "\n",
      "Epoch 00783: val_loss did not improve from -1.13603\n",
      "Epoch 784/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.8161 - val_loss: -0.4330\n",
      "\n",
      "Epoch 00784: val_loss did not improve from -1.13603\n",
      "Epoch 785/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: 0.1834 - val_loss: 0.1784\n",
      "\n",
      "Epoch 00785: val_loss did not improve from -1.13603\n",
      "Epoch 786/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: -0.3647 - val_loss: -0.2522\n",
      "\n",
      "Epoch 00786: val_loss did not improve from -1.13603\n",
      "Epoch 787/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: 0.2827 - val_loss: 1.8272\n",
      "\n",
      "Epoch 00787: val_loss did not improve from -1.13603\n",
      "Epoch 788/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: 1.8936 - val_loss: 1.7208\n",
      "\n",
      "Epoch 00788: val_loss did not improve from -1.13603\n",
      "Epoch 789/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: 1.6062 - val_loss: 1.5533\n",
      "\n",
      "Epoch 00789: val_loss did not improve from -1.13603\n",
      "Epoch 790/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: 1.4977 - val_loss: 1.5365\n",
      "\n",
      "Epoch 00790: val_loss did not improve from -1.13603\n",
      "Epoch 791/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: 1.7710 - val_loss: 2.2450\n",
      "\n",
      "Epoch 00791: val_loss did not improve from -1.13603\n",
      "Epoch 792/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: 1.8715 - val_loss: 1.5281\n",
      "\n",
      "Epoch 00792: val_loss did not improve from -1.13603\n",
      "Epoch 793/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: 1.5367 - val_loss: 1.5099\n",
      "\n",
      "Epoch 00793: val_loss did not improve from -1.13603\n",
      "Epoch 794/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: 1.4167 - val_loss: 1.4559\n",
      "\n",
      "Epoch 00794: val_loss did not improve from -1.13603\n",
      "Epoch 795/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: 1.6703 - val_loss: 2.1730\n",
      "\n",
      "Epoch 00795: val_loss did not improve from -1.13603\n",
      "Epoch 796/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: 1.4757 - val_loss: 1.4573\n",
      "\n",
      "Epoch 00796: val_loss did not improve from -1.13603\n",
      "Epoch 797/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: 1.3449 - val_loss: 1.3589\n",
      "\n",
      "Epoch 00797: val_loss did not improve from -1.13603\n",
      "Epoch 798/1000\n",
      "281/281 [==============================] - 25s 89ms/step - loss: 1.4074 - val_loss: 1.1956\n",
      "\n",
      "Epoch 00798: val_loss did not improve from -1.13603\n",
      "Epoch 799/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: 1.0013 - val_loss: 0.8759\n",
      "\n",
      "Epoch 00799: val_loss did not improve from -1.13603\n",
      "Epoch 800/1000\n",
      "281/281 [==============================] - 25s 88ms/step - loss: 1.0205 - val_loss: 0.8631\n",
      "\n",
      "Epoch 00800: val_loss did not improve from -1.13603\n",
      "Epoch 801/1000\n",
      "281/281 [==============================] - 29s 104ms/step - loss: 0.8144 - val_loss: 0.7283\n",
      "\n",
      "Epoch 00801: val_loss did not improve from -1.13603\n",
      "Epoch 802/1000\n",
      "281/281 [==============================] - 29s 104ms/step - loss: 0.7019 - val_loss: 0.7067\n",
      "\n",
      "Epoch 00802: val_loss did not improve from -1.13603\n",
      "Epoch 803/1000\n",
      "281/281 [==============================] - 29s 103ms/step - loss: 0.6578 - val_loss: 0.6820\n",
      "\n",
      "Epoch 00803: val_loss did not improve from -1.13603\n",
      "Epoch 804/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: 0.7045 - val_loss: 0.6387\n",
      "\n",
      "Epoch 00804: val_loss did not improve from -1.13603\n",
      "Epoch 805/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: 0.8348 - val_loss: 0.7043\n",
      "\n",
      "Epoch 00805: val_loss did not improve from -1.13603\n",
      "Epoch 806/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: 0.5405 - val_loss: 0.4477\n",
      "\n",
      "Epoch 00806: val_loss did not improve from -1.13603\n",
      "Epoch 807/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 0.3562 - val_loss: 0.3375\n",
      "\n",
      "Epoch 00807: val_loss did not improve from -1.13603\n",
      "Epoch 808/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 0.2691 - val_loss: 0.2960\n",
      "\n",
      "Epoch 00808: val_loss did not improve from -1.13603\n",
      "Epoch 809/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: 0.6394 - val_loss: 1.0785\n",
      "\n",
      "Epoch 00809: val_loss did not improve from -1.13603\n",
      "Epoch 810/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: 0.7683 - val_loss: 0.7107\n",
      "\n",
      "Epoch 00810: val_loss did not improve from -1.13603\n",
      "Epoch 811/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: 0.5596 - val_loss: 0.4242\n",
      "\n",
      "Epoch 00811: val_loss did not improve from -1.13603\n",
      "Epoch 812/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: 1.5720 - val_loss: 0.9498\n",
      "\n",
      "Epoch 00812: val_loss did not improve from -1.13603\n",
      "Epoch 813/1000\n",
      "281/281 [==============================] - 29s 103ms/step - loss: 0.7711 - val_loss: 0.8097\n",
      "\n",
      "Epoch 00813: val_loss did not improve from -1.13603\n",
      "Epoch 814/1000\n",
      "281/281 [==============================] - 29s 103ms/step - loss: 2.0019 - val_loss: 1.4736\n",
      "\n",
      "Epoch 00814: val_loss did not improve from -1.13603\n",
      "Epoch 815/1000\n",
      "281/281 [==============================] - 29s 103ms/step - loss: 0.7820 - val_loss: 0.4717\n",
      "\n",
      "Epoch 00815: val_loss did not improve from -1.13603\n",
      "Epoch 816/1000\n",
      "281/281 [==============================] - 29s 103ms/step - loss: 0.3973 - val_loss: 0.7941\n",
      "\n",
      "Epoch 00816: val_loss did not improve from -1.13603\n",
      "Epoch 817/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 0.3105 - val_loss: 0.3891\n",
      "\n",
      "Epoch 00817: val_loss did not improve from -1.13603\n",
      "Epoch 818/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 0.1983 - val_loss: 0.3322\n",
      "\n",
      "Epoch 00818: val_loss did not improve from -1.13603\n",
      "Epoch 819/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 0.3021 - val_loss: 0.3541\n",
      "\n",
      "Epoch 00819: val_loss did not improve from -1.13603\n",
      "Epoch 820/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 0.1114 - val_loss: 0.2568\n",
      "\n",
      "Epoch 00820: val_loss did not improve from -1.13603\n",
      "Epoch 821/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.0596 - val_loss: 0.1482\n",
      "\n",
      "Epoch 00821: val_loss did not improve from -1.13603\n",
      "Epoch 822/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.1169 - val_loss: 0.0695\n",
      "\n",
      "Epoch 00822: val_loss did not improve from -1.13603\n",
      "Epoch 823/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.1260 - val_loss: 0.2547\n",
      "\n",
      "Epoch 00823: val_loss did not improve from -1.13603\n",
      "Epoch 824/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.2126 - val_loss: 0.1805\n",
      "\n",
      "Epoch 00824: val_loss did not improve from -1.13603\n",
      "Epoch 825/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.2004 - val_loss: -0.0602\n",
      "\n",
      "Epoch 00825: val_loss did not improve from -1.13603\n",
      "Epoch 826/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 0.2771 - val_loss: 0.2066\n",
      "\n",
      "Epoch 00826: val_loss did not improve from -1.13603\n",
      "Epoch 827/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.0452 - val_loss: 0.1430\n",
      "\n",
      "Epoch 00827: val_loss did not improve from -1.13603\n",
      "Epoch 828/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: -0.0710 - val_loss: -0.0031\n",
      "\n",
      "Epoch 00828: val_loss did not improve from -1.13603\n",
      "Epoch 829/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 3.6929 - val_loss: 2.4425\n",
      "\n",
      "Epoch 00829: val_loss did not improve from -1.13603\n",
      "Epoch 830/1000\n",
      "281/281 [==============================] - 28s 99ms/step - loss: 2.0660 - val_loss: 2.0645\n",
      "\n",
      "Epoch 00830: val_loss did not improve from -1.13603\n",
      "Epoch 831/1000\n",
      "281/281 [==============================] - 28s 99ms/step - loss: 2.0501 - val_loss: 2.0611\n",
      "\n",
      "Epoch 00831: val_loss did not improve from -1.13603\n",
      "Epoch 832/1000\n",
      "281/281 [==============================] - 28s 98ms/step - loss: 2.0581 - val_loss: 2.0521\n",
      "\n",
      "Epoch 00832: val_loss did not improve from -1.13603\n",
      "Epoch 833/1000\n",
      "281/281 [==============================] - 28s 98ms/step - loss: 2.0720 - val_loss: 2.0482\n",
      "\n",
      "Epoch 00833: val_loss did not improve from -1.13603\n",
      "Epoch 834/1000\n",
      "281/281 [==============================] - 27s 98ms/step - loss: 2.0841 - val_loss: 2.0476\n",
      "\n",
      "Epoch 00834: val_loss did not improve from -1.13603\n",
      "Epoch 835/1000\n",
      "281/281 [==============================] - 27s 97ms/step - loss: 2.0808 - val_loss: 2.0496\n",
      "\n",
      "Epoch 00835: val_loss did not improve from -1.13603\n",
      "Epoch 836/1000\n",
      "281/281 [==============================] - 28s 99ms/step - loss: 2.0802 - val_loss: 2.0515\n",
      "\n",
      "Epoch 00836: val_loss did not improve from -1.13603\n",
      "Epoch 837/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 2.0733 - val_loss: 2.0549\n",
      "\n",
      "Epoch 00837: val_loss did not improve from -1.13603\n",
      "Epoch 838/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 2.0593 - val_loss: 2.0510\n",
      "\n",
      "Epoch 00838: val_loss did not improve from -1.13603\n",
      "Epoch 839/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 2.0441 - val_loss: 2.0547\n",
      "\n",
      "Epoch 00839: val_loss did not improve from -1.13603\n",
      "Epoch 840/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 2.0335 - val_loss: 2.0521\n",
      "\n",
      "Epoch 00840: val_loss did not improve from -1.13603\n",
      "Epoch 841/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 2.0440 - val_loss: 2.0517\n",
      "\n",
      "Epoch 00841: val_loss did not improve from -1.13603\n",
      "Epoch 842/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 2.0430 - val_loss: 2.0511\n",
      "\n",
      "Epoch 00842: val_loss did not improve from -1.13603\n",
      "Epoch 843/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 2.0593 - val_loss: 2.0434\n",
      "\n",
      "Epoch 00843: val_loss did not improve from -1.13603\n",
      "Epoch 844/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 2.0564 - val_loss: 2.0483\n",
      "\n",
      "Epoch 00844: val_loss did not improve from -1.13603\n",
      "Epoch 845/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 2.0577 - val_loss: 2.0460\n",
      "\n",
      "Epoch 00845: val_loss did not improve from -1.13603\n",
      "Epoch 846/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: 2.0620 - val_loss: 2.0472\n",
      "\n",
      "Epoch 00846: val_loss did not improve from -1.13603\n",
      "Epoch 847/1000\n",
      "281/281 [==============================] - 29s 103ms/step - loss: 2.0608 - val_loss: 2.0476\n",
      "\n",
      "Epoch 00847: val_loss did not improve from -1.13603\n",
      "Epoch 848/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 2.0646 - val_loss: 2.0536\n",
      "\n",
      "Epoch 00848: val_loss did not improve from -1.13603\n",
      "Epoch 849/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 2.0572 - val_loss: 2.0615\n",
      "\n",
      "Epoch 00849: val_loss did not improve from -1.13603\n",
      "Epoch 850/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 2.0651 - val_loss: 2.0657\n",
      "\n",
      "Epoch 00850: val_loss did not improve from -1.13603\n",
      "Epoch 851/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 2.0806 - val_loss: 2.0738\n",
      "\n",
      "Epoch 00851: val_loss did not improve from -1.13603\n",
      "Epoch 852/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 2.0794 - val_loss: 2.0720\n",
      "\n",
      "Epoch 00852: val_loss did not improve from -1.13603\n",
      "Epoch 853/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 2.0853 - val_loss: 2.0669\n",
      "\n",
      "Epoch 00853: val_loss did not improve from -1.13603\n",
      "Epoch 854/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 2.0658 - val_loss: 2.0669\n",
      "\n",
      "Epoch 00854: val_loss did not improve from -1.13603\n",
      "Epoch 855/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 2.0602 - val_loss: 2.0693\n",
      "\n",
      "Epoch 00855: val_loss did not improve from -1.13603\n",
      "Epoch 856/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: 2.0507 - val_loss: 2.0678\n",
      "\n",
      "Epoch 00856: val_loss did not improve from -1.13603\n",
      "Epoch 857/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 2.0444 - val_loss: 2.0722\n",
      "\n",
      "Epoch 00857: val_loss did not improve from -1.13603\n",
      "Epoch 858/1000\n",
      "281/281 [==============================] - 29s 101ms/step - loss: 2.0523 - val_loss: 2.0772\n",
      "\n",
      "Epoch 00858: val_loss did not improve from -1.13603\n",
      "Epoch 859/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: 2.0552 - val_loss: 2.0798\n",
      "\n",
      "Epoch 00859: val_loss did not improve from -1.13603\n",
      "Epoch 860/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 2.0667 - val_loss: 2.0844\n",
      "\n",
      "Epoch 00860: val_loss did not improve from -1.13603\n",
      "Epoch 861/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 2.0745 - val_loss: 2.0822\n",
      "\n",
      "Epoch 00861: val_loss did not improve from -1.13603\n",
      "Epoch 862/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: 2.0667 - val_loss: 2.0820\n",
      "\n",
      "Epoch 00862: val_loss did not improve from -1.13603\n",
      "Epoch 863/1000\n",
      "281/281 [==============================] - 28s 99ms/step - loss: 2.0712 - val_loss: 2.0796\n",
      "\n",
      "Epoch 00863: val_loss did not improve from -1.13603\n",
      "Epoch 864/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 2.0861 - val_loss: 2.0805\n",
      "\n",
      "Epoch 00864: val_loss did not improve from -1.13603\n",
      "Epoch 865/1000\n",
      "281/281 [==============================] - 28s 99ms/step - loss: 2.0950 - val_loss: 2.0696\n",
      "\n",
      "Epoch 00865: val_loss did not improve from -1.13603\n",
      "Epoch 866/1000\n",
      "281/281 [==============================] - 28s 99ms/step - loss: 2.1034 - val_loss: 2.0645\n",
      "\n",
      "Epoch 00866: val_loss did not improve from -1.13603\n",
      "Epoch 867/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: 2.0974 - val_loss: 2.0593\n",
      "\n",
      "Epoch 00867: val_loss did not improve from -1.13603\n",
      "Epoch 868/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 2.0795 - val_loss: 2.0472\n",
      "\n",
      "Epoch 00868: val_loss did not improve from -1.13603\n",
      "Epoch 869/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: 2.0633 - val_loss: 2.0522\n",
      "\n",
      "Epoch 00869: val_loss did not improve from -1.13603\n",
      "Epoch 870/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 2.0584 - val_loss: 2.0467\n",
      "\n",
      "Epoch 00870: val_loss did not improve from -1.13603\n",
      "Epoch 871/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 2.0578 - val_loss: 2.0453\n",
      "\n",
      "Epoch 00871: val_loss did not improve from -1.13603\n",
      "Epoch 872/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: 2.0592 - val_loss: 2.0393\n",
      "\n",
      "Epoch 00872: val_loss did not improve from -1.13603\n",
      "Epoch 873/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 2.0702 - val_loss: 2.0394\n",
      "\n",
      "Epoch 00873: val_loss did not improve from -1.13603\n",
      "Epoch 874/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 2.0814 - val_loss: 2.0353\n",
      "\n",
      "Epoch 00874: val_loss did not improve from -1.13603\n",
      "Epoch 875/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: 2.0895 - val_loss: 2.0351\n",
      "\n",
      "Epoch 00875: val_loss did not improve from -1.13603\n",
      "Epoch 876/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 2.0964 - val_loss: 2.0396\n",
      "\n",
      "Epoch 00876: val_loss did not improve from -1.13603\n",
      "Epoch 877/1000\n",
      "281/281 [==============================] - 29s 103ms/step - loss: 2.0805 - val_loss: 2.0347\n",
      "\n",
      "Epoch 00877: val_loss did not improve from -1.13603\n",
      "Epoch 878/1000\n",
      "281/281 [==============================] - 29s 103ms/step - loss: 2.0771 - val_loss: 2.0381\n",
      "\n",
      "Epoch 00878: val_loss did not improve from -1.13603\n",
      "Epoch 879/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: 2.0737 - val_loss: 2.0400\n",
      "\n",
      "Epoch 00879: val_loss did not improve from -1.13603\n",
      "Epoch 880/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 2.0773 - val_loss: 2.0409\n",
      "\n",
      "Epoch 00880: val_loss did not improve from -1.13603\n",
      "Epoch 881/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 2.0855 - val_loss: 2.0431\n",
      "\n",
      "Epoch 00881: val_loss did not improve from -1.13603\n",
      "Epoch 882/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: 2.0927 - val_loss: 2.0510\n",
      "\n",
      "Epoch 00882: val_loss did not improve from -1.13603\n",
      "Epoch 883/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 2.0935 - val_loss: 2.0488\n",
      "\n",
      "Epoch 00883: val_loss did not improve from -1.13603\n",
      "Epoch 884/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 2.0839 - val_loss: 2.0479\n",
      "\n",
      "Epoch 00884: val_loss did not improve from -1.13603\n",
      "Epoch 885/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 2.0658 - val_loss: 2.0503\n",
      "\n",
      "Epoch 00885: val_loss did not improve from -1.13603\n",
      "Epoch 886/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 2.0617 - val_loss: 2.0481\n",
      "\n",
      "Epoch 00886: val_loss did not improve from -1.13603\n",
      "Epoch 887/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 2.0532 - val_loss: 2.0486\n",
      "\n",
      "Epoch 00887: val_loss did not improve from -1.13603\n",
      "Epoch 888/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 2.0500 - val_loss: 2.0507\n",
      "\n",
      "Epoch 00888: val_loss did not improve from -1.13603\n",
      "Epoch 889/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 2.0585 - val_loss: 2.0604\n",
      "\n",
      "Epoch 00889: val_loss did not improve from -1.13603\n",
      "Epoch 890/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 2.0667 - val_loss: 2.0614\n",
      "\n",
      "Epoch 00890: val_loss did not improve from -1.13603\n",
      "Epoch 891/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 2.0732 - val_loss: 2.0655\n",
      "\n",
      "Epoch 00891: val_loss did not improve from -1.13603\n",
      "Epoch 892/1000\n",
      "281/281 [==============================] - 28s 99ms/step - loss: 2.0741 - val_loss: 2.0579\n",
      "\n",
      "Epoch 00892: val_loss did not improve from -1.13603\n",
      "Epoch 893/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 2.0703 - val_loss: 2.0537\n",
      "\n",
      "Epoch 00893: val_loss did not improve from -1.13603\n",
      "Epoch 894/1000\n",
      "281/281 [==============================] - 28s 98ms/step - loss: 2.0772 - val_loss: 2.0558\n",
      "\n",
      "Epoch 00894: val_loss did not improve from -1.13603\n",
      "Epoch 895/1000\n",
      "281/281 [==============================] - 28s 98ms/step - loss: 2.0802 - val_loss: 2.0567\n",
      "\n",
      "Epoch 00895: val_loss did not improve from -1.13603\n",
      "Epoch 896/1000\n",
      "281/281 [==============================] - 28s 98ms/step - loss: 2.0823 - val_loss: 2.0547\n",
      "\n",
      "Epoch 00896: val_loss did not improve from -1.13603\n",
      "Epoch 897/1000\n",
      "281/281 [==============================] - 28s 101ms/step - loss: 2.0705 - val_loss: 2.0537\n",
      "\n",
      "Epoch 00897: val_loss did not improve from -1.13603\n",
      "Epoch 898/1000\n",
      "281/281 [==============================] - 28s 100ms/step - loss: 2.0673 - val_loss: 2.0507\n",
      "\n",
      "Epoch 00898: val_loss did not improve from -1.13603\n",
      "Epoch 899/1000\n",
      "281/281 [==============================] - 29s 102ms/step - loss: 2.0729 - val_loss: 2.0484\n",
      "\n",
      "Epoch 00899: val_loss did not improve from -1.13603\n",
      "Epoch 900/1000\n",
      "281/281 [==============================] - 30s 106ms/step - loss: 2.0715 - val_loss: 2.0496\n",
      "\n",
      "Epoch 00900: val_loss did not improve from -1.13603\n",
      "Epoch 901/1000\n",
      "281/281 [==============================] - 29s 105ms/step - loss: 2.0670 - val_loss: 2.0513\n",
      "\n",
      "Epoch 00901: val_loss did not improve from -1.13603\n",
      "Epoch 902/1000\n",
      "281/281 [==============================] - 29s 104ms/step - loss: 2.0658 - val_loss: 2.0454\n",
      "\n",
      "Epoch 00902: val_loss did not improve from -1.13603\n",
      "Epoch 903/1000\n",
      "281/281 [==============================] - 30s 105ms/step - loss: 2.0631 - val_loss: 2.0457\n",
      "\n",
      "Epoch 00903: val_loss did not improve from -1.13603\n",
      "Epoch 904/1000\n",
      "281/281 [==============================] - 31s 110ms/step - loss: 2.0722 - val_loss: 2.0437\n",
      "\n",
      "Epoch 00904: val_loss did not improve from -1.13603\n",
      "Epoch 905/1000\n",
      "281/281 [==============================] - 31s 110ms/step - loss: 2.0833 - val_loss: 2.0412\n",
      "\n",
      "Epoch 00905: val_loss did not improve from -1.13603\n",
      "Epoch 906/1000\n",
      "281/281 [==============================] - 32s 115ms/step - loss: 2.0881 - val_loss: 2.0359\n",
      "\n",
      "Epoch 00906: val_loss did not improve from -1.13603\n",
      "Epoch 907/1000\n",
      "281/281 [==============================] - 31s 111ms/step - loss: 2.0902 - val_loss: 2.0362\n",
      "\n",
      "Epoch 00907: val_loss did not improve from -1.13603\n",
      "Epoch 908/1000\n",
      "281/281 [==============================] - 30s 108ms/step - loss: 2.0956 - val_loss: 2.0368\n",
      "\n",
      "Epoch 00908: val_loss did not improve from -1.13603\n",
      "Epoch 909/1000\n",
      "281/281 [==============================] - 31s 111ms/step - loss: 2.0929 - val_loss: 2.0462\n",
      "\n",
      "Epoch 00909: val_loss did not improve from -1.13603\n",
      "Epoch 910/1000\n",
      "148/281 [==============>...............] - ETA: 13s - loss: 2.0902"
     ]
    }
   ],
   "source": [
    "model_name = 'PFN_MDN_STMC_v2_1'\n",
    "chkpoint = tf.keras.callbacks.ModelCheckpoint('model/' + model_name + '.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "# earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=150, verbose=0, restore_best_weights=True)\n",
    "\n",
    "# save history to csv, or to npy later, in order to plot comparison of multiple training runs\n",
    "history_logger = tf.keras.callbacks.CSVLogger('log/' + model_name + '.log', separator=',', append=True)\n",
    "\n",
    "# load previous model if it exists\n",
    "if os.path.isfile('model/' + model_name + '.h5'):\n",
    "    PFN_mdn.load_weights('model/' + model_name + '.h5')\n",
    "\n",
    "history_ct = PFN_mdn.fit(minibatches(data, target, batch_size=1024),\n",
    "        epochs=1000,\n",
    "        steps_per_epoch=len(data)//1024,\n",
    "        validation_data=minibatches(val_data, val_target, batch_size=1024),\n",
    "        validation_steps=len(val_data)//1024,\n",
    "        verbose=1,\n",
    "        callbacks=[chkpoint,history_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "model_name = 'pfn_mdn_regressor_1'\n",
    "chkpoint = tf.keras.callbacks.ModelCheckpoint('model/' + model_name + '.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "# earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=150, verbose=0, restore_best_weights=True)\n",
    "\n",
    "# save history to csv, or to npy later, in order to plot comparison of multiple training runs\n",
    "history_logger = tf.keras.callbacks.CSVLogger('log/' + model_name + '.log', separator=',', append=True)\n",
    "\n",
    "# back up\n",
    "# backup  = tf.keras.callbacks.BackupAndRestore(backup_dir=\"backup\")\n",
    "\n",
    "t0 = t.time()\n",
    "history_ct = PFN_mdn.fit(data_generator(data, target, batch_size=1024),\n",
    "        epochs=1000,\n",
    "        steps_per_epoch=len(data)//1024,\n",
    "        validation_data=data_generator(val_data, val_target, batch_size=800),\n",
    "        validation_steps=len(val_data)//800,\n",
    "        verbose=1,\n",
    "        callbacks=[chkpoint,history_logger])\n",
    "t1 = t.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfn_history = np.load(ext_modelpath + 'pfn_regressor_3f_1.log.npy',allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('PFN_MDN_regressor_weight_nl.log.npy',history_ct.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Time to train: '+str(t1-t0)+' (s)')\n",
    "print('Time to train: '+str((t1-t0)/60)+' (m)')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e2f6deba557dc7d8d1b4cf161216c8920ae0cc2d6a027649b4e5d7481f4460e1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tensorflow-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
