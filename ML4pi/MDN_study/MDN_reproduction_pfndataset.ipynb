{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_prefix = 'D:/Work/EPE/ML4pi/'\n",
    "plotpath = path_prefix+'plots/'\n",
    "modelpath_c = path_prefix+''\n",
    "modelpath = path_prefix+''\n",
    "ext_path = \"H:/EPE_file_storage/\"\n",
    "ext_modelpath = ext_path + \"Model/\"\n",
    "ext_datapath = ext_path + \"data_storage/pipm/img/\"\n",
    "ext_plotpath = ext_path + \"plots/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\"EMB1\", \"EMB2\", \"EMB3\", \"TileBar0\", \"TileBar1\", \"TileBar2\"]\n",
    "cell_size_phi = [0.098, 0.0245, 0.0245, 0.1, 0.1, 0.1]\n",
    "cell_size_eta = [0.0031, 0.025, 0.05, 0.1, 0.1, 0.2]\n",
    "len_phi = [4, 16, 16, 4, 4, 4]\n",
    "len_eta = [128, 16, 8, 4, 4, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nfile = 10\n",
    "fileNames = []\n",
    "for i in range(1,Nfile+1):\n",
    "    fileNames.append(ext_datapath + 'X_stmc_' + str(i) + '.npz.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for fname in fileNames:\n",
    "    file_x = np.load(fname)\n",
    "    X.append(file_x)\n",
    "Xraw = np.concatenate(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xraw = np.load(ext_datapath + 'Xstmc_100.npy')\n",
    "Yraw = np.load(ext_datapath + 'Ystmc_100.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(path_prefix)\n",
    "from util import resolution_util as ru\n",
    "from util import plot_util as pu\n",
    "from util import ml_util as mu\n",
    "import uproot3 as ur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_zero_mask = Yraw > .05\n",
    "Ylog = np.log(Yraw[target_zero_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## RAW DATA ##\n",
    "#=================================================================\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "bins=np.linspace(0,2000,50,endpoint=True)\n",
    "plt.hist(Yraw[target_zero_mask], color='orange', bins=bins, density=True, alpha=.5, edgecolor='black',\n",
    "        label='Particle Truth Energy')\n",
    "plt.title('Truth Particle Energy', fontsize=16)\n",
    "plt.xlabel('E [GeV]', fontsize=14)\n",
    "plt.xlim(np.min(bins),np.max(bins))\n",
    "plt.yscale('log')\n",
    "plt.ylim(.0001,.0025)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('Regression_Plots/November21/EnergyTargets_PIPMnoEM_log_2021-11-22.png', format='png')\n",
    "plt.show()\n",
    "\n",
    "## NORMALIZED DATA ##\n",
    "#=================================================================\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "bins=np.linspace(np.log(np.exp(2)), np.log(2000), 50, endpoint=True)\n",
    "plt.hist(Ylog, color='forestgreen', bins=bins, density=True, alpha=.5, edgecolor='black',\n",
    "        label='log')\n",
    "plt.title('Regression Targets', fontsize=16)\n",
    "plt.xlabel('Log(E) [GeV]', fontsize=14)\n",
    "plt.xlim(np.min(bins),np.max(bins))\n",
    "plt.ylim(0,.4)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('Regression_Plots/November21/EnergyTargets_PIPMnoEM_log_2021-11-22.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# create scaler\n",
    "scaler_e = StandardScaler()\n",
    "scaler_cell = StandardScaler()\n",
    "# fit and transform in one step\n",
    "Y_scal = scaler_e.fit_transform(Ylog.reshape(-1,1))\n",
    "X_scal = scaler_cell.fit_transform(Xraw[target_zero_mask.reshape(-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(544815, 938)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(544815, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_scal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of devices: 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "ngpu = strategy.num_replicas_in_sync\n",
    "print ('Number of devices: {}'.format(ngpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(Xraw[target_zero_mask.reshape(-1)],\n",
    "                                                                    Ylog,\n",
    "                                                                    test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "# from . import plot_util as pu\n",
    "from util import plot_util as pu\n",
    "\n",
    "\n",
    "def _q16(x):\n",
    "    # get the IQR via the percentile function\n",
    "    # 84 is median + 1 sigma, 16 is median - 1 sigma\n",
    "    return np.percentile(x, 16)\n",
    "\n",
    "def _q84(x):\n",
    "    # get the IQR via the percentile function\n",
    "    # 84 is median + 1 sigma, 16 is median - 1 sigma\n",
    "    return np.percentile(x, 84)\n",
    "\n",
    "def responsePlot(x, y, figfile='', statistic='median',\n",
    "                 xlabel='True Energy [GeV]', ylabel='Predicted Energy / True Energy',\n",
    "                 xlim=(0.3,1000), ylim=(0,3), baseline=True,\n",
    "                 atlas_x=-1, atlas_y=-1, simulation=False,\n",
    "                 textlist=[]):\n",
    "    xbin = [10**exp for exp in np.arange(-1.0, 3.1, 0.1)]\n",
    "    ybin = np.arange(0., 3.1, 0.1)\n",
    "    xcenter = [(xbin[i] + xbin[i+1]) / 2 for i in range(len(xbin)-1)]\n",
    "    \n",
    "    responseMed = stats.binned_statistic(x, y, bins=xbin, statistic=statistic).statistic\n",
    "    responseQ16 = stats.binned_statistic(x, y, bins=xbin, statistic=_q16).statistic\n",
    "    responseQ84 = stats.binned_statistic(x, y, bins=xbin, statistic=_q84).statistic\n",
    "\n",
    "    responseQ16 = responseMed - responseQ16\n",
    "    responseQ84 = responseQ84 - responseMed\n",
    "\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    fig = plt.figure()\n",
    "    fig.patch.set_facecolor('white')\n",
    "    plt.hist2d(x, y, bins=[xbin, ybin], norm=LogNorm(),zorder = -1)\n",
    "    plt.errorbar(xcenter, responseMed, yerr=[responseQ16,responseQ84], color='red')\n",
    "    if baseline:\n",
    "        plt.plot([0.1, 1000], [1, 1], linestyle='--', color='black')\n",
    "    plt.xscale('log')\n",
    "    plt.ylim(ylim)\n",
    "    plt.xlim(xlim)\n",
    "    pu.ampl.set_xlabel(xlabel)\n",
    "    pu.ampl.set_ylabel(ylabel)\n",
    "    # ampl.set_zlabel('Clusters')\n",
    "    cb = plt.colorbar()\n",
    "    cb.ax.set_ylabel('Clusters')\n",
    "    # plt.legend()\n",
    "\n",
    "    pu.drawLabels(fig, atlas_x, atlas_y, simulation, textlist)\n",
    "\n",
    "    if figfile != '':\n",
    "        plt.savefig(figfile)\n",
    "    plt.show()\n",
    "\n",
    "    return xcenter, responseMed\n",
    "\n",
    "\n",
    "def _iqrOverMed(x):\n",
    "    # get the IQR via the percentile function\n",
    "    # 84 is median + 1 sigma, 16 is median - 1 sigma\n",
    "    q16, q84 = np.percentile(x, [16, 84])\n",
    "    return (q84 - q16) / (2 * np.median(x))\n",
    "\n",
    "\n",
    "def resolutionPlot(x, y, figfile='',\n",
    "                   xlabel='True Energy [GeV]', ylabel='Response IQR / (2 x Median)',\n",
    "                   atlas_x=-1, atlas_y=-1, simulation=False,\n",
    "                   xlim=(0.3,1000), ylim=(0,1), \n",
    "                   textlist=[]):\n",
    "    xbin = [10**exp for exp in  np.arange(-1.0, 3.1, 0.1)]\n",
    "    xcenter = [(xbin[i] + xbin[i+1]) / 2 for i in range(len(xbin)-1)]\n",
    "\n",
    "    resolution = stats.binned_statistic(x, y, bins=xbin, statistic=_iqrOverMed).statistic\n",
    "    \n",
    "    plt.cla(); plt.clf()\n",
    "    fig = plt.figure()\n",
    "    fig.patch.set_facecolor('white')\n",
    "    plt.plot(xcenter, resolution)\n",
    "    plt.xscale('log')\n",
    "    plt.xlim(xlim)\n",
    "    plt.ylim(ylim)\n",
    "    pu.ampl.set_xlabel(xlabel)\n",
    "    pu.ampl.set_ylabel(ylabel)\n",
    "\n",
    "    pu.drawLabels(fig, atlas_x, atlas_y, simulation, textlist)\n",
    "\n",
    "    if figfile != '':\n",
    "        plt.savefig(figfile)\n",
    "    plt.show()\n",
    "\n",
    "    return xcenter, resolution\n",
    "\n",
    "\n",
    "def histogramSlices(x, ylist, labels=[''], xstep=0.2, statistic='iqr', title = 'Response',\n",
    "                 xlabel='Predicted Energy / True Energy', ylabel='Clusters', alpha=1.,\n",
    "                 xlim=(0.3,1000.), ylim=(0.,3.1), binsize=0.05, baseline=False, logscale=False, density=False,\n",
    "                 atlas_x=-1, atlas_y=-1, simulation=False,\n",
    "                 textlist=[]):\n",
    "    \n",
    "    if type(ylist) != type([]):\n",
    "        ylist = [ylist]\n",
    "\n",
    "    xbin = [10**exp for exp in np.arange(-1.0, 3.1, xstep)]\n",
    "    last_xbin = [10**exp for exp in np.arange(-1.0, 3.1, xstep)]\n",
    "    \n",
    "    ybin = np.arange(ylim[0], ylim[1], binsize)\n",
    "\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "\n",
    "    for xbin_left,xbin_right in zip(last_xbin,xbin[1:]):\n",
    "        fig = plt.figure()\n",
    "        val_mask = np.logical_and(x > xbin_left, x < xbin_right)\n",
    "\n",
    "        for y,label in zip(ylist,labels):\n",
    "            if statistic == 'iqr':\n",
    "                med = np.median(y[val_mask])\n",
    "                iqr = np.percentile(y[val_mask], q=84) - np.percentile(y[val_mask], q=16)\n",
    "                plt.hist(y[val_mask], bins=ybin, density=density, \n",
    "                        label = label + ' Median = {:.2f}, IQR = {:.2f}'.format(med, iqr),\n",
    "                         alpha=alpha)\n",
    "            elif statistic == 'std':\n",
    "                mu = np.mean(y[val_mask])\n",
    "                sig = np.std(y[val_mask])\n",
    "                plt.hist(y[val_mask], bins=ybin, density=density, \n",
    "                        label = label + ' Mean = {:.2f}, Std. Dev. = {:.2f}'.format(mu, sig),\n",
    "                         alpha=alpha)\n",
    "            else:\n",
    "                plt.hist(y[val_mask], bins=ybin, density=density,\n",
    "                         label = label,\n",
    "                         alpha=alpha)\n",
    "            \n",
    "            if baseline:\n",
    "                x1 = np.linspace(-6,6,100)\n",
    "                pdf = stats.norm.pdf(x1)\n",
    "                plt.plot(x1, pdf, label='Unit Normal')\n",
    "\n",
    "        if len(textlist) >= 2:\n",
    "            textlist[1]['text'] = '{:.4g} - {:.4g} GeV Clusters'.format(xbin_left, xbin_right)\n",
    "            pu.drawLabels(fig, atlas_x, atlas_y, simulation, textlist)\n",
    "\n",
    "        if logscale:\n",
    "            plt.yscale('log')\n",
    "\n",
    "        # plt.title(title + ' {:.4g} - {:.4g} GeV'.format(xbin_left, xbin_right))\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.xlim(ylim)\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([32, 938]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.01, 0.2))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):\n",
    "  model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax),\n",
    "  ])\n",
    "  model.compile(\n",
    "      optimizer=hparams[HP_OPTIMIZER],\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      metrics=['accuracy'],\n",
    "  )\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1) # Run with 1 epoch to speed things up for demo purposes\n",
    "_, accuracy = model.evaluate(x_test, y_test)\n",
    "return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DNN(hparams):\n",
    "    number_pixels = 512 + 256 + 128 + 16 + 16 + 8\n",
    "    # create model\n",
    "    if True:\n",
    "        model = Sequential()\n",
    "        features = number_pixels + 2\n",
    "        model.add(Dense(features, input_dim=features, activation='relu'))\n",
    "        model.add(Dense(hparams[HP_NUM_UNITS], activation='relu'))\n",
    "        model.add(Dense(hparams[HP_NUM_UNITS], activation='relu'))\n",
    "        model.Dropout(hparams[HP_DROPOUT], activation='relu')\n",
    "        model.add(Dense(units=1, activation='linear'))\n",
    "        opt = Adam(learning_rate=1e-3, decay=1e-6)\n",
    "        model.compile(optimizer=hparams[HP_OPTIMIZER], loss='mse', metrics=['mae','mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 938)               880782    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 938)               880782    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 469)               440391    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 470       \n",
      "=================================================================\n",
      "Total params: 2,202,425\n",
      "Trainable params: 2,202,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as kb\n",
    "kb.clear_session()\n",
    "\n",
    "regressor_All = KerasRegressor(build_fn=DNN, batch_size=2500, epochs=500, verbose=1)\n",
    "print(DNN().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadModel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 6.2046 - mae: 1.8639 - mse: 6.2046 - val_loss: 3.1075 - val_mae: 1.2983 - val_mse: 3.1075\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.10755, saving model to dnn_regressor_pfnd.h5\n",
      "Epoch 2/500\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 2.5066 - mae: 1.1601 - mse: 2.5066 - val_loss: 2.4365 - val_mae: 1.1230 - val_mse: 2.4365\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.10755 to 2.43649, saving model to dnn_regressor_pfnd.h5\n",
      "Epoch 3/500\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 2.2351 - mae: 1.0736 - mse: 2.2351 - val_loss: 2.1983 - val_mae: 1.0621 - val_mse: 2.1983\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.43649 to 2.19834, saving model to dnn_regressor_pfnd.h5\n",
      "Epoch 4/500\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 2.1171 - mae: 1.0295 - mse: 2.1171 - val_loss: 2.1196 - val_mae: 1.0171 - val_mse: 2.1196\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.19834 to 2.11958, saving model to dnn_regressor_pfnd.h5\n",
      "Epoch 5/500\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 2.0253 - mae: 0.9953 - mse: 2.0253 - val_loss: 2.0657 - val_mae: 0.9872 - val_mse: 2.0657\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.11958 to 2.06565, saving model to dnn_regressor_pfnd.h5\n",
      "Epoch 6/500\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.9716 - mae: 0.9722 - mse: 1.9716 - val_loss: 1.9879 - val_mae: 0.9629 - val_mse: 1.9879\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.06565 to 1.98791, saving model to dnn_regressor_pfnd.h5\n",
      "Epoch 7/500\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 1.9322 - mae: 0.9550 - mse: 1.9322 - val_loss: 1.9913 - val_mae: 0.9628 - val_mse: 1.9913\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.98791\n",
      "Epoch 8/500\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 1.9020 - mae: 0.9416 - mse: 1.9020 - val_loss: 1.9366 - val_mae: 0.9560 - val_mse: 1.9366\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.98791 to 1.93657, saving model to dnn_regressor_pfnd.h5\n",
      "Epoch 9/500\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 1.8747 - mae: 0.9318 - mse: 1.8747 - val_loss: 1.9470 - val_mae: 0.9479 - val_mse: 1.9470\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.93657\n",
      "Epoch 10/500\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 1.8531 - mae: 0.9221 - mse: 1.8531 - val_loss: 1.9278 - val_mae: 0.9379 - val_mse: 1.9278\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.93657 to 1.92778, saving model to dnn_regressor_pfnd.h5\n",
      "Epoch 11/500\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 1.8380 - mae: 0.9164 - mse: 1.8380 - val_loss: 1.8756 - val_mae: 0.9176 - val_mse: 1.8756\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.92778 to 1.87563, saving model to dnn_regressor_pfnd.h5\n",
      "Epoch 12/500\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.8159 - mae: 0.9076 - mse: 1.8159 - val_loss: 1.9079 - val_mae: 0.9412 - val_mse: 1.9079\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.87563\n",
      "Epoch 13/500\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.8034 - mae: 0.9032 - mse: 1.8034 - val_loss: 1.8680 - val_mae: 0.9161 - val_mse: 1.8680\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.87563 to 1.86800, saving model to dnn_regressor_pfnd.h5\n",
      "Epoch 14/500\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.7920 - mae: 0.8984 - mse: 1.7920 - val_loss: 1.8663 - val_mae: 0.9130 - val_mse: 1.8663\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.86800 to 1.86626, saving model to dnn_regressor_pfnd.h5\n",
      "Epoch 15/500\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.7784 - mae: 0.8949 - mse: 1.7784 - val_loss: 1.8803 - val_mae: 0.9343 - val_mse: 1.8803\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.86626\n",
      "Epoch 16/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.7718 - mae: 0.8925 - mse: 1.7718 - val_loss: 1.8817 - val_mae: 0.9278 - val_mse: 1.8817\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.86626\n",
      "Epoch 17/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.7542 - mae: 0.8864 - mse: 1.7542 - val_loss: 1.8396 - val_mae: 0.8977 - val_mse: 1.8396\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.86626 to 1.83956, saving model to dnn_regressor_pfnd.h5\n",
      "Epoch 18/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.7502 - mae: 0.8861 - mse: 1.7502 - val_loss: 1.8343 - val_mae: 0.9062 - val_mse: 1.8343\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.83956 to 1.83433, saving model to dnn_regressor_pfnd.h5\n",
      "Epoch 19/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.7408 - mae: 0.8823 - mse: 1.7408 - val_loss: 1.8363 - val_mae: 0.8910 - val_mse: 1.8363\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.83433\n",
      "Epoch 20/500\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 1.7345 - mae: 0.8807 - mse: 1.7345 - val_loss: 1.8473 - val_mae: 0.9160 - val_mse: 1.8473\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.83433\n",
      "Epoch 21/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.7197 - mae: 0.8754 - mse: 1.7197 - val_loss: 1.8303 - val_mae: 0.9006 - val_mse: 1.8303\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.83433 to 1.83033, saving model to dnn_regressor_pfnd.h5\n",
      "Epoch 22/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.7062 - mae: 0.8693 - mse: 1.7062 - val_loss: 1.8178 - val_mae: 0.8811 - val_mse: 1.8178\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.83033 to 1.81781, saving model to dnn_regressor_pfnd.h5\n",
      "Epoch 23/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.6958 - mae: 0.8675 - mse: 1.6958 - val_loss: 1.8019 - val_mae: 0.8905 - val_mse: 1.8019\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.81781 to 1.80194, saving model to dnn_regressor_pfnd.h5\n",
      "Epoch 24/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.6904 - mae: 0.8664 - mse: 1.6904 - val_loss: 1.8619 - val_mae: 0.9171 - val_mse: 1.8619\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.80194\n",
      "Epoch 25/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.6791 - mae: 0.8604 - mse: 1.6791 - val_loss: 1.8246 - val_mae: 0.8876 - val_mse: 1.8246\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.80194\n",
      "Epoch 26/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.6676 - mae: 0.8571 - mse: 1.6676 - val_loss: 1.8085 - val_mae: 0.9048 - val_mse: 1.8085\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.80194\n",
      "Epoch 27/500\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 1.6675 - mae: 0.8599 - mse: 1.6675 - val_loss: 1.8287 - val_mae: 0.9012 - val_mse: 1.8287\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.80194\n",
      "Epoch 28/500\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 1.6542 - mae: 0.8543 - mse: 1.6542 - val_loss: 1.8239 - val_mae: 0.8925 - val_mse: 1.8239\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.80194\n",
      "Epoch 29/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.6472 - mae: 0.8496 - mse: 1.6472 - val_loss: 1.8275 - val_mae: 0.8962 - val_mse: 1.8275\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.80194\n",
      "Epoch 30/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.6497 - mae: 0.8556 - mse: 1.6497 - val_loss: 1.8175 - val_mae: 0.9081 - val_mse: 1.8175\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.80194\n",
      "Epoch 31/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.6388 - mae: 0.8492 - mse: 1.6388 - val_loss: 1.8100 - val_mae: 0.8870 - val_mse: 1.8100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.80194\n",
      "Epoch 32/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.6423 - mae: 0.8496 - mse: 1.6423 - val_loss: 1.7967 - val_mae: 0.8937 - val_mse: 1.7967\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.80194 to 1.79672, saving model to dnn_regressor_pfnd.h5\n",
      "Epoch 33/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.6205 - mae: 0.8418 - mse: 1.6205 - val_loss: 1.8200 - val_mae: 0.8988 - val_mse: 1.8200\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.79672\n",
      "Epoch 34/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.6085 - mae: 0.8376 - mse: 1.6085 - val_loss: 1.8206 - val_mae: 0.8772 - val_mse: 1.8206\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.79672\n",
      "Epoch 35/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.5938 - mae: 0.8332 - mse: 1.5938 - val_loss: 1.8082 - val_mae: 0.8956 - val_mse: 1.8082\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.79672\n",
      "Epoch 36/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.5883 - mae: 0.8318 - mse: 1.5883 - val_loss: 1.7981 - val_mae: 0.8776 - val_mse: 1.7981\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.79672\n",
      "Epoch 37/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.5855 - mae: 0.8311 - mse: 1.5855 - val_loss: 1.7861 - val_mae: 0.8959 - val_mse: 1.7861\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.79672 to 1.78610, saving model to dnn_regressor_pfnd.h5\n",
      "Epoch 38/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.5769 - mae: 0.8288 - mse: 1.5769 - val_loss: 1.7831 - val_mae: 0.8864 - val_mse: 1.7831\n",
      "\n",
      "Epoch 00038: val_loss improved from 1.78610 to 1.78309, saving model to dnn_regressor_pfnd.h5\n",
      "Epoch 39/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.5581 - mae: 0.8198 - mse: 1.5581 - val_loss: 1.8266 - val_mae: 0.8734 - val_mse: 1.8266\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.78309\n",
      "Epoch 40/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.5455 - mae: 0.8165 - mse: 1.5455 - val_loss: 1.8411 - val_mae: 0.8753 - val_mse: 1.8411\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.78309\n",
      "Epoch 41/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.5379 - mae: 0.8132 - mse: 1.5379 - val_loss: 1.7846 - val_mae: 0.8859 - val_mse: 1.7846\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.78309\n",
      "Epoch 42/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.5333 - mae: 0.8125 - mse: 1.5333 - val_loss: 1.8180 - val_mae: 0.9008 - val_mse: 1.8180\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.78309\n",
      "Epoch 43/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.5216 - mae: 0.8085 - mse: 1.5216 - val_loss: 1.8333 - val_mae: 0.8802 - val_mse: 1.8333\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.78309\n",
      "Epoch 44/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.5225 - mae: 0.8107 - mse: 1.5225 - val_loss: 1.7898 - val_mae: 0.8780 - val_mse: 1.7898\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.78309\n",
      "Epoch 45/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.5010 - mae: 0.8005 - mse: 1.5010 - val_loss: 1.8306 - val_mae: 0.8855 - val_mse: 1.8306\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.78309\n",
      "Epoch 46/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.5045 - mae: 0.8024 - mse: 1.5045 - val_loss: 1.7960 - val_mae: 0.8890 - val_mse: 1.7960\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.78309\n",
      "Epoch 47/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.4996 - mae: 0.8024 - mse: 1.4996 - val_loss: 1.8136 - val_mae: 0.8799 - val_mse: 1.8136\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.78309\n",
      "Epoch 48/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.4812 - mae: 0.7931 - mse: 1.4812 - val_loss: 1.8219 - val_mae: 0.8750 - val_mse: 1.8219\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.78309\n",
      "Epoch 49/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.4819 - mae: 0.7949 - mse: 1.4819 - val_loss: 1.8208 - val_mae: 0.8766 - val_mse: 1.8208\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.78309\n",
      "Epoch 50/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.4667 - mae: 0.7892 - mse: 1.4667 - val_loss: 1.8248 - val_mae: 0.8736 - val_mse: 1.8248\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.78309\n",
      "Epoch 51/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.4646 - mae: 0.7896 - mse: 1.4646 - val_loss: 1.8839 - val_mae: 0.8938 - val_mse: 1.8839\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.78309\n",
      "Epoch 52/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.4572 - mae: 0.7833 - mse: 1.4572 - val_loss: 1.8217 - val_mae: 0.8824 - val_mse: 1.8217\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.78309\n",
      "Epoch 53/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.4405 - mae: 0.7787 - mse: 1.4405 - val_loss: 1.8141 - val_mae: 0.8783 - val_mse: 1.8141\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.78309\n",
      "Epoch 54/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.4411 - mae: 0.7780 - mse: 1.4411 - val_loss: 1.8471 - val_mae: 0.8935 - val_mse: 1.8471\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.78309\n",
      "Epoch 55/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.4353 - mae: 0.7766 - mse: 1.4353 - val_loss: 1.8436 - val_mae: 0.9180 - val_mse: 1.8436\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.78309\n",
      "Epoch 56/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.4186 - mae: 0.7700 - mse: 1.4186 - val_loss: 1.8238 - val_mae: 0.8883 - val_mse: 1.8238\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.78309\n",
      "Epoch 57/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.4193 - mae: 0.7719 - mse: 1.4193 - val_loss: 1.8370 - val_mae: 0.9126 - val_mse: 1.8370\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.78309\n",
      "Epoch 58/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.4075 - mae: 0.7664 - mse: 1.4075 - val_loss: 1.8253 - val_mae: 0.8799 - val_mse: 1.8253\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.78309\n",
      "Epoch 59/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.3923 - mae: 0.7610 - mse: 1.3923 - val_loss: 1.8241 - val_mae: 0.8799 - val_mse: 1.8241\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.78309\n",
      "Epoch 60/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.3922 - mae: 0.7612 - mse: 1.3922 - val_loss: 1.8495 - val_mae: 0.9019 - val_mse: 1.8495\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.78309\n",
      "Epoch 61/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.3847 - mae: 0.7578 - mse: 1.3847 - val_loss: 1.8590 - val_mae: 0.8912 - val_mse: 1.8590\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.78309\n",
      "Epoch 62/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.3792 - mae: 0.7550 - mse: 1.3792 - val_loss: 1.9080 - val_mae: 0.9152 - val_mse: 1.9080\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.78309\n",
      "Epoch 63/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.3684 - mae: 0.7512 - mse: 1.3684 - val_loss: 1.8675 - val_mae: 0.8998 - val_mse: 1.8675\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.78309\n",
      "Epoch 64/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.3625 - mae: 0.7479 - mse: 1.3625 - val_loss: 1.8626 - val_mae: 0.8819 - val_mse: 1.8626\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.78309\n",
      "Epoch 65/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.3543 - mae: 0.7449 - mse: 1.3543 - val_loss: 1.8325 - val_mae: 0.8792 - val_mse: 1.8325\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.78309\n",
      "Epoch 66/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.3437 - mae: 0.7426 - mse: 1.3437 - val_loss: 1.8656 - val_mae: 0.8774 - val_mse: 1.8656\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.78309\n",
      "Epoch 67/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.3401 - mae: 0.7390 - mse: 1.3401 - val_loss: 1.9199 - val_mae: 0.8935 - val_mse: 1.9199\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.78309\n",
      "Epoch 68/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.3473 - mae: 0.7442 - mse: 1.3473 - val_loss: 1.8371 - val_mae: 0.8878 - val_mse: 1.8371\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.78309\n",
      "Epoch 69/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.3258 - mae: 0.7344 - mse: 1.3258 - val_loss: 1.8613 - val_mae: 0.9098 - val_mse: 1.8613\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.78309\n",
      "Epoch 70/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.3168 - mae: 0.7323 - mse: 1.3168 - val_loss: 1.8678 - val_mae: 0.9210 - val_mse: 1.8678\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.78309\n",
      "Epoch 71/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.3140 - mae: 0.7297 - mse: 1.3140 - val_loss: 1.8803 - val_mae: 0.8966 - val_mse: 1.8803\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.78309\n",
      "Epoch 72/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.3069 - mae: 0.7259 - mse: 1.3069 - val_loss: 1.8824 - val_mae: 0.9188 - val_mse: 1.8824\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.78309\n",
      "Epoch 73/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.2963 - mae: 0.7220 - mse: 1.2963 - val_loss: 1.8653 - val_mae: 0.8851 - val_mse: 1.8653\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.78309\n",
      "Epoch 74/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.2910 - mae: 0.7216 - mse: 1.2910 - val_loss: 1.8655 - val_mae: 0.8849 - val_mse: 1.8655\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.78309\n",
      "Epoch 75/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.2903 - mae: 0.7206 - mse: 1.2903 - val_loss: 1.8663 - val_mae: 0.8841 - val_mse: 1.8663\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.78309\n",
      "Epoch 76/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.2814 - mae: 0.7166 - mse: 1.2814 - val_loss: 1.8627 - val_mae: 0.8883 - val_mse: 1.8627\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.78309\n",
      "Epoch 77/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.2756 - mae: 0.7130 - mse: 1.2756 - val_loss: 1.8865 - val_mae: 0.9190 - val_mse: 1.8865\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.78309\n",
      "Epoch 78/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.2733 - mae: 0.7124 - mse: 1.2733 - val_loss: 1.8890 - val_mae: 0.9174 - val_mse: 1.8890\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.78309\n",
      "Epoch 79/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.2586 - mae: 0.7064 - mse: 1.2586 - val_loss: 1.9513 - val_mae: 0.8903 - val_mse: 1.9513\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.78309\n",
      "Epoch 80/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.2616 - mae: 0.7092 - mse: 1.2616 - val_loss: 1.8999 - val_mae: 0.8956 - val_mse: 1.8999\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.78309\n",
      "Epoch 81/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.2531 - mae: 0.7043 - mse: 1.2531 - val_loss: 1.9179 - val_mae: 0.8920 - val_mse: 1.9179\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.78309\n",
      "Epoch 82/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.2532 - mae: 0.7029 - mse: 1.2532 - val_loss: 1.9086 - val_mae: 0.8931 - val_mse: 1.9086\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.78309\n",
      "Epoch 83/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.2360 - mae: 0.6984 - mse: 1.2360 - val_loss: 1.8940 - val_mae: 0.8866 - val_mse: 1.8940\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.78309\n",
      "Epoch 84/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.2365 - mae: 0.6961 - mse: 1.2365 - val_loss: 1.9337 - val_mae: 0.9214 - val_mse: 1.9337\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1.78309\n",
      "Epoch 85/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.2376 - mae: 0.7000 - mse: 1.2376 - val_loss: 1.8685 - val_mae: 0.8860 - val_mse: 1.8685\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.78309\n",
      "Epoch 86/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.2297 - mae: 0.6939 - mse: 1.2297 - val_loss: 1.8896 - val_mae: 0.8793 - val_mse: 1.8896\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.78309\n",
      "Epoch 87/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.2257 - mae: 0.6929 - mse: 1.2257 - val_loss: 1.9124 - val_mae: 0.9092 - val_mse: 1.9124\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.78309\n",
      "Epoch 88/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.2077 - mae: 0.6859 - mse: 1.2077 - val_loss: 1.9168 - val_mae: 0.8950 - val_mse: 1.9168\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.78309\n",
      "Epoch 89/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.2082 - mae: 0.6849 - mse: 1.2082 - val_loss: 1.9204 - val_mae: 0.8913 - val_mse: 1.9204\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.78309\n",
      "Epoch 90/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.2192 - mae: 0.6916 - mse: 1.2192 - val_loss: 1.9076 - val_mae: 0.8824 - val_mse: 1.9076\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.78309\n",
      "Epoch 91/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.1902 - mae: 0.6778 - mse: 1.1902 - val_loss: 1.8943 - val_mae: 0.8933 - val_mse: 1.8943\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.78309\n",
      "Epoch 92/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.1919 - mae: 0.6786 - mse: 1.1919 - val_loss: 1.9387 - val_mae: 0.8997 - val_mse: 1.9387\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.78309\n",
      "Epoch 93/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.1863 - mae: 0.6764 - mse: 1.1863 - val_loss: 1.9002 - val_mae: 0.8982 - val_mse: 1.9002\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.78309\n",
      "Epoch 94/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.1750 - mae: 0.6736 - mse: 1.1750 - val_loss: 1.9085 - val_mae: 0.8865 - val_mse: 1.9085\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.78309\n",
      "Epoch 95/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.1939 - mae: 0.6792 - mse: 1.1939 - val_loss: 1.9333 - val_mae: 0.8944 - val_mse: 1.9333\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.78309\n",
      "Epoch 96/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.1705 - mae: 0.6706 - mse: 1.1705 - val_loss: 1.9213 - val_mae: 0.9049 - val_mse: 1.9213\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1.78309\n",
      "Epoch 97/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.1667 - mae: 0.6676 - mse: 1.1667 - val_loss: 1.9794 - val_mae: 0.9334 - val_mse: 1.9794\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.78309\n",
      "Epoch 98/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.1706 - mae: 0.6705 - mse: 1.1706 - val_loss: 1.9625 - val_mae: 0.9066 - val_mse: 1.9625\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.78309\n",
      "Epoch 99/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.1707 - mae: 0.6694 - mse: 1.1707 - val_loss: 1.9510 - val_mae: 0.8931 - val_mse: 1.9510\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.78309\n",
      "Epoch 100/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.1541 - mae: 0.6625 - mse: 1.1541 - val_loss: 1.9505 - val_mae: 0.8916 - val_mse: 1.9505\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.78309\n",
      "Epoch 101/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.1551 - mae: 0.6632 - mse: 1.1551 - val_loss: 1.9283 - val_mae: 0.9151 - val_mse: 1.9283\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1.78309\n",
      "Epoch 102/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.1532 - mae: 0.6646 - mse: 1.1532 - val_loss: 1.9441 - val_mae: 0.9128 - val_mse: 1.9441\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1.78309\n",
      "Epoch 103/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.1403 - mae: 0.6584 - mse: 1.1403 - val_loss: 1.9448 - val_mae: 0.9012 - val_mse: 1.9448\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1.78309\n",
      "Epoch 104/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.1413 - mae: 0.6589 - mse: 1.1413 - val_loss: 1.9935 - val_mae: 0.9072 - val_mse: 1.9935\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1.78309\n",
      "Epoch 105/500\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 1.1638 - mae: 0.6659 - mse: 1.1638 - val_loss: 1.9378 - val_mae: 0.9155 - val_mse: 1.9378\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1.78309\n",
      "Epoch 106/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.1619 - mae: 0.6706 - mse: 1.1619 - val_loss: 1.9433 - val_mae: 0.9150 - val_mse: 1.9433\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1.78309\n",
      "Epoch 107/500\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 1.1754 - mae: 0.6679 - mse: 1.1754 - val_loss: 1.9253 - val_mae: 0.8899 - val_mse: 1.9253\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1.78309\n",
      "Epoch 108/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.1774 - mae: 0.6751 - mse: 1.1774 - val_loss: 1.9507 - val_mae: 0.8965 - val_mse: 1.9507\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1.78309\n",
      "Epoch 109/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.4245 - mae: 0.7118 - mse: 1.4245 - val_loss: 1.9812 - val_mae: 0.9152 - val_mse: 1.9812\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1.78309\n",
      "Epoch 110/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.3492 - mae: 0.7263 - mse: 1.3492 - val_loss: 1.9478 - val_mae: 0.9014 - val_mse: 1.9478\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1.78309\n",
      "Epoch 111/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.4572 - mae: 0.7115 - mse: 1.4572 - val_loss: 1.9678 - val_mae: 0.8996 - val_mse: 1.9678\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1.78309\n",
      "Epoch 112/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.2114 - mae: 0.6883 - mse: 1.2114 - val_loss: 1.9365 - val_mae: 0.8936 - val_mse: 1.9365\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1.78309\n",
      "Epoch 113/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.4404 - mae: 0.6977 - mse: 1.4404 - val_loss: 1.9340 - val_mae: 0.9067 - val_mse: 1.9340\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1.78309\n",
      "Epoch 114/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.7746 - mae: 0.7208 - mse: 1.7746 - val_loss: 1.8958 - val_mae: 0.9397 - val_mse: 1.8958\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1.78309\n",
      "Epoch 115/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.5539 - mae: 0.7788 - mse: 1.5539 - val_loss: 2.0020 - val_mae: 0.9656 - val_mse: 2.0020\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1.78309\n",
      "Epoch 116/500\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2.9616 - mae: 0.8209 - mse: 2.9616 - val_loss: 1.9003 - val_mae: 0.9154 - val_mse: 1.9003\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1.78309\n",
      "Epoch 117/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.4954 - mae: 0.7630 - mse: 1.4954 - val_loss: 1.9199 - val_mae: 0.9136 - val_mse: 1.9199\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1.78309\n",
      "Epoch 118/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 4.5097 - mae: 0.8062 - mse: 4.5097 - val_loss: 1.9433 - val_mae: 0.9163 - val_mse: 1.9433\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1.78309\n",
      "Epoch 119/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.4000 - mae: 0.7382 - mse: 1.4000 - val_loss: 2.0725 - val_mae: 0.9748 - val_mse: 2.0725\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1.78309\n",
      "Epoch 120/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.3007 - mae: 0.7217 - mse: 1.3007 - val_loss: 2.4226 - val_mae: 1.1103 - val_mse: 2.4226\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1.78309\n",
      "Epoch 121/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.5218 - mae: 0.7344 - mse: 1.5218 - val_loss: 2.4280 - val_mae: 1.0683 - val_mse: 2.4280\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1.78309\n",
      "Epoch 122/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 2.0777 - mae: 0.7516 - mse: 2.0777 - val_loss: 2.0031 - val_mae: 0.9582 - val_mse: 2.0031\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1.78309\n",
      "Epoch 123/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.3929 - mae: 0.7446 - mse: 1.3929 - val_loss: 1.9607 - val_mae: 0.9137 - val_mse: 1.9607\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 1.78309\n",
      "Epoch 124/500\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 1.6777 - mae: 0.7372 - mse: 1.6777 - val_loss: 1.9657 - val_mae: 0.9120 - val_mse: 1.9657\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1.78309\n",
      "Epoch 125/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.8196 - mae: 0.7294 - mse: 1.8196 - val_loss: 1.9783 - val_mae: 0.9175 - val_mse: 1.9783\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 1.78309\n",
      "Epoch 126/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 2.2574 - mae: 0.7269 - mse: 2.2574 - val_loss: 1.9671 - val_mae: 0.9244 - val_mse: 1.9671\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1.78309\n",
      "Epoch 127/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.6759 - mae: 0.7146 - mse: 1.6759 - val_loss: 1.9530 - val_mae: 0.9113 - val_mse: 1.9530\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 1.78309\n",
      "Epoch 128/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.4705 - mae: 0.6926 - mse: 1.4705 - val_loss: 2.4869 - val_mae: 1.0747 - val_mse: 2.4869\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1.78309\n",
      "Epoch 129/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.5058 - mae: 0.7160 - mse: 1.5058 - val_loss: 1.9963 - val_mae: 0.9137 - val_mse: 1.9963\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1.78309\n",
      "Epoch 130/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.1852 - mae: 0.6811 - mse: 1.1852 - val_loss: 1.9502 - val_mae: 0.8989 - val_mse: 1.9502\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 1.78309\n",
      "Epoch 131/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.1528 - mae: 0.6718 - mse: 1.1528 - val_loss: 2.0232 - val_mae: 0.9313 - val_mse: 2.0232\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 1.78309\n",
      "Epoch 132/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.4483 - mae: 0.6812 - mse: 1.4483 - val_loss: 1.9685 - val_mae: 0.9011 - val_mse: 1.9685\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 1.78309\n",
      "Epoch 133/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.1675 - mae: 0.6762 - mse: 1.1675 - val_loss: 1.9465 - val_mae: 0.9076 - val_mse: 1.9465\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 1.78309\n",
      "Epoch 134/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.1688 - mae: 0.6703 - mse: 1.1688 - val_loss: 1.9872 - val_mae: 0.9229 - val_mse: 1.9872\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 1.78309\n",
      "Epoch 135/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.1431 - mae: 0.6576 - mse: 1.1431 - val_loss: 1.9882 - val_mae: 0.9257 - val_mse: 1.9882\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 1.78309\n",
      "Epoch 136/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.2300 - mae: 0.6688 - mse: 1.2300 - val_loss: 2.0282 - val_mae: 0.9225 - val_mse: 2.0282\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 1.78309\n",
      "Epoch 137/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.1934 - mae: 0.6637 - mse: 1.1934 - val_loss: 1.9425 - val_mae: 0.8973 - val_mse: 1.9425\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 1.78309\n",
      "Epoch 138/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.1113 - mae: 0.6493 - mse: 1.1113 - val_loss: 1.9994 - val_mae: 0.9175 - val_mse: 1.9994\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 1.78309\n",
      "Epoch 139/500\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 1.1166 - mae: 0.6513 - mse: 1.1166 - val_loss: 1.9574 - val_mae: 0.8977 - val_mse: 1.9574\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 1.78309\n",
      "Epoch 140/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.0940 - mae: 0.6438 - mse: 1.0940 - val_loss: 2.0310 - val_mae: 0.9314 - val_mse: 2.0310\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 1.78309\n",
      "Epoch 141/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.0932 - mae: 0.6433 - mse: 1.0932 - val_loss: 1.9778 - val_mae: 0.9036 - val_mse: 1.9778\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 1.78309\n",
      "Epoch 142/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.0859 - mae: 0.6406 - mse: 1.0859 - val_loss: 2.0489 - val_mae: 0.9180 - val_mse: 2.0489\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 1.78309\n",
      "Epoch 143/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.0764 - mae: 0.6363 - mse: 1.0764 - val_loss: 2.0166 - val_mae: 0.9108 - val_mse: 2.0166\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 1.78309\n",
      "Epoch 144/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.0842 - mae: 0.6380 - mse: 1.0842 - val_loss: 2.0474 - val_mae: 0.9203 - val_mse: 2.0474\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 1.78309\n",
      "Epoch 145/500\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 1.0666 - mae: 0.6332 - mse: 1.0666 - val_loss: 1.9974 - val_mae: 0.9119 - val_mse: 1.9974\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 1.78309\n",
      "Epoch 146/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.0727 - mae: 0.6337 - mse: 1.0727 - val_loss: 1.9560 - val_mae: 0.9052 - val_mse: 1.9560\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 1.78309\n",
      "Epoch 147/500\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 1.0673 - mae: 0.6305 - mse: 1.0673 - val_loss: 1.9990 - val_mae: 0.9064 - val_mse: 1.9990\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 1.78309\n",
      "Epoch 148/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.0616 - mae: 0.6290 - mse: 1.0616 - val_loss: 1.9610 - val_mae: 0.9021 - val_mse: 1.9610\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 1.78309\n",
      "Epoch 149/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.0967 - mae: 0.6355 - mse: 1.0967 - val_loss: 1.9797 - val_mae: 0.9050 - val_mse: 1.9797\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 1.78309\n",
      "Epoch 150/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.0664 - mae: 0.6301 - mse: 1.0664 - val_loss: 1.9782 - val_mae: 0.9021 - val_mse: 1.9782\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 1.78309\n",
      "Epoch 151/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.0642 - mae: 0.6287 - mse: 1.0642 - val_loss: 1.9992 - val_mae: 0.9097 - val_mse: 1.9992\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 1.78309\n",
      "Epoch 152/500\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 1.0481 - mae: 0.6252 - mse: 1.0481 - val_loss: 1.9629 - val_mae: 0.8919 - val_mse: 1.9629\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 1.78309\n",
      "Epoch 153/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.0382 - mae: 0.6201 - mse: 1.0382 - val_loss: 2.0555 - val_mae: 0.9342 - val_mse: 2.0555\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 1.78309\n",
      "Epoch 154/500\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 1.0303 - mae: 0.6170 - mse: 1.0303 - val_loss: 2.1047 - val_mae: 0.9458 - val_mse: 2.1047\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 1.78309\n",
      "Epoch 155/500\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 1.0152 - mae: 0.6107 - mse: 1.0152 - val_loss: 1.9913 - val_mae: 0.9038 - val_mse: 1.9913\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 1.78309\n",
      "Epoch 156/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.0333 - mae: 0.6174 - mse: 1.0333 - val_loss: 1.9774 - val_mae: 0.8987 - val_mse: 1.9774\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 1.78309\n",
      "Epoch 157/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.0356 - mae: 0.6180 - mse: 1.0356 - val_loss: 2.0152 - val_mae: 0.9074 - val_mse: 2.0152\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 1.78309\n",
      "Epoch 158/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.0177 - mae: 0.6118 - mse: 1.0177 - val_loss: 2.0050 - val_mae: 0.9101 - val_mse: 2.0050\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 1.78309\n",
      "Epoch 159/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.0101 - mae: 0.6074 - mse: 1.0101 - val_loss: 1.9996 - val_mae: 0.9092 - val_mse: 1.9996\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 1.78309\n",
      "Epoch 160/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.0116 - mae: 0.6079 - mse: 1.0116 - val_loss: 2.0478 - val_mae: 0.9045 - val_mse: 2.0478\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 1.78309\n",
      "Epoch 161/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.0047 - mae: 0.6059 - mse: 1.0047 - val_loss: 2.0585 - val_mae: 0.9264 - val_mse: 2.0585\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 1.78309\n",
      "Epoch 162/500\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 1.0059 - mae: 0.6063 - mse: 1.0059 - val_loss: 2.0404 - val_mae: 0.9072 - val_mse: 2.0404\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 1.78309\n",
      "Epoch 163/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.9981 - mae: 0.6030 - mse: 0.9981 - val_loss: 2.0376 - val_mae: 0.9027 - val_mse: 2.0376\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 1.78309\n",
      "Epoch 164/500\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 1.0071 - mae: 0.6074 - mse: 1.0071 - val_loss: 2.0570 - val_mae: 0.9157 - val_mse: 2.0570\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 1.78309\n",
      "Epoch 165/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.0171 - mae: 0.6103 - mse: 1.0171 - val_loss: 2.0854 - val_mae: 0.9402 - val_mse: 2.0854\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 1.78309\n",
      "Epoch 166/500\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.9987 - mae: 0.6034 - mse: 0.9987 - val_loss: 2.0220 - val_mae: 0.9077 - val_mse: 2.0220\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 1.78309\n",
      "Epoch 167/500\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.9855 - mae: 0.5985 - mse: 0.9855 - val_loss: 2.0906 - val_mae: 0.9253 - val_mse: 2.0906\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 1.78309\n",
      "Epoch 168/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.9957 - mae: 0.6007 - mse: 0.9957 - val_loss: 2.0809 - val_mae: 0.9336 - val_mse: 2.0809\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 1.78309\n",
      "Epoch 169/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.9837 - mae: 0.5970 - mse: 0.9837 - val_loss: 2.0802 - val_mae: 0.9220 - val_mse: 2.0802\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 1.78309\n",
      "Epoch 170/500\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.9749 - mae: 0.5939 - mse: 0.9749 - val_loss: 2.0310 - val_mae: 0.9172 - val_mse: 2.0310\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 1.78309\n",
      "Epoch 171/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.9797 - mae: 0.5941 - mse: 0.9797 - val_loss: 2.0765 - val_mae: 0.9225 - val_mse: 2.0765\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 1.78309\n",
      "Epoch 172/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.9714 - mae: 0.5917 - mse: 0.9714 - val_loss: 2.0427 - val_mae: 0.9108 - val_mse: 2.0427\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 1.78309\n",
      "Epoch 173/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.9760 - mae: 0.5928 - mse: 0.9760 - val_loss: 2.0112 - val_mae: 0.9071 - val_mse: 2.0112\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 1.78309\n",
      "Epoch 174/500\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.9786 - mae: 0.5946 - mse: 0.9786 - val_loss: 2.0838 - val_mae: 0.9359 - val_mse: 2.0838\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 1.78309\n",
      "Epoch 175/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.9582 - mae: 0.5857 - mse: 0.9582 - val_loss: 2.0547 - val_mae: 0.9098 - val_mse: 2.0547\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 1.78309\n",
      "Epoch 176/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.9492 - mae: 0.5832 - mse: 0.9492 - val_loss: 2.0806 - val_mae: 0.9241 - val_mse: 2.0806\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 1.78309\n",
      "Epoch 177/500\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.9663 - mae: 0.5873 - mse: 0.9663 - val_loss: 2.0429 - val_mae: 0.9083 - val_mse: 2.0429\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 1.78309\n",
      "Epoch 178/500\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.9576 - mae: 0.5851 - mse: 0.9576 - val_loss: 2.0285 - val_mae: 0.9001 - val_mse: 2.0285\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 1.78309\n",
      "Epoch 179/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.9496 - mae: 0.5815 - mse: 0.9496 - val_loss: 2.0840 - val_mae: 0.9377 - val_mse: 2.0840\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 1.78309\n",
      "Epoch 180/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.9416 - mae: 0.5785 - mse: 0.9416 - val_loss: 2.0652 - val_mae: 0.9167 - val_mse: 2.0652\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 1.78309\n",
      "Epoch 181/500\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.9498 - mae: 0.5824 - mse: 0.9498 - val_loss: 2.1022 - val_mae: 0.9278 - val_mse: 2.1022\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 1.78309\n",
      "Epoch 182/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.9371 - mae: 0.5783 - mse: 0.9371 - val_loss: 2.0754 - val_mae: 0.9233 - val_mse: 2.0754\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 1.78309\n",
      "Epoch 183/500\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.9513 - mae: 0.5840 - mse: 0.9513 - val_loss: 2.0535 - val_mae: 0.9050 - val_mse: 2.0535\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 1.78309\n",
      "Epoch 184/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.9423 - mae: 0.5784 - mse: 0.9423 - val_loss: 2.0847 - val_mae: 0.9295 - val_mse: 2.0847\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 1.78309\n",
      "Epoch 185/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.9424 - mae: 0.5796 - mse: 0.9424 - val_loss: 2.1571 - val_mae: 0.9465 - val_mse: 2.1571\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 1.78309\n",
      "Epoch 186/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.9285 - mae: 0.5730 - mse: 0.9285 - val_loss: 2.1319 - val_mae: 0.9224 - val_mse: 2.1319\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 1.78309\n",
      "Epoch 187/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.9297 - mae: 0.5730 - mse: 0.9297 - val_loss: 2.0929 - val_mae: 0.9253 - val_mse: 2.0929\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 1.78309\n",
      "Epoch 188/500\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.9256 - mae: 0.5712 - mse: 0.9256 - val_loss: 2.1118 - val_mae: 0.9299 - val_mse: 2.1118\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 1.78309\n"
     ]
    }
   ],
   "source": [
    "chkpoint = tf.keras.callbacks.ModelCheckpoint('dnn_regressor_pfnd.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=150, verbose=0, restore_best_weights=True)\n",
    "history_baseline_all = regressor_All.fit(X_train, \n",
    "                                         y_train,\n",
    "                                         validation_split = 0.1,\n",
    "                                         callbacks=[chkpoint, earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.plot(history_baseline_all.history['val_loss'], label=\"Validation\")\n",
    "plt.plot(history_baseline_all.history['loss'], label=\"Training\")\n",
    "plt.yscale('log')\n",
    "plt.ylim(.001,10)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.xlim(0,200)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.xlabel('Epochs', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "plt.legend(loc='upper right', ncol=1)\n",
    "plt.text(200, 1.5, 'LR=1e-3', fontsize=13)\n",
    "plt.text(200, 1, 'Batch: 509', fontsize=13)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('Regression_Plots/July/XY_STSC_lossCurves_3000batch_LR1e-2_2021-07-016.png', format='png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'regressor_All' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_32332/946028253.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m           \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m           \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregressor_All\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_scal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'regressor_All' is not defined"
     ]
    }
   ],
   "source": [
    "def eval_generator(data, batch_size):\n",
    "     batches = (len(data) + batch_size - 1)//batch_size\n",
    "     for i in range(batches):\n",
    "          X = data[i*batch_size : (i+1)*batch_size]\n",
    "          yield (X)\n",
    "pred = regressor_All.predict(eval_generator(X_scal,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_pred = np.exp(pred).reshape(-1)\n",
    "y_plot = np.exp(Ylog).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 631.8483  ,   17.684353,   11.75669 , ...,   10.472796,\n",
       "        613.1755  , 1051.1642  ], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([670.32836914,   3.67780995,   4.88845158, ..., 433.81128514,\n",
       "       602.20581055, 626.68877983])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 799.992x599.976 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 799.992x599.976 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resid_DNN = dnn_pred-y_plot\n",
    "resid_MDN_mask = np.logical_and(resid_DNN < 2000, resid_DNN > -2000)\n",
    "\n",
    "n_bins = 500\n",
    "plt.cla(); plt.clf()\n",
    "fig = plt.figure()\n",
    "fig.patch.set_facecolor('white')\n",
    "plt.hist(resid_DNN,bins = n_bins,alpha=0.75)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Learned - True Energy')\n",
    "plt.ylabel('Clusters')\n",
    "plt.xlim(-3000,3000)\n",
    "plt.legend()\n",
    "\n",
    "atlas_x = 0.55\n",
    "atlas_y = 0.95\n",
    "simulation = True\n",
    "textlist = [{'x': 0.55, 'y': 0.85, 'text': 'Single $\\pi^{+}$, All Clusters'},\n",
    "            {'x': 0.55, 'y': 0.8,  'text': 'DNN'}]\n",
    "pu.drawLabels(fig, atlas_x, atlas_y, simulation, textlist)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 799.992x599.976 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 799.992x599.976 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xcenter, medDNN = ru.responsePlot( (y_plot), (dnn_pred/y_plot),  \n",
    "                 plotpath+'hist_2D_calib_vs_ratioReg_E1T0_pp_profile.pdf',\n",
    "                 'median',\n",
    "                 atlas_x = 0.46, atlas_y = 0.95, simulation = True,\n",
    "                 textlist = [{'x': 0.46, 'y': 0.85, 'text': 'Single $\\pi^{+}$, All Clusters'},\n",
    "                             {'x': 0.46, 'y': 0.8,  'text': 'DNN'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcenter, iqrMDN3 = resolutionPlot(x=y_plot, y=pred/y_plot,\n",
    "                        atlas_x = 0.56, atlas_y = 0.95, simulation = True,\n",
    "                        textlist = [{'x': 0.56, 'y': 0.85, 'text': 'Single $\\pi^{+}$, All Clusters'},\n",
    "                                    {'x': 0.56, 'y': 0.8,  'text': 'PFN'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogramSlices(y_plot, dnn_pred,\n",
    "                atlas_x = 0.55, atlas_y = 0.85, simulation = True,\n",
    "                textlist = [{'x': 0.55, 'y': 0.75, 'text': 'Single $\\pi^{+}$'},\n",
    "                            {'x': 0.55, 'y': 0.7, 'text': ''},\n",
    "                            {'x': 0.55, 'y': 0.65,  'text': 'DNN'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xcenter, iqrDNN = resolutionPlot(pp[pp.test].cluster_ENG_CALIB_TOT, \n",
    "                        pp[pp.test].predict_regressor_DNN_EoverCalib,\n",
    "                        ylim=(0,0.75),\n",
    "                        atlas_x = 0.56, atlas_y = 0.95, simulation = True,\n",
    "                        textlist = [{'x': 0.56, 'y': 0.85, 'text': 'Single $\\pi^{+}$, All Clusters'},\n",
    "                                    {'x': 0.56, 'y': 0.8,  'text': 'DNN'}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tensor(X):\n",
    "    return tf.concat([tfp.distributions.Distribution.mean(X), tfp.distributions.Distribution.stddev(X)],1)\n",
    "\n",
    "def MDN():\n",
    "    event_shape = [1]\n",
    "    num_components = 4\n",
    "    params_size = tfp.layers.MixtureNormal.params_size(num_components, event_shape)\n",
    "    number_pixels = 512 + 256 + 128 + 16 + 16 +8\n",
    "    with strategy.scope():    \n",
    "        model = Sequential()\n",
    "        features = number_pixels + 2\n",
    "        model.add(Dense(features, input_dim=features, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(features, activation='relu'))\n",
    "        model.add(Dense(int(features/2), activation='relu'))\n",
    "        # model.add(Dense(units=params_size, activation=lambda x: tf.clip_by_value(x, -30., 30.)))\n",
    "        \n",
    "        model.add(tfp.layers.MixtureNormal(num_components, event_shape, convert_to_tensor_fn=convert_to_tensor))\n",
    "        model.add(tfp.layers.MixtureNormal(num_components, event_shape, validate_args=True,\n",
    "                                          convert_to_tensor_fn=convert_to_tensor))\n",
    "\n",
    "        opt = Adam(learning_rate=1e-3)#, decay=1e-6)\n",
    "\n",
    "        model.compile(optimizer=opt, loss=\"mse\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`mixture_distribution` components (2) does not equal `components_distribution.batch_shape[-1]` (4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_32332/3348684908.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mkb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mregressor_All\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKerasRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMDN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMDN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_32332/1175379052.py\u001b[0m in \u001b[0;36mMDN\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMixtureNormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_components\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_to_tensor_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         model.add(tfp.layers.MixtureNormal(num_components, event_shape, validate_args=True,\n\u001b[0m\u001b[0;32m     19\u001b[0m                                           convert_to_tensor_fn=convert_to_tensor))\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    215\u001b[0m       \u001b[1;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m       \u001b[1;31m# refresh its output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m       \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_probability\\python\\layers\\distribution_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_enter_dunder_call\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m     distribution, _ = super(DistributionLambda, self).__call__(\n\u001b[0m\u001b[0;32m    225\u001b[0m         inputs, *args, **kwargs)\n\u001b[0;32m    226\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_enter_dunder_call\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    974\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    977\u001b[0m                                                 input_list)\n\u001b[0;32m    978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1112\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[0;32m   1113\u001b[0m       \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[0;32m   1115\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[0;32m   1116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    846\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    886\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m           \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 888\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    889\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    334\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Allowlisted %s: from cache'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_probability\\python\\layers\\distribution_layer.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m     distribution, value = super(DistributionLambda, self).call(\n\u001b[0m\u001b[0;32m    231\u001b[0m         inputs, *args, **kwargs)\n\u001b[0;32m    232\u001b[0m     \u001b[1;31m# We always save the most recently built distribution variables for tracking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training)\u001b[0m\n\u001b[0;32m    901\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwatch_accessed_variables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_variable_creator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 903\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    904\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreated_variables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwatched_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    905\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_probability\\python\\layers\\distribution_layer.py\u001b[0m in \u001b[0;36m_fn\u001b[1;34m(*fargs, **fkwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m       \u001b[1;34m\"\"\"Wraps `make_distribution_fn` to return both dist and concrete value.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m       \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_distribution_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m       \u001b[0mvalue_is_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m       maybe_composite_convert_to_tensor_fn = (\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_probability\\python\\layers\\distribution_layer.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1588\u001b[0m     super(MixtureNormal, self).__init__(\n\u001b[1;32m-> 1589\u001b[1;33m         lambda t: MixtureNormal.new(  # pylint: disable=g-long-lambda\n\u001b[0m\u001b[0;32m   1590\u001b[0m             t, num_components, event_shape, validate_args),\n\u001b[0;32m   1591\u001b[0m         \u001b[0mconvert_to_tensor_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_probability\\python\\layers\\distribution_layer.py\u001b[0m in \u001b[0;36mnew\u001b[1;34m(params, num_components, event_shape, validate_args, name)\u001b[0m\n\u001b[0;32m   1602\u001b[0m     \u001b[1;34m\"\"\"Create the distribution instance from a `params` vector.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1603\u001b[0m     \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'params'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1604\u001b[1;33m     return MixtureSameFamily.new(\n\u001b[0m\u001b[0;32m   1605\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1606\u001b[0m         \u001b[0mnum_components\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_probability\\python\\layers\\distribution_layer.py\u001b[0m in \u001b[0;36mnew\u001b[1;34m(params, num_components, component_layer, validate_args, name)\u001b[0m\n\u001b[0;32m   1478\u001b[0m       mixture_dist = categorical_lib.Categorical(\n\u001b[0;32m   1479\u001b[0m           logits=params[..., :num_components])\n\u001b[1;32m-> 1480\u001b[1;33m       return mixture_same_family_lib.MixtureSameFamily(\n\u001b[0m\u001b[0;32m   1481\u001b[0m           \u001b[0mmixture_dist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1482\u001b[0m           \u001b[0mcomponents_dist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\decorator.py\u001b[0m in \u001b[0;36mfun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\distribution.py\u001b[0m in \u001b[0;36mwrapped_init\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    343\u001b[0m       \u001b[1;31m# called, here is the place to do it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m       \u001b[0mself_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m       \u001b[0mdefault_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m       \u001b[1;31m# Note: if we ever want to override things set in `self` by subclass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m       \u001b[1;31m# `__init__`, here is the place to do it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\mixture_same_family.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, mixture_distribution, components_distribution, reparameterize, validate_args, allow_nan_stats, name)\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[0mreparameterization_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreparameterization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNOT_REPARAMETERIZED\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m       super(MixtureSameFamily, self).__init__(\n\u001b[0m\u001b[0;32m    191\u001b[0m           \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_components_distribution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m           \u001b[0mreparameterization_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreparameterization_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dtype, reparameterization_type, validate_args, allow_nan_stats, parameters, graph_parents, name)\u001b[0m\n\u001b[0;32m    631\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_defer_all_assertions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m       self._initial_parameter_control_dependencies = tuple(\n\u001b[1;32m--> 633\u001b[1;33m           \u001b[0md\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parameter_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    634\u001b[0m           if d is not None)\n\u001b[0;32m    635\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\mixture_same_family.py\u001b[0m in \u001b[0;36m_parameter_control_dependencies\u001b[1;34m(self, is_init)\u001b[0m\n\u001b[0;32m    681\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkm\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mkc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mkm\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mkc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 683\u001b[1;33m         raise ValueError('`mixture_distribution` components ({}) does not '\n\u001b[0m\u001b[0;32m    684\u001b[0m                          \u001b[1;34m'equal `components_distribution.batch_shape[-1]` '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m                          '({})'.format(km, kc))\n",
      "\u001b[1;31mValueError\u001b[0m: `mixture_distribution` components (2) does not equal `components_distribution.batch_shape[-1]` (4)"
     ]
    }
   ],
   "source": [
    "import keras.backend as kb\n",
    "\n",
    "kb.clear_session()\n",
    "regressor_All = KerasRegressor(build_fn=MDN, batch_size=2500, epochs=1000, verbose=1)\n",
    "print(MDN().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "167/167 [==============================] - 6s 20ms/step - loss: 42.5635 - val_loss: 9.0021\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 9.00209, saving model to mdn_regressor_1.h5\n",
      "Epoch 2/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 8.6214 - val_loss: 9.3575\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 9.00209\n",
      "Epoch 3/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 8.1627 - val_loss: 6.7020\n",
      "\n",
      "Epoch 00003: val_loss improved from 9.00209 to 6.70202, saving model to mdn_regressor_1.h5\n",
      "Epoch 4/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 7.7670 - val_loss: 5.6268\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.70202 to 5.62684, saving model to mdn_regressor_1.h5\n",
      "Epoch 5/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 3.8801 - val_loss: 1.8962\n",
      "\n",
      "Epoch 00005: val_loss improved from 5.62684 to 1.89624, saving model to mdn_regressor_1.h5\n",
      "Epoch 6/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.8387 - val_loss: 1.8353\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.89624 to 1.83529, saving model to mdn_regressor_1.h5\n",
      "Epoch 7/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.7673 - val_loss: 1.8226\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.83529 to 1.82261, saving model to mdn_regressor_1.h5\n",
      "Epoch 8/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.7308 - val_loss: 1.7601\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.82261 to 1.76007, saving model to mdn_regressor_1.h5\n",
      "Epoch 9/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.7068 - val_loss: 1.7475\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.76007 to 1.74749, saving model to mdn_regressor_1.h5\n",
      "Epoch 10/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6913 - val_loss: 1.7482\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.74749\n",
      "Epoch 11/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.6735 - val_loss: 1.7388\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.74749 to 1.73879, saving model to mdn_regressor_1.h5\n",
      "Epoch 12/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.6589 - val_loss: 1.7069\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.73879 to 1.70688, saving model to mdn_regressor_1.h5\n",
      "Epoch 13/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.6491 - val_loss: 1.7187\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.70688\n",
      "Epoch 14/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6449 - val_loss: 1.6932\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.70688 to 1.69319, saving model to mdn_regressor_1.h5\n",
      "Epoch 15/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6507 - val_loss: 1.6878\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.69319 to 1.68780, saving model to mdn_regressor_1.h5\n",
      "Epoch 16/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6089 - val_loss: 1.7080\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.68780\n",
      "Epoch 17/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5952 - val_loss: 1.6874\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.68780 to 1.68741, saving model to mdn_regressor_1.h5\n",
      "Epoch 18/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5893 - val_loss: 1.6647\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.68741 to 1.66466, saving model to mdn_regressor_1.h5\n",
      "Epoch 19/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5790 - val_loss: 1.6662\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.66466\n",
      "Epoch 20/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5689 - val_loss: 1.6804\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.66466\n",
      "Epoch 21/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5574 - val_loss: 1.6739\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.66466\n",
      "Epoch 22/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5544 - val_loss: 1.6499\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.66466 to 1.64990, saving model to mdn_regressor_1.h5\n",
      "Epoch 23/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5422 - val_loss: 1.6447\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.64990 to 1.64473, saving model to mdn_regressor_1.h5\n",
      "Epoch 24/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5436 - val_loss: 1.6751\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.64473\n",
      "Epoch 25/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5344 - val_loss: 1.6771\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.64473\n",
      "Epoch 26/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5278 - val_loss: 1.6684\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.64473\n",
      "Epoch 27/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.5126 - val_loss: 1.6666\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.64473\n",
      "Epoch 28/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.9792 - val_loss: 2.5763\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.64473\n",
      "Epoch 29/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.8195 - val_loss: 1.6603\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.64473\n",
      "Epoch 30/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5148 - val_loss: 1.6543\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.64473\n",
      "Epoch 31/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5068 - val_loss: 1.6507\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.64473\n",
      "Epoch 32/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5009 - val_loss: 1.6955\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.64473\n",
      "Epoch 33/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4838 - val_loss: 1.6530\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.64473\n",
      "Epoch 34/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4747 - val_loss: 1.6457\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.64473\n",
      "Epoch 35/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4663 - val_loss: 1.6459\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.64473\n",
      "Epoch 36/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4735 - val_loss: 1.6473\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.64473\n",
      "Epoch 37/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4564 - val_loss: 1.6942\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.64473\n",
      "Epoch 38/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4505 - val_loss: 1.6581\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.64473\n",
      "Epoch 39/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4490 - val_loss: 1.6537\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.64473\n",
      "Epoch 40/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.4365 - val_loss: 1.6603\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.64473\n",
      "Epoch 41/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4312 - val_loss: 1.6507\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.64473\n",
      "Epoch 42/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4272 - val_loss: 1.6574\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.64473\n",
      "Epoch 43/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4170 - val_loss: 1.6512\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.64473\n",
      "Epoch 44/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4183 - val_loss: 1.6748\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.64473\n",
      "Epoch 45/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4086 - val_loss: 1.6953\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.64473\n",
      "Epoch 46/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4004 - val_loss: 1.6975\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.64473\n",
      "Epoch 47/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4012 - val_loss: 1.7521\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.64473\n",
      "Epoch 48/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4008 - val_loss: 1.6670\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.64473\n",
      "Epoch 49/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3873 - val_loss: 1.7025\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.64473\n",
      "Epoch 50/1000\n",
      "167/167 [==============================] - ETA: 0s - loss: 1.378 - 2s 10ms/step - loss: 1.3797 - val_loss: 1.6806\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.64473\n",
      "Epoch 51/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3686 - val_loss: 1.6852\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.64473\n",
      "Epoch 52/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3710 - val_loss: 1.6802\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.64473\n",
      "Epoch 53/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3579 - val_loss: 1.6713\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.64473\n",
      "Epoch 54/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3557 - val_loss: 1.6827\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.64473\n",
      "Epoch 55/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3475 - val_loss: 1.6933\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.64473\n",
      "Epoch 56/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3432 - val_loss: 1.6973\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.64473\n",
      "Epoch 57/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3329 - val_loss: 1.7089\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.64473\n",
      "Epoch 58/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3307 - val_loss: 1.7007\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.64473\n",
      "Epoch 59/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.3269 - val_loss: 1.7133\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.64473\n",
      "Epoch 60/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.3218 - val_loss: 1.6891\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.64473\n",
      "Epoch 61/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3142 - val_loss: 1.7127\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.64473\n",
      "Epoch 62/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3000 - val_loss: 1.7086\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.64473\n",
      "Epoch 63/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.3059 - val_loss: 1.7275\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.64473\n",
      "Epoch 64/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2896 - val_loss: 1.7240\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.64473\n",
      "Epoch 65/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2869 - val_loss: 1.7502\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.64473\n",
      "Epoch 66/1000\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 1.2810 - val_loss: 1.7826\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.64473\n",
      "Epoch 67/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.2778 - val_loss: 1.7116\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.64473\n",
      "Epoch 68/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.2736 - val_loss: 1.7325\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.64473\n",
      "Epoch 69/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2739 - val_loss: 1.7426\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.64473\n",
      "Epoch 70/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2488 - val_loss: 1.7620\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.64473\n",
      "Epoch 71/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2542 - val_loss: 1.7536\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.64473\n",
      "Epoch 72/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2501 - val_loss: 1.7273\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.64473\n",
      "Epoch 73/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2432 - val_loss: 1.7437\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.64473\n",
      "Epoch 74/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2380 - val_loss: 1.7823\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.64473\n",
      "Epoch 75/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2305 - val_loss: 1.7616\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.64473\n",
      "Epoch 76/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2262 - val_loss: 1.7690\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.64473\n",
      "Epoch 77/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2122 - val_loss: 1.7959\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.64473\n",
      "Epoch 78/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2104 - val_loss: 1.7694\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.64473\n",
      "Epoch 79/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.1993 - val_loss: 1.8160\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.64473\n",
      "Epoch 80/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.1988 - val_loss: 1.7875\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.64473\n",
      "Epoch 81/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.1881 - val_loss: 1.8376\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.64473\n",
      "Epoch 82/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.1881 - val_loss: 1.8265\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.64473\n",
      "Epoch 83/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.1831 - val_loss: 1.8464\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.64473\n",
      "Epoch 84/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.1778 - val_loss: 1.8091\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1.64473\n",
      "Epoch 85/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.1688 - val_loss: 1.8013\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.64473\n",
      "Epoch 86/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.1722 - val_loss: 1.8076\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.64473\n",
      "Epoch 87/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.1640 - val_loss: 1.7942\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.64473\n",
      "Epoch 88/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.1559 - val_loss: 1.7886\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.64473\n",
      "Epoch 89/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.1623 - val_loss: 1.7862\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.64473\n",
      "Epoch 90/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.1393 - val_loss: 1.8423\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.64473\n",
      "Epoch 91/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.1382 - val_loss: 1.8726\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.64473\n",
      "Epoch 92/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.1342 - val_loss: 1.8714\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.64473\n",
      "Epoch 93/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.1285 - val_loss: 1.8513\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.64473\n",
      "Epoch 94/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.1162 - val_loss: 1.8781\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.64473\n",
      "Epoch 95/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.1202 - val_loss: 1.8502\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.64473\n",
      "Epoch 96/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.1157 - val_loss: 1.8321\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1.64473\n",
      "Epoch 97/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.1019 - val_loss: 1.8849\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.64473\n",
      "Epoch 98/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.1014 - val_loss: 1.8711\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.64473\n",
      "Epoch 99/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.0917 - val_loss: 1.8498\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.64473\n",
      "Epoch 100/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.0857 - val_loss: 1.8652\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.64473\n",
      "Epoch 101/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.0902 - val_loss: 1.8768\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1.64473\n",
      "Epoch 102/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.0753 - val_loss: 1.8799\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1.64473\n",
      "Epoch 103/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.0775 - val_loss: 1.8997\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1.64473\n",
      "Epoch 104/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.0702 - val_loss: 1.9291\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1.64473\n",
      "Epoch 105/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.0696 - val_loss: 1.8892\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1.64473\n",
      "Epoch 106/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.0506 - val_loss: 1.8540\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1.64473\n",
      "Epoch 107/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.0534 - val_loss: 1.8760\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1.64473\n",
      "Epoch 108/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.0539 - val_loss: 1.9350\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1.64473\n",
      "Epoch 109/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.0441 - val_loss: 1.9189\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1.64473\n",
      "Epoch 110/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.0387 - val_loss: 1.9402\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1.64473\n",
      "Epoch 111/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.0346 - val_loss: 1.9068\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1.64473\n",
      "Epoch 112/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.0279 - val_loss: 1.9060\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1.64473\n",
      "Epoch 113/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.0206 - val_loss: 1.9642\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1.64473\n",
      "Epoch 114/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.0209 - val_loss: 1.9217\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1.64473\n",
      "Epoch 115/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.0112 - val_loss: 1.9623\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1.64473\n",
      "Epoch 116/1000\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 1.0045 - val_loss: 1.9166\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1.64473\n",
      "Epoch 117/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.0002 - val_loss: 1.9195\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1.64473\n",
      "Epoch 118/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.0064 - val_loss: 1.9178\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1.64473\n",
      "Epoch 119/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.9858 - val_loss: 1.9358\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1.64473\n",
      "Epoch 120/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.9903 - val_loss: 1.9375\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1.64473\n",
      "Epoch 121/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.9806 - val_loss: 1.9881\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1.64473\n",
      "Epoch 122/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.9999 - val_loss: 1.9685\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1.64473\n",
      "Epoch 123/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.9727 - val_loss: 1.9374\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 1.64473\n"
     ]
    }
   ],
   "source": [
    "chkpoint = tf.keras.callbacks.ModelCheckpoint('mdn_regressor_1.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=100, verbose=0, restore_best_weights=True)\n",
    "history_mdn = regressor_All.fit(X_train, \n",
    "                                y_train,\n",
    "                                validation_split=0.1,\n",
    "                                callbacks=[chkpoint, earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown activation function: <lambda>. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_32332/1893620542.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmdn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mdn_regressor_1.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    198\u001b[0m         if (h5py is not None and\n\u001b[0;32m    199\u001b[0m             (isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[1;32m--> 200\u001b[1;33m           return hdf5_format.load_model_from_hdf5(filepath, custom_objects,\n\u001b[0m\u001b[0;32m    201\u001b[0m                                                   compile)\n\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    178\u001b[0m       \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m     model = model_config_lib.model_from_config(model_config,\n\u001b[0m\u001b[0;32m    181\u001b[0m                                                custom_objects=custom_objects)\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\saving\\model_config.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m     50\u001b[0m                     '`Sequential.from_config(config)`?')\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\layers\\serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m    206\u001b[0m   \"\"\"\n\u001b[0;32m    207\u001b[0m   \u001b[0mpopulate_deserializable_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m   return generic_utils.deserialize_keras_object(\n\u001b[0m\u001b[0;32m    209\u001b[0m       \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLOCAL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;34m'custom_objects'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marg_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m         deserialized_obj = cls.from_config(\n\u001b[0m\u001b[0;32m    675\u001b[0m             \u001b[0mcls_config\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m             custom_objects=dict(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mfrom_config\u001b[1;34m(cls, config, custom_objects)\u001b[0m\n\u001b[0;32m    430\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer_config\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayer_configs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m       layer = layer_module.deserialize(layer_config,\n\u001b[0m\u001b[0;32m    433\u001b[0m                                        custom_objects=custom_objects)\n\u001b[0;32m    434\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\layers\\serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m    206\u001b[0m   \"\"\"\n\u001b[0;32m    207\u001b[0m   \u001b[0mpopulate_deserializable_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m   return generic_utils.deserialize_keras_object(\n\u001b[0m\u001b[0;32m    209\u001b[0m       \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLOCAL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    679\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m           \u001b[0mdeserialized_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m       \u001b[1;31m# Then `cls` may be a function returning a class.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mfrom_config\u001b[1;34m(cls, config)\u001b[0m\n\u001b[0;32m    746\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m     \"\"\"\n\u001b[1;32m--> 748\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\layers\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m       raise ValueError(f'Received an invalid value for `units`, expected '\n\u001b[0;32m   1153\u001b[0m                        f'a positive integer, got {units}.')\n\u001b[1;32m-> 1154\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1155\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_initializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitializers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\activations.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(identifier)\u001b[0m\n\u001b[0;32m    594\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[0midentifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    597\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\activations.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(name, custom_objects)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[0mglobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m   return deserialize_keras_object(\n\u001b[0m\u001b[0;32m    556\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    702\u001b[0m       \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    705\u001b[0m             \u001b[1;34m'Unknown {}: {}. Please ensure this object is '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m             \u001b[1;34m'passed to the `custom_objects` argument. See '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown activation function: <lambda>. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
     ]
    }
   ],
   "source": [
    "mdn = tf.keras.models.load_model(\"mdn_regressor_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410/410 [==============================] - 2s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = regressor_All.predict(eval_generator(X_test,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdn_pred = np.exp(pred[:,0]).reshape(-1)\n",
    "y_plot = np.exp(y_test).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 39.59385  , 139.65034  ,  12.142118 , ...,  49.8313   ,\n",
       "        16.653246 ,   5.0155077], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdn_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 37.70606995, 114.45298767,  20.52076626, ...,  41.38512802,\n",
       "         1.24079919,   0.36038172])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp['predict_regressor_MDN'] = np.exp(scaler_cal.inverse_transform(pred[:,0].reshape(-1,1)))\n",
    "pp['predict_regressor_MDN_EoverCalib'] = pp.predict_regressor_MDN / pp.cluster_ENG_CALIB_TOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_MDN = pp.predict_regressor_MDN-pp.cluster_ENG_CALIB_TOT\n",
    "resid_MDN_mask = np.logical_and(resid_MDN < 2000, resid_MDN > -2000)\n",
    "\n",
    "n_bins = 500\n",
    "plt.cla(); plt.clf()\n",
    "fig = plt.figure()\n",
    "fig.patch.set_facecolor('white')\n",
    "plt.hist(resid_MDN[resid_MDN_mask],bins = n_bins, \n",
    "        #  label='Mean = {:.2f}, Std. Dev. = {:.2f}'.format(np.mean(resid_MDN[resid_MDN_mask]),\n",
    "        #                                                   np.std(resid_MDN[resid_MDN_mask]))\n",
    "         )\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Learned - True Energy')\n",
    "plt.xlim(-2000,2000)\n",
    "plt.legend()\n",
    "\n",
    "atlas_x = 0.55\n",
    "atlas_y = 0.95\n",
    "simulation = True\n",
    "textlist = [{'x': 0.55, 'y': 0.85, 'text': 'Single $\\pi^{+}$, All Clusters'},\n",
    "            {'x': 0.55, 'y': 0.8,  'text': 'MDN, 1 Component'}]\n",
    "pu.drawLabels(fig, atlas_x, atlas_y, simulation, textlist)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 799.992x599.976 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 799.992x599.976 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xcenter, medMDN = ru.responsePlot(y_plot, mdn_pred/y_plot,\n",
    "                 plotpath+'hist_2D_calib_vs_ratioReg_E1T0_pp_profile.pdf',\n",
    "                 'median',\n",
    "                 atlas_x = 0.46, atlas_y = 0.95, simulation = True,\n",
    "                 textlist = [{'x': 0.46, 'y': 0.85, 'text': 'Single $\\pi^{+}$, All Clusters'},\n",
    "                             {'x': 0.46, 'y': 0.8,  'text': 'MDN, 1 Component'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcenter, iqrMDN = resolutionPlot(pp[pp.test].cluster_ENG_CALIB_TOT,\n",
    "                        pp[pp.test].predict_regressor_MDN_EoverCalib,\n",
    "                        ylim=(0,0.75),\n",
    "                        atlas_x = 0.56, atlas_y = 0.95, simulation = True,\n",
    "                        textlist = [{'x': 0.56, 'y': 0.85, 'text': 'Single $\\pi^{+}$, All Clusters'},\n",
    "                                    {'x': 0.56, 'y': 0.8,  'text': 'MDN, 1 Components'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogramSlices(pp[pp.test].cluster_ENG_CALIB_TOT, pp[pp.test].predict_regressor_MDN_EoverCalib,\n",
    "                atlas_x = 0.55, atlas_y = 0.85, simulation = True,\n",
    "                textlist = [{'x': 0.55, 'y': 0.75, 'text': 'Single $\\pi^{+}$'},\n",
    "                            {'x': 0.55, 'y': 0.7, 'text': ''},\n",
    "                            {'x': 0.55, 'y': 0.65,  'text': 'MDN, 1 Component'}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MDN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MDN_3():\n",
    "    event_shape = [1]\n",
    "    num_components = 3\n",
    "    params_size = tfp.layers.MixtureNormal.params_size(num_components, event_shape)\n",
    "    number_pixels = 512 + 256 + 128 + 16 + 16 + 8\n",
    "    with strategy.scope():    \n",
    "        model = Sequential()\n",
    "        features = number_pixels + 2\n",
    "        model.add(Dense(features, input_dim=features, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(features, activation='relu'))\n",
    "        model.add(Dense(int(features/2), activation='relu'))\n",
    "        model.add(Dense(units=params_size, activation=lambda x: tf.clip_by_value(x, -30., 30.)))\n",
    "        \n",
    "        # model.add(tfp.layers.MixtureNormal(num_components, event_shape, convert_to_tensor_fn=convert_to_tensor))\n",
    "        model.add(tfp.layers.MixtureNormal(num_components, event_shape, validate_args=True,\n",
    "                                          convert_to_tensor_fn=convert_to_tensor))\n",
    "\n",
    "        opt = Adam(learning_rate=1e-4)#, decay=1e-6)\n",
    "        model.compile(optimizer=opt, loss=\"mse\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 938)               880782    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 938)               880782    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 469)               440391    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 9)                 4230      \n",
      "_________________________________________________________________\n",
      "mixture_normal_3 (MixtureNor multiple                  0         \n",
      "=================================================================\n",
      "Total params: 2,206,185\n",
      "Trainable params: 2,206,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "regressor_All = KerasRegressor(build_fn=MDN_3, batch_size=2500, epochs=1000, verbose=1)\n",
    "print(MDN_3().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "167/167 [==============================] - 7s 22ms/step - loss: 12.2881 - val_loss: 5.7846\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.78455, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 2/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 4.6681 - val_loss: 5.4778\n",
      "\n",
      "Epoch 00002: val_loss improved from 5.78455 to 5.47776, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 3/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 3.9405 - val_loss: 2.9635\n",
      "\n",
      "Epoch 00003: val_loss improved from 5.47776 to 2.96353, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 4/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 2.7890 - val_loss: 2.4205\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.96353 to 2.42055, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 5/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 3.3657 - val_loss: 2.5787\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.42055\n",
      "Epoch 6/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 2.7069 - val_loss: 2.2993\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.42055 to 2.29928, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 7/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 2.2832 - val_loss: 2.3343\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.29928\n",
      "Epoch 8/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 2.1953 - val_loss: 2.0046\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.29928 to 2.00461, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 9/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 3.6651 - val_loss: 2.0101\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.00461\n",
      "Epoch 10/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.9224 - val_loss: 1.9356\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.00461 to 1.93557, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 11/1000\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 1.9306 - val_loss: 1.9057\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.93557 to 1.90570, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 12/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 2.0471 - val_loss: 4.0336\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.90570\n",
      "Epoch 13/1000\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 1.9400 - val_loss: 1.8758\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.90570 to 1.87585, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 14/1000\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 1.9077 - val_loss: 2.1397\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.87585\n",
      "Epoch 15/1000\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 2.1075 - val_loss: 1.8543\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.87585 to 1.85426, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 16/1000\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 1.8728 - val_loss: 1.8545\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.85426\n",
      "Epoch 17/1000\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 1.8651 - val_loss: 1.8400\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.85426 to 1.83998, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 18/1000\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 2.0971 - val_loss: 1.8526\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.83998\n",
      "Epoch 19/1000\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 1.8498 - val_loss: 1.8346\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.83998 to 1.83465, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 20/1000\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 1.7873 - val_loss: 1.8235\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.83465 to 1.82354, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 21/1000\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 2.3900 - val_loss: 2.2399\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.82354\n",
      "Epoch 22/1000\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 1.8475 - val_loss: 1.8194\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.82354 to 1.81943, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 23/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.8567 - val_loss: 1.8534\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.81943\n",
      "Epoch 24/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.8135 - val_loss: 2.3105\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.81943\n",
      "Epoch 25/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.7998 - val_loss: 1.9444\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.81943\n",
      "Epoch 26/1000\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 1.8104 - val_loss: 1.8275\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.81943\n",
      "Epoch 27/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.8378 - val_loss: 1.8818\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.81943\n",
      "Epoch 28/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.7899 - val_loss: 1.8210\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.81943\n",
      "Epoch 29/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.7928 - val_loss: 1.8223\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.81943\n",
      "Epoch 30/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.8628 - val_loss: 1.9141\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.81943\n",
      "Epoch 31/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.7989 - val_loss: 1.7851\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.81943 to 1.78510, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 32/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.8073 - val_loss: 1.9572\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.78510\n",
      "Epoch 33/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.7602 - val_loss: 1.8267\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.78510\n",
      "Epoch 34/1000\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 1.7810 - val_loss: 1.7872\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.78510\n",
      "Epoch 35/1000\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 1.7480 - val_loss: 1.7860\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.78510\n",
      "Epoch 36/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.7950 - val_loss: 1.7716\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.78510 to 1.77157, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 37/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.7600 - val_loss: 1.7851\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.77157\n",
      "Epoch 38/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.7696 - val_loss: 1.8298\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.77157\n",
      "Epoch 39/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.7575 - val_loss: 1.7997\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.77157\n",
      "Epoch 40/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.7794 - val_loss: 1.7769\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.77157\n",
      "Epoch 41/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.7701 - val_loss: 1.8939\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.77157\n",
      "Epoch 42/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.7672 - val_loss: 1.7698\n",
      "\n",
      "Epoch 00042: val_loss improved from 1.77157 to 1.76982, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 43/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.7726 - val_loss: 1.7592\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.76982 to 1.75916, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 44/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6952 - val_loss: 1.8363\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.75916\n",
      "Epoch 45/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.7355 - val_loss: 1.8001\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.75916\n",
      "Epoch 46/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.8214 - val_loss: 2.1333\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.75916\n",
      "Epoch 47/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.7526 - val_loss: 1.7465\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.75916 to 1.74651, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 48/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6964 - val_loss: 1.7438\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.74651 to 1.74380, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 49/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.7031 - val_loss: 1.7636\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.74380\n",
      "Epoch 50/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6900 - val_loss: 1.8164\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.74380\n",
      "Epoch 51/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6943 - val_loss: 1.7554\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.74380\n",
      "Epoch 52/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.8081 - val_loss: 1.7380\n",
      "\n",
      "Epoch 00052: val_loss improved from 1.74380 to 1.73797, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 53/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6954 - val_loss: 1.7494\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.73797\n",
      "Epoch 54/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6660 - val_loss: 1.7381\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.73797\n",
      "Epoch 55/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6781 - val_loss: 1.7709\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.73797\n",
      "Epoch 56/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6726 - val_loss: 1.7424\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.73797\n",
      "Epoch 57/1000\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 1.7075 - val_loss: 1.8094\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.73797\n",
      "Epoch 58/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6766 - val_loss: 1.7295\n",
      "\n",
      "Epoch 00058: val_loss improved from 1.73797 to 1.72951, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 59/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6943 - val_loss: 1.7532\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.72951\n",
      "Epoch 60/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6789 - val_loss: 1.7914\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.72951\n",
      "Epoch 61/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6729 - val_loss: 1.8296\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.72951\n",
      "Epoch 62/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6680 - val_loss: 1.8531\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.72951\n",
      "Epoch 63/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.6833 - val_loss: 1.7324\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.72951\n",
      "Epoch 64/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6517 - val_loss: 1.7270\n",
      "\n",
      "Epoch 00064: val_loss improved from 1.72951 to 1.72703, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 65/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6608 - val_loss: 1.7175\n",
      "\n",
      "Epoch 00065: val_loss improved from 1.72703 to 1.71750, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 66/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6710 - val_loss: 1.7168\n",
      "\n",
      "Epoch 00066: val_loss improved from 1.71750 to 1.71683, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 67/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6843 - val_loss: 1.7258\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.71683\n",
      "Epoch 68/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6550 - val_loss: 1.7301\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.71683\n",
      "Epoch 69/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6380 - val_loss: 1.7179\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.71683\n",
      "Epoch 70/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6326 - val_loss: 1.7353\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.71683\n",
      "Epoch 71/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6526 - val_loss: 1.7242\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.71683\n",
      "Epoch 72/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6576 - val_loss: 1.7582\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.71683\n",
      "Epoch 73/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6583 - val_loss: 1.7197\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.71683\n",
      "Epoch 74/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6460 - val_loss: 1.8012\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.71683\n",
      "Epoch 75/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6235 - val_loss: 1.7242\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.71683\n",
      "Epoch 76/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6182 - val_loss: 1.7134\n",
      "\n",
      "Epoch 00076: val_loss improved from 1.71683 to 1.71337, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 77/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6260 - val_loss: 1.7095\n",
      "\n",
      "Epoch 00077: val_loss improved from 1.71337 to 1.70947, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 78/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6209 - val_loss: 1.7418\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.70947\n",
      "Epoch 79/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6202 - val_loss: 1.7223\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.70947\n",
      "Epoch 80/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6211 - val_loss: 1.7606\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.70947\n",
      "Epoch 81/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6097 - val_loss: 1.7198\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.70947\n",
      "Epoch 82/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6137 - val_loss: 1.7180\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.70947\n",
      "Epoch 83/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5966 - val_loss: 1.7385\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.70947\n",
      "Epoch 84/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6024 - val_loss: 1.7433\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1.70947\n",
      "Epoch 85/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6029 - val_loss: 1.7142\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.70947\n",
      "Epoch 86/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.6061 - val_loss: 1.7578\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.70947\n",
      "Epoch 87/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5917 - val_loss: 1.7296\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.70947\n",
      "Epoch 88/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5902 - val_loss: 1.7081\n",
      "\n",
      "Epoch 00088: val_loss improved from 1.70947 to 1.70814, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 89/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5919 - val_loss: 1.7487\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.70814\n",
      "Epoch 90/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5806 - val_loss: 1.7447\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.70814\n",
      "Epoch 91/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5920 - val_loss: 1.7287\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.70814\n",
      "Epoch 92/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5815 - val_loss: 1.7374\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.70814\n",
      "Epoch 93/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5778 - val_loss: 1.6970\n",
      "\n",
      "Epoch 00093: val_loss improved from 1.70814 to 1.69699, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 94/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5879 - val_loss: 1.7020\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.69699\n",
      "Epoch 95/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5866 - val_loss: 1.7078\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.69699\n",
      "Epoch 96/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5864 - val_loss: 1.7668\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1.69699\n",
      "Epoch 97/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5558 - val_loss: 1.7469\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.69699\n",
      "Epoch 98/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5691 - val_loss: 1.6894\n",
      "\n",
      "Epoch 00098: val_loss improved from 1.69699 to 1.68941, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 99/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.5918 - val_loss: 1.7487\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.68941\n",
      "Epoch 100/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.5717 - val_loss: 1.7459\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.68941\n",
      "Epoch 101/1000\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 1.5468 - val_loss: 1.7397\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1.68941\n",
      "Epoch 102/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5735 - val_loss: 1.6986\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1.68941\n",
      "Epoch 103/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5400 - val_loss: 1.7564\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1.68941\n",
      "Epoch 104/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5620 - val_loss: 1.7031\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1.68941\n",
      "Epoch 105/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5334 - val_loss: 1.6999\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1.68941\n",
      "Epoch 106/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5478 - val_loss: 1.6885\n",
      "\n",
      "Epoch 00106: val_loss improved from 1.68941 to 1.68850, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 107/1000\n",
      "167/167 [==============================] - ETA: 0s - loss: 1.552 - 2s 10ms/step - loss: 1.5512 - val_loss: 1.7132\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1.68850\n",
      "Epoch 108/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5346 - val_loss: 1.6905\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1.68850\n",
      "Epoch 109/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5324 - val_loss: 1.6942\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1.68850\n",
      "Epoch 110/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5645 - val_loss: 1.7986\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1.68850\n",
      "Epoch 111/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5449 - val_loss: 1.7613\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1.68850\n",
      "Epoch 112/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5363 - val_loss: 1.6927\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1.68850\n",
      "Epoch 113/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5256 - val_loss: 1.8032\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1.68850\n",
      "Epoch 114/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5213 - val_loss: 1.6948\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1.68850\n",
      "Epoch 115/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5297 - val_loss: 1.7175\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1.68850\n",
      "Epoch 116/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5189 - val_loss: 1.7181\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1.68850\n",
      "Epoch 117/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5219 - val_loss: 1.7144\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1.68850\n",
      "Epoch 118/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5159 - val_loss: 1.6922\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1.68850\n",
      "Epoch 119/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5358 - val_loss: 1.6882\n",
      "\n",
      "Epoch 00119: val_loss improved from 1.68850 to 1.68823, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 120/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5143 - val_loss: 1.7106\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1.68823\n",
      "Epoch 121/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5106 - val_loss: 1.7170\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1.68823\n",
      "Epoch 122/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.5161 - val_loss: 1.7007\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1.68823\n",
      "Epoch 123/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5078 - val_loss: 1.6870\n",
      "\n",
      "Epoch 00123: val_loss improved from 1.68823 to 1.68702, saving model to mdn3_regressor_pfnd.h5\n",
      "Epoch 124/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5018 - val_loss: 1.7041\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1.68702\n",
      "Epoch 125/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5058 - val_loss: 1.7109\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 1.68702\n",
      "Epoch 126/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5018 - val_loss: 1.6984\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1.68702\n",
      "Epoch 127/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5054 - val_loss: 1.7180\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 1.68702\n",
      "Epoch 128/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.5011 - val_loss: 1.7103\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1.68702\n",
      "Epoch 129/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4945 - val_loss: 1.7160\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1.68702\n",
      "Epoch 130/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.5069 - val_loss: 1.7094\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 1.68702\n",
      "Epoch 131/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4943 - val_loss: 1.7091\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 1.68702\n",
      "Epoch 132/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4894 - val_loss: 1.6988\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 1.68702\n",
      "Epoch 133/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4909 - val_loss: 1.7177\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 1.68702\n",
      "Epoch 134/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4936 - val_loss: 1.7421\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 1.68702\n",
      "Epoch 135/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4822 - val_loss: 1.8391\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 1.68702\n",
      "Epoch 136/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4809 - val_loss: 1.6921\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 1.68702\n",
      "Epoch 137/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4854 - val_loss: 1.7120\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 1.68702\n",
      "Epoch 138/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4744 - val_loss: 1.7186\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 1.68702\n",
      "Epoch 139/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4801 - val_loss: 1.7056\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 1.68702\n",
      "Epoch 140/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4709 - val_loss: 1.7177\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 1.68702\n",
      "Epoch 141/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.4759 - val_loss: 1.7182\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 1.68702\n",
      "Epoch 142/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4665 - val_loss: 1.7004\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 1.68702\n",
      "Epoch 143/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.4662 - val_loss: 1.7070\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 1.68702\n",
      "Epoch 144/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.4807 - val_loss: 1.6971\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 1.68702\n",
      "Epoch 145/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.4591 - val_loss: 1.7374\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 1.68702\n",
      "Epoch 146/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.4696 - val_loss: 1.6985\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 1.68702\n",
      "Epoch 147/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.4758 - val_loss: 1.7054\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 1.68702\n",
      "Epoch 148/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4626 - val_loss: 1.7025\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 1.68702\n",
      "Epoch 149/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.4553 - val_loss: 1.7191\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 1.68702\n",
      "Epoch 150/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4638 - val_loss: 1.7112\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 1.68702\n",
      "Epoch 151/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4639 - val_loss: 1.6871\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 1.68702\n",
      "Epoch 152/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4527 - val_loss: 1.6961\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 1.68702\n",
      "Epoch 153/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.4642 - val_loss: 1.7369\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 1.68702\n",
      "Epoch 154/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4433 - val_loss: 1.7172\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 1.68702\n",
      "Epoch 155/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4593 - val_loss: 1.7085\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 1.68702\n",
      "Epoch 156/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4482 - val_loss: 1.7125\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 1.68702\n",
      "Epoch 157/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4317 - val_loss: 1.7188\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 1.68702\n",
      "Epoch 158/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.4404 - val_loss: 1.7798\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 1.68702\n",
      "Epoch 159/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4403 - val_loss: 1.7253\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 1.68702\n",
      "Epoch 160/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4318 - val_loss: 1.7047\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 1.68702\n",
      "Epoch 161/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.4337 - val_loss: 1.6996\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 1.68702\n",
      "Epoch 162/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4285 - val_loss: 1.7754\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 1.68702\n",
      "Epoch 163/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4359 - val_loss: 1.7540\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 1.68702\n",
      "Epoch 164/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4297 - val_loss: 1.7102\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 1.68702\n",
      "Epoch 165/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4391 - val_loss: 1.6994\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 1.68702\n",
      "Epoch 166/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4375 - val_loss: 1.8316\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 1.68702\n",
      "Epoch 167/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.4464 - val_loss: 1.7596\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 1.68702\n",
      "Epoch 168/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4249 - val_loss: 1.7035\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 1.68702\n",
      "Epoch 169/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4240 - val_loss: 1.7042\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 1.68702\n",
      "Epoch 170/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4125 - val_loss: 1.7038\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 1.68702\n",
      "Epoch 171/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4235 - val_loss: 1.7220\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 1.68702\n",
      "Epoch 172/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4114 - val_loss: 1.7194\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 1.68702\n",
      "Epoch 173/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.4124 - val_loss: 1.7322\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 1.68702\n",
      "Epoch 174/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4145 - val_loss: 1.7493\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 1.68702\n",
      "Epoch 175/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.4063 - val_loss: 1.7665\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 1.68702\n",
      "Epoch 176/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.4080 - val_loss: 1.7207\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 1.68702\n",
      "Epoch 177/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.4211 - val_loss: 1.7129\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 1.68702\n",
      "Epoch 178/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.3993 - val_loss: 1.7695\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 1.68702\n",
      "Epoch 179/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.4045 - val_loss: 1.7077\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 1.68702\n",
      "Epoch 180/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3983 - val_loss: 1.7364\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 1.68702\n",
      "Epoch 181/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4058 - val_loss: 1.7344\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 1.68702\n",
      "Epoch 182/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.4036 - val_loss: 1.7916\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 1.68702\n",
      "Epoch 183/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.3958 - val_loss: 1.7148\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 1.68702\n",
      "Epoch 184/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.3936 - val_loss: 1.7560\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 1.68702\n",
      "Epoch 185/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3957 - val_loss: 1.7330\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 1.68702\n",
      "Epoch 186/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3927 - val_loss: 1.7273\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 1.68702\n",
      "Epoch 187/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3857 - val_loss: 1.7207\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 1.68702\n",
      "Epoch 188/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3926 - val_loss: 1.7406\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 1.68702\n",
      "Epoch 189/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3955 - val_loss: 1.7150\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 1.68702\n",
      "Epoch 190/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3900 - val_loss: 1.8419\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 1.68702\n",
      "Epoch 191/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.3786 - val_loss: 1.7600\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 1.68702\n",
      "Epoch 192/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.3843 - val_loss: 1.7557\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 1.68702\n",
      "Epoch 193/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.3841 - val_loss: 1.7270\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 1.68702\n",
      "Epoch 194/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.3772 - val_loss: 1.7737\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 1.68702\n",
      "Epoch 195/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3775 - val_loss: 1.7417\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 1.68702\n",
      "Epoch 196/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3787 - val_loss: 1.7610\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 1.68702\n",
      "Epoch 197/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.3705 - val_loss: 1.7524\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 1.68702\n",
      "Epoch 198/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3815 - val_loss: 1.7459\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 1.68702\n",
      "Epoch 199/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3741 - val_loss: 1.7408\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 1.68702\n",
      "Epoch 200/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3711 - val_loss: 1.7230\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 1.68702\n",
      "Epoch 201/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3908 - val_loss: 1.7506\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 1.68702\n",
      "Epoch 202/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3649 - val_loss: 1.7623\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 1.68702\n",
      "Epoch 203/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3599 - val_loss: 1.7234\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 1.68702\n",
      "Epoch 204/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3648 - val_loss: 1.7187\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 1.68702\n",
      "Epoch 205/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3765 - val_loss: 1.7513\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 1.68702\n",
      "Epoch 206/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3559 - val_loss: 1.7398\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 1.68702\n",
      "Epoch 207/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3522 - val_loss: 1.7378\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 1.68702\n",
      "Epoch 208/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3562 - val_loss: 1.7298\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 1.68702\n",
      "Epoch 209/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3556 - val_loss: 1.7650\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 1.68702\n",
      "Epoch 210/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3572 - val_loss: 1.7230\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 1.68702\n",
      "Epoch 211/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3508 - val_loss: 1.8108\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 1.68702\n",
      "Epoch 212/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3637 - val_loss: 1.7588\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 1.68702\n",
      "Epoch 213/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3514 - val_loss: 1.7329\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 1.68702\n",
      "Epoch 214/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3456 - val_loss: 1.7515\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 1.68702\n",
      "Epoch 215/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3495 - val_loss: 1.7261\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 1.68702\n",
      "Epoch 216/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3423 - val_loss: 1.8012\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 1.68702\n",
      "Epoch 217/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3352 - val_loss: 1.7580\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 1.68702\n",
      "Epoch 218/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3480 - val_loss: 1.7520\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 1.68702\n",
      "Epoch 219/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3412 - val_loss: 1.7383\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 1.68702\n",
      "Epoch 220/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3338 - val_loss: 1.7562\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 1.68702\n",
      "Epoch 221/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3395 - val_loss: 1.7318\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 1.68702\n",
      "Epoch 222/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3400 - val_loss: 1.7713\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 1.68702\n",
      "Epoch 223/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3294 - val_loss: 1.7418\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 1.68702\n",
      "Epoch 224/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3327 - val_loss: 1.7501\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 1.68702\n",
      "Epoch 225/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3328 - val_loss: 1.7616\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 1.68702\n",
      "Epoch 226/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3369 - val_loss: 1.7370\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 1.68702\n",
      "Epoch 227/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3297 - val_loss: 1.7529\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 1.68702\n",
      "Epoch 228/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3271 - val_loss: 1.7516\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 1.68702\n",
      "Epoch 229/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3334 - val_loss: 1.7392\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 1.68702\n",
      "Epoch 230/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.3179 - val_loss: 1.7498\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 1.68702\n",
      "Epoch 231/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3236 - val_loss: 1.7502\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 1.68702\n",
      "Epoch 232/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3111 - val_loss: 1.7649\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 1.68702\n",
      "Epoch 233/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3297 - val_loss: 1.7591\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 1.68702\n",
      "Epoch 234/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3254 - val_loss: 1.7812\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 1.68702\n",
      "Epoch 235/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3134 - val_loss: 1.7609\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 1.68702\n",
      "Epoch 236/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3185 - val_loss: 1.7654\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 1.68702\n",
      "Epoch 237/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.3048 - val_loss: 1.7536\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 1.68702\n",
      "Epoch 238/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3101 - val_loss: 1.8135\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 1.68702\n",
      "Epoch 239/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3140 - val_loss: 1.7577\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 1.68702\n",
      "Epoch 240/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3047 - val_loss: 1.7935\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 1.68702\n",
      "Epoch 241/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3102 - val_loss: 1.7563\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 1.68702\n",
      "Epoch 242/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3021 - val_loss: 1.7686\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 1.68702\n",
      "Epoch 243/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3053 - val_loss: 1.7662\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 1.68702\n",
      "Epoch 244/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.3030 - val_loss: 1.7782\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 1.68702\n",
      "Epoch 245/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.3125 - val_loss: 1.7551\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 1.68702\n",
      "Epoch 246/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2930 - val_loss: 1.7650\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 1.68702\n",
      "Epoch 247/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2915 - val_loss: 1.7610\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 1.68702\n",
      "Epoch 248/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3062 - val_loss: 1.8280\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 1.68702\n",
      "Epoch 249/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3013 - val_loss: 1.7778\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 1.68702\n",
      "Epoch 250/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.3015 - val_loss: 1.7649\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 1.68702\n",
      "Epoch 251/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2926 - val_loss: 1.7869\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 1.68702\n",
      "Epoch 252/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2798 - val_loss: 1.7756\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 1.68702\n",
      "Epoch 253/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2999 - val_loss: 1.7853\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 1.68702\n",
      "Epoch 254/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2904 - val_loss: 1.7892\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 1.68702\n",
      "Epoch 255/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2910 - val_loss: 1.7976\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 1.68702\n",
      "Epoch 256/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2842 - val_loss: 1.7742\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 1.68702\n",
      "Epoch 257/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2824 - val_loss: 1.7815\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 1.68702\n",
      "Epoch 258/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2823 - val_loss: 1.7853\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 1.68702\n",
      "Epoch 259/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2817 - val_loss: 1.7898\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 1.68702\n",
      "Epoch 260/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2772 - val_loss: 1.8101\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 1.68702\n",
      "Epoch 261/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2955 - val_loss: 1.7707\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 1.68702\n",
      "Epoch 262/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2803 - val_loss: 1.7843\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 1.68702\n",
      "Epoch 263/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2765 - val_loss: 1.7849\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 1.68702\n",
      "Epoch 264/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2719 - val_loss: 1.8099\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 1.68702\n",
      "Epoch 265/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2688 - val_loss: 1.8220\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 1.68702\n",
      "Epoch 266/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2694 - val_loss: 1.7791\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 1.68702\n",
      "Epoch 267/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2592 - val_loss: 1.7859\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 1.68702\n",
      "Epoch 268/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2712 - val_loss: 1.7800\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 1.68702\n",
      "Epoch 269/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2685 - val_loss: 1.7838\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 1.68702\n",
      "Epoch 270/1000\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 1.2699 - val_loss: 1.7701\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 1.68702\n",
      "Epoch 271/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2597 - val_loss: 1.7756\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 1.68702\n",
      "Epoch 272/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2697 - val_loss: 1.8007\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 1.68702\n",
      "Epoch 273/1000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 1.2593 - val_loss: 1.8729\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 1.68702\n"
     ]
    }
   ],
   "source": [
    "chkpoint = tf.keras.callbacks.ModelCheckpoint('mdn3_regressor_pfnd.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=150, verbose=0, restore_best_weights=True)\n",
    "history_mdn3 = regressor_All.fit(X_train, \n",
    "                                 y_train,\n",
    "                                 validation_split=0.1,\n",
    "                                 callbacks=[chkpoint, earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = regressor_All.predict(eval_generator(All_input,300))\n",
    "pp['predict_regressor_MDN3'] = np.exp(scaler_cal.inverse_transform(pred[:,0].reshape(-1,1)))\n",
    "pp['predict_regressor_MDN3_EoverCalib'] = pp.predict_regressor_MDN3 / pp.cluster_ENG_CALIB_TOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_MDN3 = pp.predict_regressor_MDN3-pp.cluster_ENG_CALIB_TOT\n",
    "resid_MDN3_mask = np.logical_and(resid_MDN3 < 2000, resid_MDN3 > -2000)\n",
    "\n",
    "n_bins = 500\n",
    "plt.cla(); plt.clf()\n",
    "fig = plt.figure()\n",
    "fig.patch.set_facecolor('white')\n",
    "plt.hist(resid_MDN3[resid_MDN3_mask],bins = n_bins)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Learned - True Energy')\n",
    "plt.xlim(-2000,2000)\n",
    "plt.legend()\n",
    "\n",
    "atlas_x = 0.55\n",
    "atlas_y = 0.95\n",
    "simulation = True\n",
    "textlist = [{'x': 0.55, 'y': 0.85, 'text': 'Single $\\pi^{+}$, All Clusters'},\n",
    "            {'x': 0.55, 'y': 0.8,  'text': 'MDN, 3 Components'}]\n",
    "pu.drawLabels(fig, atlas_x, atlas_y, simulation, textlist)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcenter, iqrMDN3 = resolutionPlot(pp[pp.test].cluster_ENG_CALIB_TOT,\n",
    "                        pp[pp.test].predict_regressor_MDN3_EoverCalib,\n",
    "                        ylim=(0,0.75),\n",
    "                        atlas_x = 0.56, atlas_y = 0.95, simulation = True,\n",
    "                        textlist = [{'x': 0.56, 'y': 0.85, 'text': 'Single $\\pi^{+}$, All Clusters'},\n",
    "                                    {'x': 0.56, 'y': 0.8,  'text': 'MDN, 3 Components'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcenter, medMDN3 = ru.responsePlot(pp[pp.test].cluster_ENG_CALIB_TOT, pp[pp.test].predict_regressor_MDN3_EoverCalib,\n",
    "                 plotpath+'hist_2D_calib_vs_ratioReg_E1T0_pp_profile.pdf',\n",
    "                 'median',\n",
    "                 atlas_x = 0.46, atlas_y = 0.95, simulation = True,\n",
    "                 textlist = [{'x': 0.46, 'y': 0.85, 'text': 'Single $\\pi^{+}$, All Clusters'},\n",
    "                             {'x': 0.46, 'y': 0.8,  'text': 'MDN, 3 Components'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogramSlices(pp[pp.test].cluster_ENG_CALIB_TOT, pp[pp.test].predict_regressor_MDN3_EoverCalib,\n",
    "                atlas_x = 0.55, atlas_y = 0.85, simulation = True,\n",
    "                textlist = [{'x': 0.55, 'y': 0.75, 'text': 'Single $\\pi^{+}$'},\n",
    "                            {'x': 0.55, 'y': 0.7, 'text': ''},\n",
    "                            {'x': 0.55, 'y': 0.65,  'text': 'MDN, 3 Components'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 500\n",
    "plt.cla(); plt.clf()\n",
    "fig = plt.figure()\n",
    "fig.patch.set_facecolor('white')\n",
    "plt.hist(resid_DNN,bins = n_bins,alpha=0.5, label='DNN')\n",
    "plt.hist(resid_MDN[resid_MDN_mask],bins = n_bins,alpha=0.5, label='MDN w/ 1 Component')\n",
    "plt.hist(resid_MDN3[resid_MDN3_mask],bins = n_bins,alpha=0.5, label='MDN w/ 3 Components')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Learned - True Energy')\n",
    "plt.xlim(-3000,3000)\n",
    "plt.legend()\n",
    "\n",
    "atlas_x = 0.55\n",
    "atlas_y = 0.8\n",
    "simulation = True\n",
    "textlist = [{'x': 0.55, 'y': 0.7, 'text': 'Single $\\pi^{+}$, All Clusters'}]\n",
    "pu.drawLabels(fig, atlas_x, atlas_y, simulation, textlist)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pu.lineOverlay(xcenter=xcenter, lines = [medDNN, medMDN, medMDN3],\n",
    "                                labels = ['DNN', 'MDN w/ 1 Component', 'MDN w/ 3 Components'],\n",
    "                xlabel = 'True Energy [GeV]', ylabel = 'Response Median',\n",
    "                figfile = plotpath + \"hist_2D_E_vs_ratio_pp_profile_Overlay_Overlay_BaseLCAll.pdf\",\n",
    "                x_min = 0.3, y_min=0.75, y_max = 1.25,\n",
    "                extra_lines = [[[0.1,1000],[1,1]]],\n",
    "                # linestyles = ['solid', 'dashed', 'solid', 'dashed', 'solid','dashed','solid','dashed','solid','dashed'], colorgrouping=2,\n",
    "                atlas_x = 0.5, atlas_y = 0.275, simulation = True,\n",
    "                textlist = [{'x': 0.5, 'y': 0.175, 'text': 'Single $\\pi^{+}$, All Clusters'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogramSlices(pp.cluster_ENG_CALIB_TOT, \n",
    "                ylist=[pp.predict_regressor_DNN_EoverCalib, \n",
    "                       pp.predict_regressor_MDN_EoverCalib, \n",
    "                       pp.predict_regressor_MDN3_EoverCalib],\n",
    "                labels=['DNN', 'MDN w/ 1 Component', 'MDN w/ 3 Components'],\n",
    "                binsize=0.02, xstep=0.2, alpha=0.8,\n",
    "                atlas_x = 0.55, atlas_y = 0.8, simulation = True,\n",
    "                textlist = [{'x': 0.55, 'y': 0.7, 'text': 'Single $\\pi^{+}$'},\n",
    "                            {'x': 0.55, 'y': 0.65, 'text': ''}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pu.lineOverlay(xcenter=xcenter, lines = [iqrDNN, iqrMDN, iqrMDN3],\n",
    "                labels = ['DNN', 'MDN w/ 1 Component', 'MDN w/ 3 Components'],\n",
    "                xlabel = 'True Energy [GeV]', ylabel = 'Response IQR / (2 x Median)',\n",
    "                figfile = plotpath + \"hist_2D_calib_vs_ratio_pp_res_Overlay_BaseRegLCEMB1TileBar0E1T0All.pdf\",\n",
    "                x_min = 0.3, y_max = .75,\n",
    "                atlas_x = 0.56, atlas_y = 0.75, simulation = True,\n",
    "                textlist = [{'x': 0.56, 'y': 0.65, 'text': 'Single $\\pi^{+}$, All Clusters'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = pred[:,0]\n",
    "sigma = pred[:,1]\n",
    "\n",
    "# Renormalize data (inverse transform scaler normalization); propogate uncertainties\n",
    "median = scaler_cal.scale_ * median\n",
    "sigma = scaler_cal.scale_ * sigma # or _median * (sigma / median)\n",
    "\n",
    "median = median + scaler_cal.mean_\n",
    "\n",
    "median = np.exp(median)   # Reconstructed Energy Per Cluster\n",
    "sigma = median * sigma   # Reconstructed Energy Uncertainty (Std dev) Per Cluster\n",
    "\n",
    "\n",
    "# Calculate pull\n",
    "pull = (median-pp.cluster_ENG_CALIB_TOT) / sigma\n",
    "badval_mask = np.logical_and(pull < 100, pull > -100)\n",
    "pull = pull[badval_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pull\n",
    "n_bins = 1000\n",
    "plt.cla(); plt.clf()\n",
    "fig = plt.figure()\n",
    "fig.patch.set_facecolor('white')\n",
    "plt.hist(pull,bins = n_bins, label='All Clusters, Mean = {:.3f}, Std. dev. = {:.3f}'.format(pull.mean(), pull.std()))\n",
    "plt.xlabel('(Predicted Energy - True Energy) / Predicted Uncertainty')\n",
    "plt.ylabel('Clusters')\n",
    "plt.xlim(-6,6)\n",
    "plt.legend()\n",
    "\n",
    "atlas_x = 0.58\n",
    "atlas_y = 0.85\n",
    "simulation = True\n",
    "textlist = [{'x': 0.58, 'y': 0.75, 'text': 'Single $\\pi^{+}$, All Clusters'},\n",
    "            {'x': 0.58, 'y': 0.7, 'text': 'MDN, 3 Components'}]\n",
    "pu.drawLabels(fig, atlas_x, atlas_y, simulation, textlist)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pull\n",
    "n_bins = 1000\n",
    "plt.cla(); plt.clf()\n",
    "fig = plt.figure()\n",
    "fig.patch.set_facecolor('white')\n",
    "plt.hist(pull,bins = n_bins, density = True, label='All Clusters, Mean = {:.3f}, Std. dev. = {:.3f}'.format(pull.mean(), pull.std()))\n",
    "\n",
    "x = np.linspace(-6,6,100)\n",
    "pdf = stats.norm.pdf(x)\n",
    "plt.plot(x, pdf, label='Unit Normal')\n",
    "\n",
    "plt.xlabel('(Predicted Energy - True Energy) / Predicted Uncertainty')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.xlim(-6,6)\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "\n",
    "atlas_x = 0.3\n",
    "atlas_y = 0.25\n",
    "simulation = True\n",
    "textlist = [{'x': 0.3, 'y': 0.15, 'text': 'Single $\\pi^{+}$, All Clusters'},\n",
    "            {'x': 0.3, 'y': 0.1, 'text': 'MDN, 3 Components'}]\n",
    "pu.drawLabels(fig, atlas_x, atlas_y, simulation, textlist)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogramSlices(pp.cluster_ENG_CALIB_TOT, pull, statistic='std',\n",
    "                ylim=(-6., 6.), xstep=1.3333333333333, binsize=0.1, \n",
    "                xlabel='Pull', ylabel='Clusters', title='Pull',\n",
    "                atlas_x = 0.58, atlas_y = 0.85, simulation = True,\n",
    "                textlist = [{'x': 0.58, 'y': 0.75, 'text': 'Single $\\pi^{+}$'},\n",
    "                            {'x': 0.58, 'y': 0.7, 'text': ''},\n",
    "                            {'x': 0.58, 'y': 0.65, 'text': 'MDN, 3 Components'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogramSlices(pp.cluster_ENG_CALIB_TOT, pull, statistic='std',\n",
    "                ylim=(-6., 6.), xstep=1.3333333333333, binsize=0.1, baseline=True, logscale=True, density=True,\n",
    "                xlabel='Pull', ylabel='Probability Density', title='Pull',\n",
    "                atlas_x = 0.3, atlas_y = 0.4, simulation = True,\n",
    "                textlist = [{'x': 0.3, 'y': 0.3, 'text': 'Single $\\pi^{+}$'},\n",
    "                            {'x': 0.3, 'y': 0.25, 'text': ''},\n",
    "                            {'x': 0.3, 'y': 0.2, 'text': 'MDN, 3 Components'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_over_true = median / pp.cluster_ENG_CALIB_TOT   #   Reconstructed Energy / True Energy\n",
    "iqr_over_median = 2 * sigma / median  # Reconstructed Energy Resolution Per Cluster\n",
    "iqr_over_true = 2 * sigma / pp.cluster_ENG_CALIB_TOT  # Pred Sigma / True Energy Per Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcenter, iqrOverMed_MDN_learned = ru.responsePlot(pp.cluster_ENG_CALIB_TOT, iqr_over_median/2,\n",
    "                 plotpath+'hist_2D_calib_vs_sigma.pdf',\n",
    "                 'median',\n",
    "                 atlas_x = 0.38, atlas_y = 0.95, simulation = True,\n",
    "                 xlim=(0.3,1000), ylim=(0,0.75), baseline=False,\n",
    "                 xlabel='True Energy [GeV]', ylabel='Predicted IQR / (2 x Predicted Energy)',\n",
    "                 textlist = [{'x': 0.38, 'y': 0.85, 'text': 'Single $\\pi^{+}$, All Clusters'},\n",
    "                             {'x': 0.38, 'y': 0.8,  'text': 'MDN, 3 Components'}])\n",
    "\n",
    "xcenter, iqrOverTrue_MDN_learned = ru.responsePlot(pp.cluster_ENG_CALIB_TOT, iqr_over_true/2,\n",
    "                 plotpath+'hist_2D_calib_vs_sigma.pdf',\n",
    "                 'median',\n",
    "                 atlas_x = 0.38, atlas_y = 0.95, simulation = True,\n",
    "                 xlim=(0.3,1000), ylim=(0,0.75), baseline=False,\n",
    "                 xlabel='True Energy [GeV]', ylabel='Predicted IQR / (2 x True Energy)',\n",
    "                 textlist = [{'x': 0.38, 'y': 0.85, 'text': 'Single $\\pi^{+}$, All Clusters'},\n",
    "                             {'x': 0.38, 'y': 0.8,  'text': 'MDN, 3 Components'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pu.lineOverlay(xcenter=xcenter, lines = [iqrMDN3, iqrOverMed_MDN_learned],\n",
    "                labels = ['Response IQR / (2 x Response Median)', 'Median Predicted IQR / (2 x Predicted Energy)'],\n",
    "                xlabel = 'True Energy [GeV]', ylabel = 'Resolution',\n",
    "                figfile = plotpath + \"hist_2D_calib_vs_ratio_pp_res_Overlay_BaseRegLCEMB1TileBar0E1T0All.pdf\",\n",
    "                x_min = 0.3, y_max = 0.75,\n",
    "                linestyles = ['dashed', 'solid', 'solid'], colorgrouping=1,\n",
    "                atlas_x = 0.55, atlas_y = 0.75, simulation = True,\n",
    "                textlist = [{'x': 0.55, 'y': 0.65, 'text': 'Single $\\pi^{+}$, All Clusters'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tensor(X):\n",
    "    # return tf.concat([tfp.distributions.Distribution.mean(X), tfp.distributions.Distribution.stddev(X)],1)\n",
    "    # return X.sample(100)\n",
    "    return X.prob(np.linspace(-3,3,100))\n",
    "\n",
    "def MDN3():\n",
    "    event_shape = [1]\n",
    "    num_components = 3\n",
    "    params_size = tfp.layers.MixtureNormal.params_size(num_components, event_shape)\n",
    "    number_pixels = 512 + 256 + 128 + 16 + 16 +8\n",
    "    with strategy.scope():    \n",
    "        model = Sequential()\n",
    "        features = number_pixels + 2\n",
    "        model.add(Dense(features, input_dim=features, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(features, activation='relu'))\n",
    "        model.add(Dense(int(features/2), activation='relu'))\n",
    "        model.add(Dense(units=params_size, activation=lambda x: tf.clip_by_value(x, -30., 30.)))\n",
    "        \n",
    "        model.add(tfp.layers.MixtureNormal(num_components, event_shape, #validate_args=True,\n",
    "                                           convert_to_tensor_fn=convert_to_tensor))\n",
    "\n",
    "        opt = Adam(learning_rate=1e-4)#, decay=1e-6)\n",
    "        model.compile(optimizer=opt, loss=lambda y, model: -model.log_prob(y))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_All = MDN3()\n",
    "regressor_All.load_weights(modelpath + 'mdn3_regressor.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = regressor_All(All_input)\n",
    "\n",
    "t1 = test.sample(10).numpy().reshape(-1)\n",
    "t1 = t1[np.logical_and(t1 < 3, t1 > -3)]\n",
    "\n",
    "plt.hist(pp[pp.train].s_logECalib.to_numpy(), bins=100, alpha=0.3, density=True, label='All Clusters')\n",
    "plt.hist(t1, bins=100, alpha=0.3, density=True, label='MDN Sampled Distribution')\n",
    "# plt.yscale('log')\n",
    "plt.title(\"Log Normalized Energy\")\n",
    "plt.xlabel('Log Normalized Truth Energy')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b5d44aea0cc164fd0ebfc1732b90238ce53cef8d0e631d031394e4c6aaa004a9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tensorflow-gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
